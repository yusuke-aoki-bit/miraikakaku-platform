#!/usr/bin/env python3
"""
Miraikakaku ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é‡è¦åº¦ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡ãƒ»æ•´ç†
"""

import os
import shutil
from datetime import datetime

def organize_files():
    """ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ—‚ï¸ Miraikakaku ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†é–‹å§‹")
    
    # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    files = []
    for item in os.listdir('.'):
        if os.path.isfile(item) and not item.startswith('.'):
            files.append(item)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡
    file_categories = {
        'ğŸš€ CORE_SYSTEM': [
            'universal_stock_api.py',           # ãƒ¡ã‚¤ãƒ³API
            'comprehensive_japanese_stocks_enhanced.py',  # æ—¥æœ¬æ ªDB
            'optimized_etfs_3000.json'          # ETF DB (if exists)
        ],
        
        'ğŸ¤– ML_BATCH_SYSTEM': [
            'miraikakakubatch.py',              # ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ 
            'ml_prediction_system.py',          # MLäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³
            'japanese_stock_updater.py',        # æ—¥æœ¬æ ªæ›´æ–°
            'simple_monitor.py',                # è»½é‡ç›£è¦–
            'test_ml_integration.py'            # MLãƒ†ã‚¹ãƒˆ
        ],
        
        'ğŸ“Š DOCUMENTATION': [
            'README.md',                        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
            'README_BATCH_SYSTEM.md',           # ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ æ–‡æ›¸
            'README_ML_BATCH_SYSTEM.md'         # MLæ–‡æ›¸
        ],
        
        'ğŸ”§ SETUP_TOOLS': [
            'install_batch_system.py',          # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼
            'setup_monitoring.sh',              # ç›£è¦–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            'miraikakaku-batch.service'         # systemdã‚µãƒ¼ãƒ“ã‚¹
        ],
        
        'ğŸ“ˆ DATA_BUILDERS': [
            'etf_optimizer.py',                 # ETFæœ€é©åŒ–
            'global_stock_database.py'          # ã‚°ãƒ­ãƒ¼ãƒãƒ«DB
        ],
        
        'ğŸ—ƒï¸ LEGACY_DATA_FILES': [
            'comprehensive_stocks.py',          # æ—§556ç¤¾DB
            'comprehensive_stocks_backup.py',   # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            'comprehensive_stocks_expanded.py', # æ‹¡å¼µç‰ˆ
            'comprehensive_stocks_massive.py',  # å¤§è¦æ¨¡ç‰ˆ
            'comprehensive_japanese_stocks_complete.py'  # å®Œå…¨ç‰ˆ
        ],
        
        'ğŸ”¨ DEVELOPMENT_TOOLS': [
            'build_comprehensive_database.py',  # DBæ§‹ç¯‰
            'create_enhanced_japanese_stocks.py', # å¼·åŒ–DBä½œæˆ
            'create_complete_japanese_stocks.py', # å®Œå…¨DBä½œæˆ
            'fetch_comprehensive_stocks.py',    # åŒ…æ‹¬å–å¾—
            'massive_stock_expansion.py'        # å¤§è¦æ¨¡æ‹¡å¼µ
        ],
        
        'ğŸ“‹ REPORTS': [
            'DATABASE_EXPANSION_REPORT.md',     # DBæ‹¡å¼µãƒ¬ãƒãƒ¼ãƒˆ
            'US_STOCK_DATABASE_ENHANCEMENT_REPORT.md', # ç±³å›½æ ªãƒ¬ãƒãƒ¼ãƒˆ
            'japanese_stock_coverage_report.md' # æ—¥æœ¬æ ªãƒ¬ãƒãƒ¼ãƒˆ
        ],
        
        'ğŸ§ª EXPERIMENTAL': [
            'batch_data_populate.py',           # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿æŠ•å…¥
            'ORGANIZE_FILES.py'                 # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
        ]
    }
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡çµæœè¡¨ç¤º
    print("\nğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡çµæœ:")
    print("=" * 60)
    
    found_files = set()
    
    for category, file_list in file_categories.items():
        print(f"\n{category}:")
        category_files = []
        for file_name in file_list:
            if file_name in files:
                status = "âœ… å­˜åœ¨"
                found_files.add(file_name)
                category_files.append(file_name)
            else:
                status = "âŒ ãªã—"
            print(f"  {file_name:<40} {status}")
        
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®çµ±è¨ˆ
        if category_files:
            total_size = sum(os.path.getsize(f) for f in category_files)
            print(f"    ğŸ“Š ã“ã®ã‚«ãƒ†ã‚´ãƒª: {len(category_files)}ãƒ•ã‚¡ã‚¤ãƒ« ({total_size/1024:.1f}KB)")
    
    # æœªåˆ†é¡ãƒ•ã‚¡ã‚¤ãƒ«
    unclassified = [f for f in files if f not in found_files]
    if unclassified:
        print(f"\nâ“ æœªåˆ†é¡ãƒ•ã‚¡ã‚¤ãƒ«:")
        for file_name in unclassified:
            size = os.path.getsize(file_name) / 1024
            print(f"  {file_name:<40} ({size:.1f}KB)")
    
    print("\n" + "=" * 60)
    
    # æ•´ç†æ¨å¥¨äº‹é …
    print("\nğŸ’¡ æ•´ç†æ¨å¥¨äº‹é …:")
    
    recommendations = []
    
    # é‡è¦åº¦åˆ†æ
    core_files = len(file_categories['ğŸš€ CORE_SYSTEM'])
    legacy_files = len([f for f in file_categories['ğŸ—ƒï¸ LEGACY_DATA_FILES'] if f in files])
    dev_files = len([f for f in file_categories['ğŸ”¨ DEVELOPMENT_TOOLS'] if f in files])
    
    if legacy_files > 0:
        recommendations.append(f"ğŸ“¦ LEGACY_DATA_FILES ({legacy_files}ãƒ•ã‚¡ã‚¤ãƒ«) ã‚’ archives/ ã«ç§»å‹•")
    
    if dev_files > 3:
        recommendations.append(f"ğŸ”¨ DEVELOPMENT_TOOLS ã‚’ tools/ ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ•´ç†")
    
    if len(unclassified) > 0:
        recommendations.append(f"â“ æœªåˆ†é¡ãƒ•ã‚¡ã‚¤ãƒ« ({len(unclassified)}ãƒ•ã‚¡ã‚¤ãƒ«) ã®ç”¨é€”ç¢ºèª")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ææ¡ˆ
    recommendations.append("ğŸ“ æ¨å¥¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :")
    
    directory_structure = """
miraikakaku/
â”œâ”€â”€ ğŸš€ CORE (å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ )
â”‚   â”œâ”€â”€ universal_stock_api.py
â”‚   â”œâ”€â”€ comprehensive_japanese_stocks_enhanced.py
â”‚   â””â”€â”€ optimized_etfs_3000.json
â”‚
â”œâ”€â”€ ğŸ¤– BATCH (è‡ªå‹•å‡¦ç†)
â”‚   â”œâ”€â”€ miraikakakubatch.py
â”‚   â”œâ”€â”€ ml_prediction_system.py
â”‚   â”œâ”€â”€ japanese_stock_updater.py
â”‚   â””â”€â”€ simple_monitor.py
â”‚
â”œâ”€â”€ ğŸ“Š DOCS (æ–‡æ›¸)
â”‚   â”œâ”€â”€ README*.md
â”‚   â””â”€â”€ reports/
â”‚
â”œâ”€â”€ ğŸ”§ SETUP (ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
â”‚   â”œâ”€â”€ install_batch_system.py
â”‚   â”œâ”€â”€ setup_monitoring.sh
â”‚   â””â”€â”€ config/
â”‚
â”œâ”€â”€ ğŸ“¦ ARCHIVES (ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–)
â”‚   â”œâ”€â”€ legacy_databases/
â”‚   â””â”€â”€ old_versions/
â”‚
â””â”€â”€ ğŸ”¨ TOOLS (é–‹ç™ºãƒ„ãƒ¼ãƒ«)
    â”œâ”€â”€ builders/
    â””â”€â”€ utilities/
"""
    
    for rec in recommendations:
        print(f"  â€¢ {rec}")
    
    print(directory_structure)
    
    # è‡ªå‹•æ•´ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    print("\nğŸ¤– è‡ªå‹•æ•´ç†å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ")
    print("1. ã¯ã„ - æ¨å¥¨æ§‹é€ ã§æ•´ç†")
    print("2. ã„ã„ãˆ - ç¾çŠ¶ç¶­æŒ")
    print("3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã®ã¿")
    
    # choice = input("é¸æŠ (1-3): ")
    choice = "3"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å®‰å…¨ãªé¸æŠ
    
    if choice == "1":
        auto_organize_files(file_categories, files)
    elif choice == "3":
        create_backup()
    
    # çµ±è¨ˆæƒ…å ±
    print("\nğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµ±è¨ˆ:")
    total_files = len(files)
    total_size = sum(os.path.getsize(f) for f in files) / 1024 / 1024
    print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
    print(f"  ç·ã‚µã‚¤ã‚º: {total_size:.2f}MB")
    print(f"  ã‚³ã‚¢ã‚·ã‚¹ãƒ†ãƒ : {len([f for f in file_categories['ğŸš€ CORE_SYSTEM'] if f in files])}ãƒ•ã‚¡ã‚¤ãƒ«")
    print(f"  å®Ÿè¡Œä¸­ã‚·ã‚¹ãƒ†ãƒ : universal_stock_api.py, miraikakakubatch.py")
    
    print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†åˆ†æå®Œäº†")

def auto_organize_files(file_categories, files):
    """è‡ªå‹•ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†"""
    print("\nğŸ¤– è‡ªå‹•æ•´ç†å®Ÿè¡Œä¸­...")
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_dir = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(backup_dir, exist_ok=True)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    directories = {
        'core': 'ğŸš€_CORE_SYSTEM',
        'batch': 'ğŸ¤–_BATCH_SYSTEM', 
        'docs': 'ğŸ“Š_DOCUMENTATION',
        'setup': 'ğŸ”§_SETUP_TOOLS',
        'archives': 'ğŸ“¦_ARCHIVES',
        'tools': 'ğŸ”¨_TOOLS'
    }
    
    for dir_name in directories.values():
        os.makedirs(dir_name, exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹• (å®Ÿéš›ã®ç§»å‹•ã¯å±é™ºãªã®ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)
    print("  (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ - å®Ÿéš›ã®ç§»å‹•ã¯è¡Œã„ã¾ã›ã‚“)")
    
    move_plan = {
        'ğŸš€ CORE_SYSTEM': 'ğŸš€_CORE_SYSTEM/',
        'ğŸ¤– ML_BATCH_SYSTEM': 'ğŸ¤–_BATCH_SYSTEM/',
        'ğŸ“Š DOCUMENTATION': 'ğŸ“Š_DOCUMENTATION/',
        'ğŸ”§ SETUP_TOOLS': 'ğŸ”§_SETUP_TOOLS/',
        'ğŸ—ƒï¸ LEGACY_DATA_FILES': 'ğŸ“¦_ARCHIVES/',
        'ğŸ”¨ DEVELOPMENT_TOOLS': 'ğŸ”¨_TOOLS/'
    }
    
    for category, target_dir in move_plan.items():
        if category in file_categories:
            for file_name in file_categories[category]:
                if file_name in files:
                    print(f"    {file_name} â†’ {target_dir}")

def create_backup():
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
    print("\nğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
    
    backup_dir = f"project_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(backup_dir, exist_ok=True)
    
    # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    important_files = [
        'universal_stock_api.py',
        'miraikakakubatch.py',
        'ml_prediction_system.py',
        'comprehensive_japanese_stocks_enhanced.py',
        'README*.md'
    ]
    
    backup_count = 0
    for pattern in important_files:
        if '*' in pattern:
            # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¯¾å¿œ
            import glob
            for file_path in glob.glob(pattern):
                if os.path.exists(file_path):
                    shutil.copy2(file_path, backup_dir)
                    backup_count += 1
        else:
            if os.path.exists(pattern):
                shutil.copy2(pattern, backup_dir)
                backup_count += 1
    
    print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_dir} ({backup_count}ãƒ•ã‚¡ã‚¤ãƒ«)")

if __name__ == "__main__":
    organize_files()