#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Miraikakaku AI Assistant System
È´òÂ∫¶„Å™AIÊäïË≥á„Ç¢„Éâ„Éê„Ç§„Ç∂„Éº

Ê©üËÉΩ:
- Ëá™ÁÑ∂Ë®ÄË™û„Å´„Çà„ÇãÊäïË≥áÁõ∏Ë´áÂØæÂøú
- Â∏ÇÂ†¥ÂàÜÊûê„Å®‰∫àÊ∏¨„ÅÆË™¨Êòé
- „Éù„Éº„Éà„Éï„Ç©„É™„Ç™ÊúÄÈÅ©ÂåñÊèêÊ°à
- „É™„Çπ„ÇØÂàÜÊûê„Å®„Ç¢„É©„Éº„Éà
- ÊäïË≥áÊà¶Áï•„Ç´„Çπ„Çø„Éû„Ç§„Ç∫
- „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂàÜÊûêÔºà„ÉÜ„Ç≠„Çπ„Éà + „Éá„Éº„ÇøÔºâ
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import re
import numpy as np
import pandas as pd

# „Éá„Éº„Çø„Éô„Éº„Çπ
import psycopg2
from psycopg2.extras import RealDictCursor

# Ê©üÊ¢∞Â≠¶Áøí„ÉªÁµ±Ë®à
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# „É≠„Ç∞Ë®≠ÂÆö
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ai_assistant.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class UserQuery:
    """„É¶„Éº„Ç∂„Éº„ÅÆË≥™Âïè"""
    text: str
    user_id: Optional[str]
    timestamp: datetime
    context: Dict[str, Any]
    intent: Optional[str] = None
    entities: Optional[Dict[str, List[str]]] = None

@dataclass
class AssistantResponse:
    """AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„ÅÆÂõûÁ≠î"""
    response_text: str
    confidence: float
    response_type: str  # 'analysis', 'recommendation', 'explanation', 'alert'
    data_sources: List[str]
    suggested_actions: List[str]
    related_stocks: List[str]
    charts_data: Optional[Dict[str, Any]]
    timestamp: datetime
    reasoning: List[str]

@dataclass
class InvestmentProfile:
    """ÊäïË≥á„Éó„É≠„Éï„Ç°„Ç§„É´"""
    user_id: str
    risk_tolerance: str  # 'conservative', 'moderate', 'aggressive'
    investment_horizon: str  # 'short', 'medium', 'long'
    preferred_sectors: List[str]
    capital_amount: Optional[float]
    experience_level: str  # 'beginner', 'intermediate', 'advanced'
    goals: List[str]
    constraints: List[str]

class NaturalLanguageProcessor:
    """Ëá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜ„Ç®„É≥„Ç∏„É≥"""

    def __init__(self):
        self.intent_patterns = {
            'price_inquiry': [
                r'.*‰æ°Ê†º.*', r'.*Ê†™‰æ°.*', r'.*„ÅÑ„Åè„Çâ.*', r'.*ÂÄ§ÊÆµ.*',
                r'.*price.*', r'.*cost.*', r'.*worth.*'
            ],
            'prediction_request': [
                r'.*‰∫àÊ∏¨.*', r'.*‰∫àÊÉ≥.*', r'.*Ë¶ãÈÄö„Åó.*', r'.*Â∞ÜÊù•.*',
                r'.*prediction.*', r'.*forecast.*', r'.*future.*'
            ],
            'analysis_request': [
                r'.*ÂàÜÊûê.*', r'.*Ë©ï‰æ°.*', r'.*„Å©„ÅÜÊÄù„ÅÜ.*', r'.*ÊÑèË¶ã.*',
                r'.*analysis.*', r'.*analyze.*', r'.*opinion.*'
            ],
            'recommendation_request': [
                r'.*„Åä„Åô„Åô„ÇÅ.*', r'.*Êé®Â•®.*', r'.*Ë≤∑„ÅÜ.*', r'.*Â£≤„Çã.*',
                r'.*recommend.*', r'.*suggest.*', r'.*buy.*', r'.*sell.*'
            ],
            'portfolio_inquiry': [
                r'.*„Éù„Éº„Éà„Éï„Ç©„É™„Ç™.*', r'.*Ë≥áÁî£ÈÖçÂàÜ.*', r'.*ÂàÜÊï£.*',
                r'.*portfolio.*', r'.*allocation.*', r'.*diversification.*'
            ],
            'risk_inquiry': [
                r'.*„É™„Çπ„ÇØ.*', r'.*Âç±Èô∫.*', r'.*ÂÆâÂÖ®.*', r'.*volatility.*',
                r'.*risk.*', r'.*safe.*', r'.*danger.*'
            ]
        }

        self.entity_patterns = {
            'stock_symbols': r'\b([A-Z]{1,5})\b',
            'companies': [
                'Apple', 'Google', 'Microsoft', 'Tesla', 'Amazon',
                '„Ç¢„ÉÉ„Éó„É´', '„Ç∞„Éº„Ç∞„É´', '„Éû„Ç§„ÇØ„É≠„ÇΩ„Éï„Éà', '„ÉÜ„Çπ„É©', '„Ç¢„Éû„Çæ„É≥'
            ],
            'numbers': r'\$?(\d{1,3}(?:,\d{3})*(?:\.\d{2})?)',
            'time_periods': [
                '‰ªäÊó•', 'ÊòéÊó•', 'Êù•ÈÄ±', 'Êù•Êúà', '‰ªäÂπ¥',
                'today', 'tomorrow', 'next week', 'next month'
            ]
        }

        # TF-IDF for semantic similarity (if available)
        if SKLEARN_AVAILABLE:
            self.vectorizer = TfidfVectorizer(
                max_features=1000,
                stop_words='english',
                ngram_range=(1, 2)
            )
            self._trained = False

    def analyze_query(self, query: UserQuery) -> UserQuery:
        """„ÇØ„Ç®„É™ÂàÜÊûê"""
        logger.info(f"üìù „ÇØ„Ç®„É™ÂàÜÊûê: {query.text[:50]}...")

        # ÊÑèÂõ≥ÂàÜÈ°û
        query.intent = self._classify_intent(query.text)

        # „Ç®„É≥„ÉÜ„Ç£„ÉÜ„Ç£ÊäΩÂá∫
        query.entities = self._extract_entities(query.text)

        logger.info(f"üéØ ÂàÜÊûêÁµêÊûú: ÊÑèÂõ≥={query.intent}, „Ç®„É≥„ÉÜ„Ç£„ÉÜ„Ç£={len(query.entities) if query.entities else 0}‰ª∂")
        return query

    def _classify_intent(self, text: str) -> str:
        """ÊÑèÂõ≥ÂàÜÈ°û"""
        text_lower = text.lower()

        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    return intent

        return 'general_inquiry'

    def _extract_entities(self, text: str) -> Dict[str, List[str]]:
        """„Ç®„É≥„ÉÜ„Ç£„ÉÜ„Ç£ÊäΩÂá∫"""
        entities = {}

        # Ê†™Âºè„Ç∑„É≥„Éú„É´
        symbols = re.findall(self.entity_patterns['stock_symbols'], text.upper())
        if symbols:
            entities['symbols'] = list(set(symbols))

        # ‰ºöÁ§æÂêç
        companies = []
        for company in self.entity_patterns['companies']:
            if company.lower() in text.lower():
                companies.append(company)
        if companies:
            entities['companies'] = companies

        # Êï∞ÂÄ§
        numbers = re.findall(self.entity_patterns['numbers'], text)
        if numbers:
            entities['numbers'] = numbers

        return entities

class MarketDataAnalyzer:
    """Â∏ÇÂ†¥„Éá„Éº„ÇøÂàÜÊûê„Ç®„É≥„Ç∏„É≥"""

    def __init__(self):
        self.db_config = {
            'host': "34.173.9.214",
            'database': "miraikakaku",
            'user': "postgres",
            'password': os.getenv('DB_PASSWORD')
        }

    def get_stock_analysis(self, symbol: str) -> Dict[str, Any]:
        """Ê†™ÂºèÂàÜÊûê„Éá„Éº„ÇøÂèñÂæó"""
        logger.info(f"üìä {symbol}„ÅÆÂàÜÊûê„Éá„Éº„ÇøÂèñÂæó‰∏≠...")

        try:
            conn = psycopg2.connect(**self.db_config)

            # ÊúÄÊñ∞‰æ°Ê†º„Éá„Éº„Çø
            price_query = """
            SELECT date, close_price, volume,
                   close_price - LAG(close_price) OVER (ORDER BY date) as price_change
            FROM stock_prices
            WHERE symbol = %s
            ORDER BY date DESC
            LIMIT 30
            """

            price_df = pd.read_sql_query(price_query, conn, params=[symbol])

            # ‰∫àÊ∏¨„Éá„Éº„Çø
            prediction_query = """
            SELECT prediction_date, predicted_price, confidence_score
            FROM stock_predictions
            WHERE symbol = %s
            AND prediction_date >= CURRENT_DATE
            ORDER BY prediction_date ASC
            LIMIT 10
            """

            prediction_df = pd.read_sql_query(prediction_query, conn, params=[symbol])

            conn.close()

            if price_df.empty:
                return {'error': f'{symbol}„ÅÆ„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì'}

            # ÂàÜÊûêË®àÁÆó
            analysis = self._calculate_technical_indicators(price_df)
            analysis['predictions'] = prediction_df.to_dict('records') if not prediction_df.empty else []
            analysis['symbol'] = symbol
            analysis['last_updated'] = datetime.now().isoformat()

            return analysis

        except Exception as e:
            logger.error(f"ÂàÜÊûê„Éá„Éº„ÇøÂèñÂæó„Ç®„É©„Éº: {e}")
            return {'error': str(e)}

    def _calculate_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:
        """„ÉÜ„ÇØ„Éã„Ç´„É´ÊåáÊ®ôË®àÁÆó"""
        if df.empty:
            return {}

        analysis = {}

        # Âü∫Êú¨Áµ±Ë®à
        latest_price = df.iloc[0]['close_price']
        analysis['current_price'] = float(latest_price)
        analysis['price_change_1d'] = float(df.iloc[0]['price_change']) if df.iloc[0]['price_change'] else 0

        # ÁßªÂãïÂπ≥Âùá
        df['ma_5'] = df['close_price'].rolling(5).mean()
        df['ma_20'] = df['close_price'].rolling(20).mean()

        analysis['ma_5'] = float(df.iloc[0]['ma_5']) if not pd.isna(df.iloc[0]['ma_5']) else None
        analysis['ma_20'] = float(df.iloc[0]['ma_20']) if not pd.isna(df.iloc[0]['ma_20']) else None

        # „Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£
        returns = df['close_price'].pct_change().dropna()
        analysis['volatility'] = float(returns.std()) * np.sqrt(252) if len(returns) > 1 else 0

        # RSIÈ¢®ÊåáÊ®ô
        gains = returns.where(returns > 0, 0)
        losses = -returns.where(returns < 0, 0)
        if len(gains) > 1 and len(losses) > 1:
            avg_gain = gains.mean()
            avg_loss = losses.mean()
            if avg_loss != 0:
                rs = avg_gain / avg_loss
                analysis['rsi_like'] = float(100 - (100 / (1 + rs)))
            else:
                analysis['rsi_like'] = 100

        # „Éà„É¨„É≥„ÉâÂàÜÊûê
        if len(df) >= 5:
            recent_trend = np.polyfit(range(5), df.iloc[:5]['close_price'].values, 1)[0]
            analysis['trend'] = 'up' if recent_trend > 0 else 'down'
            analysis['trend_strength'] = abs(float(recent_trend))

        return analysis

class InvestmentAdvisor:
    """ÊäïË≥á„Ç¢„Éâ„Éê„Ç§„Ç∂„Éº„Ç®„É≥„Ç∏„É≥"""

    def __init__(self):
        self.risk_profiles = {
            'conservative': {
                'volatility_threshold': 0.15,
                'recommended_allocation': {'stocks': 0.4, 'bonds': 0.5, 'cash': 0.1},
                'max_single_position': 0.05
            },
            'moderate': {
                'volatility_threshold': 0.25,
                'recommended_allocation': {'stocks': 0.6, 'bonds': 0.3, 'cash': 0.1},
                'max_single_position': 0.10
            },
            'aggressive': {
                'volatility_threshold': 0.35,
                'recommended_allocation': {'stocks': 0.8, 'bonds': 0.1, 'cash': 0.1},
                'max_single_position': 0.20
            }
        }

    def generate_recommendation(
        self,
        query: UserQuery,
        analysis_data: Dict[str, Any],
        user_profile: Optional[InvestmentProfile] = None
    ) -> List[str]:
        """ÊäïË≥áÊé®Â•®ÁîüÊàê"""

        recommendations = []

        if 'error' in analysis_data:
            recommendations.append("Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®„Éá„Éº„Çø„ÇíÂèñÂæó„Åß„Åç„Åæ„Åõ„Çì„ÄÇ")
            return recommendations

        symbol = analysis_data.get('symbol', 'Unknown')
        current_price = analysis_data.get('current_price', 0)
        volatility = analysis_data.get('volatility', 0)
        trend = analysis_data.get('trend', 'neutral')

        # „É™„Çπ„ÇØË©ï‰æ°
        risk_level = self._assess_risk_level(analysis_data, user_profile)

        if query.intent == 'recommendation_request':
            if trend == 'up' and risk_level == 'low':
                recommendations.append(f"{symbol}„ÅØ‰∏äÊòá„Éà„É¨„É≥„Éâ„Åã„Å§‰Ωé„É™„Çπ„ÇØ„Åß„ÄÅÊäïË≥áÊ§úË®é„Å´ÂÄ§„Åó„Åæ„Åô„ÄÇ")
            elif trend == 'down' or risk_level == 'high':
                recommendations.append(f"{symbol}„ÅØÁèæÂú®„É™„Çπ„ÇØ„ÅåÈ´ò„ÅÑ„Åü„ÇÅ„ÄÅÊÖéÈáç„Å™Âà§Êñ≠„Çí„ÅäÂãß„ÇÅ„Åó„Åæ„Åô„ÄÇ")
            else:
                recommendations.append(f"{symbol}„ÅØ‰∏≠Á´ãÁöÑ„Å™Áä∂Ê≥Å„Åß„Åô„ÄÇ‰ªñ„ÅÆÊäïË≥áÊ©ü‰ºö„Å®ÊØîËºÉÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

        elif query.intent == 'risk_inquiry':
            if volatility > 0.3:
                recommendations.append(f"{symbol}„ÅØÈ´ò„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£Ôºà{volatility:.1%}Ôºâ„ÅÆ„Åü„ÇÅ„ÄÅ„É™„Çπ„ÇØÁÆ°ÁêÜ„ÅåÈáçË¶Å„Åß„Åô„ÄÇ")
            else:
                recommendations.append(f"{symbol}„ÅØÊØîËºÉÁöÑÂÆâÂÆöÁöÑ„Å™ÂÄ§Âãï„ÅçÔºà„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£{volatility:.1%}Ôºâ„ÇíÁ§∫„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ")

        elif query.intent == 'prediction_request':
            predictions = analysis_data.get('predictions', [])
            if predictions:
                next_pred = predictions[0]
                recommendations.append(f"AI„É¢„Éá„É´„ÅØ{symbol}„ÅÆÊ¨°Êúü‰∫àÊ∏¨‰æ°Ê†º„Çí${next_pred['predicted_price']:.2f}„Å®‰∫àÊ∏¨„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ")
                recommendations.append(f"‰∫àÊ∏¨‰ø°È†ºÂ∫¶: {next_pred['confidence_score']:.1%}")

        # „Éù„Éº„Éà„Éï„Ç©„É™„Ç™Èñ¢ÈÄ£„Ç¢„Éâ„Éê„Ç§„Çπ
        if user_profile and query.intent == 'portfolio_inquiry':
            profile_rec = self._generate_portfolio_advice(user_profile, analysis_data)
            recommendations.extend(profile_rec)

        return recommendations

    def _assess_risk_level(
        self,
        analysis_data: Dict[str, Any],
        user_profile: Optional[InvestmentProfile]
    ) -> str:
        """„É™„Çπ„ÇØ„É¨„Éô„É´Ë©ï‰æ°"""
        volatility = analysis_data.get('volatility', 0)

        # „Éá„Éï„Ç©„É´„ÉàÈñæÂÄ§
        thresholds = self.risk_profiles['moderate']

        if user_profile and user_profile.risk_tolerance in self.risk_profiles:
            thresholds = self.risk_profiles[user_profile.risk_tolerance]

        if volatility > thresholds['volatility_threshold']:
            return 'high'
        elif volatility < thresholds['volatility_threshold'] * 0.6:
            return 'low'
        else:
            return 'medium'

    def _generate_portfolio_advice(
        self,
        profile: InvestmentProfile,
        analysis_data: Dict[str, Any]
    ) -> List[str]:
        """„Éù„Éº„Éà„Éï„Ç©„É™„Ç™„Ç¢„Éâ„Éê„Ç§„ÇπÁîüÊàê"""
        advice = []

        risk_config = self.risk_profiles.get(profile.risk_tolerance, self.risk_profiles['moderate'])

        advice.append(f"„ÅÇ„Å™„Åü„ÅÆ{profile.risk_tolerance}„É™„Çπ„ÇØ„Éó„É≠„Éï„Ç°„Ç§„É´„Å´Âü∫„Å•„ÅèÊé®Â•®Ë≥áÁî£ÈÖçÂàÜ:")
        for asset, ratio in risk_config['recommended_allocation'].items():
            advice.append(f"- {asset}: {ratio:.0%}")

        advice.append(f"Âçò‰∏ÄÈäòÊüÑ„ÅÆÊúÄÂ§ßÊäïË≥áÊØîÁéá: {risk_config['max_single_position']:.0%}")

        return advice

class AIAssistantEngine:
    """AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„É°„Ç§„É≥„Ç®„É≥„Ç∏„É≥"""

    def __init__(self):
        self.nlp = NaturalLanguageProcessor()
        self.market_analyzer = MarketDataAnalyzer()
        self.investment_advisor = InvestmentAdvisor()

        # ÂøúÁ≠î„ÉÜ„É≥„Éó„É¨„Éº„Éà
        self.response_templates = {
            'greeting': [
                "„Åì„Çì„Å´„Å°„ÅØÔºÅÊäïË≥á„Å´Èñ¢„Åô„Çã„ÅîË≥™Âïè„Å´„ÅäÁ≠î„Åà„Åó„Åæ„Åô„ÄÇ",
                "Miraikakaku AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Åß„Åô„ÄÇ„Å©„ÅÆ„Çà„ÅÜ„Å™„Çµ„Éù„Éº„Éà„Çí„ÅäÊ±Ç„ÇÅ„Åß„Åô„ÅãÔºü"
            ],
            'price_inquiry': [
                "ÊúÄÊñ∞„ÅÆ‰æ°Ê†ºÊÉÖÂ†±„Çí„ÅäË™ø„Åπ„Åó„Åæ„Åô„ÄÇ",
                "‰æ°Ê†º„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Å¶„ÅÑ„Åæ„Åô..."
            ],
            'analysis_complete': [
                "ÂàÜÊûê„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ",
                "‰ª•‰∏ã„ÅåÂàÜÊûêÁµêÊûú„Åß„ÅôÔºö"
            ]
        }

    def process_query(
        self,
        query_text: str,
        user_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> AssistantResponse:
        """„É°„Ç§„É≥„ÇØ„Ç®„É™Âá¶ÁêÜ"""

        logger.info(f"ü§ñ AI„Ç¢„Ç∑„Çπ„Çø„É≥„ÉàÂá¶ÁêÜÈñãÂßã: {query_text[:50]}...")

        # „ÇØ„Ç®„É™Ê∫ñÂÇô
        query = UserQuery(
            text=query_text,
            user_id=user_id,
            timestamp=datetime.now(),
            context=context or {}
        )

        # Ëá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜ
        query = self.nlp.analyze_query(query)

        # „É¨„Çπ„Éù„É≥„ÇπÁîüÊàê
        response = self._generate_response(query)

        logger.info(f"‚úÖ ÂøúÁ≠îÁîüÊàêÂÆå‰∫Ü: ‰ø°È†ºÂ∫¶{response.confidence:.2f}")
        return response

    def _generate_response(self, query: UserQuery) -> AssistantResponse:
        """„É¨„Çπ„Éù„É≥„ÇπÁîüÊàê"""

        response_text = ""
        confidence = 0.7
        suggested_actions = []
        related_stocks = []
        data_sources = []
        reasoning = []

        try:
            # Êå®Êã∂„Éª‰∏ÄËà¨ÁöÑ„Å™Ë≥™Âïè
            if any(greeting in query.text.lower() for greeting in ['„Åì„Çì„Å´„Å°„ÅØ', 'hello', 'hi', '„ÅØ„Åò„ÇÅ„Åæ„Åó„Å¶']):
                response_text = "„Åì„Çì„Å´„Å°„ÅØÔºÅMiraikakaku AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Åß„Åô„ÄÇÊ†™ÂºèÊäïË≥á„Å´Èñ¢„Åô„Çã„ÅîË≥™Âïè„Å´„ÅäÁ≠î„Åà„Åó„Åæ„Åô„ÄÇÈäòÊüÑÂàÜÊûê„ÄÅÂ∏ÇÂ†¥‰∫àÊ∏¨„ÄÅÊäïË≥á„Ç¢„Éâ„Éê„Ç§„Çπ„Å™„Å©„ÄÅ„ÅäÊ∞óËªΩ„Å´„ÅäÂ∞ã„Å≠„Åè„Å†„Åï„ÅÑ„ÄÇ"
                confidence = 0.95

            # Ê†™ÂºèÈñ¢ÈÄ£„ÅÆË≥™Âïè
            elif query.entities and 'symbols' in query.entities:
                symbol = query.entities['symbols'][0]
                related_stocks = [symbol]

                # Â∏ÇÂ†¥„Éá„Éº„ÇøÂàÜÊûê
                analysis_data = self.market_analyzer.get_stock_analysis(symbol)
                data_sources = ['market_data', 'predictions']

                if 'error' not in analysis_data:
                    # Âü∫Êú¨ÊÉÖÂ†±
                    current_price = analysis_data.get('current_price', 0)
                    price_change = analysis_data.get('price_change_1d', 0)
                    volatility = analysis_data.get('volatility', 0)

                    response_text = f"{symbol}„ÅÆÂàÜÊûêÁµêÊûúÔºö\n"
                    response_text += f"ÁèæÂú®‰æ°Ê†º: ${current_price:.2f}\n"
                    response_text += f"1Êó•Â§âÂãï: {price_change:+.2f} ({price_change/current_price*100:+.1f}%)\n"
                    response_text += f"Âπ¥Èñì„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£: {volatility:.1%}\n"

                    # „Éà„É¨„É≥„ÉâÊÉÖÂ†±
                    trend = analysis_data.get('trend')
                    if trend:
                        trend_desc = "‰∏äÊòáÂÇæÂêë" if trend == 'up' else "‰∏ãÈôçÂÇæÂêë"
                        response_text += f"Áü≠Êúü„Éà„É¨„É≥„Éâ: {trend_desc}\n"

                    # ÊäïË≥á„Ç¢„Éâ„Éê„Ç§„Çπ
                    recommendations = self.investment_advisor.generate_recommendation(
                        query, analysis_data
                    )

                    if recommendations:
                        response_text += "\nüìã ÊäïË≥á„Ç¢„Éâ„Éê„Ç§„Çπ:\n"
                        for rec in recommendations:
                            response_text += f"‚Ä¢ {rec}\n"

                    confidence = 0.85
                    reasoning = [
                        f"ÊúÄÊñ∞„ÅÆÂ∏ÇÂ†¥„Éá„Éº„Çø„ÇíÂàÜÊûê",
                        f"„ÉÜ„ÇØ„Éã„Ç´„É´ÊåáÊ®ô„ÇíË®àÁÆó",
                        f"AI„É¢„Éá„É´„Å´„Çà„Çã‰∫àÊ∏¨„ÇíËÄÉÊÖÆ"
                    ]

                    # Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥
                    if query.intent == 'recommendation_request':
                        if analysis_data.get('trend') == 'up':
                            suggested_actions = ["Ë©≥Á¥∞ÂàÜÊûê„ÅÆÂÆüË°å", "„É™„Çπ„ÇØË©ï‰æ°„ÅÆÁ¢∫Ë™ç", "„Éù„Éº„Éà„Éï„Ç©„É™„Ç™ÂΩ±Èüø„ÅÆÊ§úË®é"]
                        else:
                            suggested_actions = ["Â∏ÇÂ†¥ÂãïÂêë„ÅÆÁ∂ôÁ∂öÁõ£Ë¶ñ", "‰ª£ÊõøÊäïË≥áÊ©ü‰ºö„ÅÆÊé¢Á¥¢"]

                else:
                    response_text = f"Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„ÄÇ{symbol}„ÅÆ„Éá„Éº„Çø„ÇíÂèñÂæó„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ"
                    confidence = 0.3

            # ‰∏ÄËà¨ÁöÑ„Å™ÊäïË≥áÁõ∏Ë´á
            elif query.intent == 'portfolio_inquiry':
                response_text = """„Éù„Éº„Éà„Éï„Ç©„É™„Ç™ÊúÄÈÅ©Âåñ„ÅÆ„Åü„ÇÅ„ÅÆÂü∫Êú¨ÂéüÂâáÔºö

1. **ÂàÜÊï£ÊäïË≥á**: „É™„Çπ„ÇØ„ÇíË§áÊï∞„ÅÆË≥áÁî£„Å´ÂàÜÊï£
2. **Ë≥áÁî£ÈÖçÂàÜ**: Âπ¥ÈΩ¢„Å®ÊäïË≥áÁõÆÊ®ô„Å´Âøú„Åò„ÅüÊ†™Âºè„ÉªÂÇµÂà∏„ÅÆÊØîÁéá
3. **ÂÆöÊúüÁöÑ„Å™„É™„Éê„É©„É≥„Çπ**: ÁõÆÊ®ôÈÖçÂàÜ„ÅÆÁ∂≠ÊåÅ
4. **Èï∑ÊúüÊäïË≥á**: Â∏ÇÂ†¥„ÅÆÁü≠ÊúüÂ§âÂãï„Å´ÊÉë„Çè„Åï„Çå„Å™„ÅÑ

ÂÖ∑‰ΩìÁöÑ„Å™ÈäòÊüÑ„Å´„Å§„ÅÑ„Å¶„ÅäËÅû„Åç„Å´„Å™„Çä„Åü„ÅÑÂ†¥Âêà„ÅØ„ÄÅÈäòÊüÑ„Ç≥„Éº„ÉâÔºà‰æãÔºöAAPL„ÄÅGOOGLÔºâ„ÇíÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"""
                confidence = 0.8
                suggested_actions = ["ÂÖ∑‰ΩìÁöÑ„Å™ÈäòÊüÑ„ÅÆÁõ∏Ë´á", "„É™„Çπ„ÇØË®±ÂÆπÂ∫¶„ÅÆË®∫Êñ≠", "ÊäïË≥áÁõÆÊ®ô„ÅÆË®≠ÂÆö"]

            elif query.intent == 'risk_inquiry':
                response_text = """ÊäïË≥á„É™„Çπ„ÇØÁÆ°ÁêÜ„ÅÆ„Éù„Ç§„É≥„ÉàÔºö

üî¥ **È´ò„É™„Çπ„ÇØË¶ÅÂõ†**:
‚Ä¢ È´ò„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ÈäòÊüÑÔºàÂπ¥Èñì30%‰ª•‰∏ä„ÅÆ‰æ°Ê†ºÂ§âÂãïÔºâ
‚Ä¢ ÈõÜ‰∏≠ÊäïË≥áÔºàÂçò‰∏ÄÈäòÊüÑ„Å∏„ÅÆÂÅèÈáçÔºâ
‚Ä¢ Áü≠ÊúüÂ£≤Ë≤∑

üü° **„É™„Çπ„ÇØËªΩÊ∏õÁ≠ñ**:
‚Ä¢ ÂàÜÊï£ÊäïË≥á„Å´„Çà„Çã„É™„Çπ„ÇØÂàÜÊï£
‚Ä¢ ÊêçÂàá„Çä„É´„Éº„É´„ÅÆË®≠ÂÆö
‚Ä¢ ÊäïË≥áÈáëÈ°ç„ÅÆÈÅ©Âàá„Å™ÁÆ°ÁêÜ

ÂÖ∑‰ΩìÁöÑ„Å™ÈäòÊüÑ„ÅÆ„É™„Çπ„ÇØË©ï‰æ°„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅÈäòÊüÑ„Ç≥„Éº„Éâ„Çí„ÅäÊïô„Åà„Åè„Å†„Åï„ÅÑ„ÄÇ"""
                confidence = 0.75

            else:
                # „Éá„Éï„Ç©„É´„ÉàÂøúÁ≠î
                response_text = """‰ª•‰∏ã„Å´„Å§„ÅÑ„Å¶„Çµ„Éù„Éº„Éà„Åß„Åç„Åæ„ÅôÔºö

üìà **Â∏ÇÂ†¥ÂàÜÊûê**: ÈäòÊüÑ„Ç≥„Éº„ÉâÔºàAAPL„ÄÅGOOGL„Å™„Å©Ôºâ„ÇíÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ
üéØ **ÊäïË≥á„Ç¢„Éâ„Éê„Ç§„Çπ**: „ÄåAAPL„ÇíË≤∑„ÅÜ„Åπ„Åç„Åß„Åô„ÅãÔºü„Äç„ÅÆ„Çà„ÅÜ„Å™Ë≥™Âïè
üìä **„É™„Çπ„ÇØÂàÜÊûê**: „ÄåTSLA„ÅÆ„É™„Çπ„ÇØ„ÅØÔºü„Äç„ÅÆ„Çà„ÅÜ„Å™Ë≥™Âïè
üíº **„Éù„Éº„Éà„Éï„Ç©„É™„Ç™Áõ∏Ë´á**: Ë≥áÁî£ÈÖçÂàÜ„ÇÑÂàÜÊï£ÊäïË≥á„Å´„Å§„ÅÑ„Å¶

‰Ωï„Å´„Å§„ÅÑ„Å¶„ÅäÁü•„Çä„Å´„Å™„Çä„Åü„ÅÑ„Åß„Åô„ÅãÔºü"""
                confidence = 0.6

        except Exception as e:
            logger.error(f"ÂøúÁ≠îÁîüÊàê„Ç®„É©„Éº: {e}")
            response_text = "Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„ÄÇÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ„ÇÇ„ÅÜ‰∏ÄÂ∫¶„ÅäË©¶„Åó„Åè„Å†„Åï„ÅÑ„ÄÇ"
            confidence = 0.2

        return AssistantResponse(
            response_text=response_text,
            confidence=confidence,
            response_type=query.intent or 'general',
            data_sources=data_sources,
            suggested_actions=suggested_actions,
            related_stocks=related_stocks,
            charts_data=None,
            timestamp=datetime.now(),
            reasoning=reasoning
        )

def main():
    """„ÉÜ„Çπ„ÉàÂÆüË°å"""
    logger.info("ü§ñ AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Ç∑„Çπ„ÉÜ„É†ÈñãÂßã")

    assistant = AIAssistantEngine()

    # „ÉÜ„Çπ„Éà„ÇØ„Ç®„É™
    test_queries = [
        "„Åì„Çì„Å´„Å°„ÅØ",
        "AAPL„ÅÆÊ†™‰æ°„ÅØ„Å©„ÅÜ„Åß„Åô„ÅãÔºü",
        "TSLA„ÇíË≤∑„ÅÜ„Åπ„Åç„Åß„Åó„Çá„ÅÜ„ÅãÔºü",
        "„Éù„Éº„Éà„Éï„Ç©„É™„Ç™„ÅÆÂàÜÊï£„Å´„Å§„ÅÑ„Å¶Êïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ",
        "MSFT„ÅÆ„É™„Çπ„ÇØ„ÇíÊïô„Åà„Å¶",
        "ÊäïË≥áÂàùÂøÉËÄÖ„Å´„Åä„Åô„Åô„ÇÅ„ÅÆÈäòÊüÑ„ÅØÔºü"
    ]

    for query in test_queries:
        logger.info(f"\n{'='*50}")
        logger.info(f"Ë≥™Âïè: {query}")
        logger.info(f"{'='*50}")

        response = assistant.process_query(query)

        print(f"ü§ñ AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà:")
        print(response.response_text)
        print(f"\n‰ø°È†ºÂ∫¶: {response.confidence:.2f}")
        print(f"ÂøúÁ≠î„Çø„Ç§„Éó: {response.response_type}")

        if response.suggested_actions:
            print(f"Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥: {', '.join(response.suggested_actions)}")

        if response.related_stocks:
            print(f"Èñ¢ÈÄ£ÈäòÊüÑ: {', '.join(response.related_stocks)}")

        print("\n" + "="*50 + "\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("üëã AI„Ç¢„Ç∑„Çπ„Çø„É≥„ÉàÁµÇ‰∫Ü")
    except Exception as e:
        logger.error(f"ÂÆüË°å„Ç®„É©„Éº: {e}")
        sys.exit(1)