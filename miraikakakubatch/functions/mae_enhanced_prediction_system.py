#!/usr/bin/env python3
"""
MAEå¼·åŒ–äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®MAEã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨ã™ã‚‹äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
"""

import pymysql
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MAEEnhancedPredictionSystem:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
        }
        self.mae_history = {}  # éŠ˜æŸ„åˆ¥MAEå±¥æ­´
        self.prediction_models = {}  # éŠ˜æŸ„åˆ¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        
    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def calculate_historical_mae_features(self, symbol: str, days_back: int = 30) -> Dict:
        """
        ç‰¹å®šéŠ˜æŸ„ã®éå»MAEç‰¹å¾´é‡ã‚’è¨ˆç®—
        """
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # éå»ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã¨å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                cursor.execute("""
                    SELECT 
                        sp.prediction_date,
                        sp.predicted_price,
                        sp.model_type,
                        sp.confidence_score,
                        sph.close_price as actual_price
                    FROM stock_predictions sp
                    JOIN stock_price_history sph ON (
                        sp.symbol = sph.symbol 
                        AND DATE(sp.prediction_date) = DATE(sph.date)
                    )
                    WHERE sp.symbol = %s
                    AND sp.prediction_date >= DATE_SUB(NOW(), INTERVAL %s DAY)
                    AND sp.prediction_date < NOW()
                    ORDER BY sp.prediction_date DESC
                """, (symbol, days_back))
                
                historical_data = cursor.fetchall()
                
                if not historical_data:
                    return {
                        'recent_mae': 0.0,
                        'mae_trend': 0.0,
                        'prediction_count': 0,
                        'model_consistency': 0.0,
                        'confidence_correlation': 0.0
                    }
                
                # MAEè¨ˆç®—ã¨ç‰¹å¾´é‡æŠ½å‡º
                mae_values = []
                confidences = []
                model_types = []
                dates = []
                
                for pred_date, pred_price, model_type, confidence, actual_price in historical_data:
                    mae = abs(pred_price - actual_price)
                    mae_values.append(mae)
                    confidences.append(confidence)
                    model_types.append(model_type)
                    dates.append(pred_date)
                
                # ç‰¹å¾´é‡è¨ˆç®—
                recent_mae = np.mean(mae_values[-7:]) if len(mae_values) >= 7 else np.mean(mae_values)
                
                # MAE ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæœ€è¿‘7æ—¥ vs å‰æœŸé–“ã®æ¯”è¼ƒï¼‰
                if len(mae_values) >= 14:
                    recent_period_mae = np.mean(mae_values[-7:])
                    previous_period_mae = np.mean(mae_values[-14:-7])
                    mae_trend = (recent_period_mae - previous_period_mae) / previous_period_mae
                else:
                    mae_trend = 0.0
                
                # ãƒ¢ãƒ‡ãƒ«ä¸€è²«æ€§ï¼ˆåŒã˜ãƒ¢ãƒ‡ãƒ«ãŒé€£ç¶šã—ã¦è‰¯ã„äºˆæ¸¬ã‚’ã—ã¦ã„ã‚‹ã‹ï¼‰
                model_consistency = len(set(model_types[-5:])) / 5.0 if len(model_types) >= 5 else 0.5
                
                # ä¿¡é ¼åº¦ã¨MAEã®ç›¸é–¢
                if len(mae_values) > 3:
                    confidence_correlation = np.corrcoef(confidences, mae_values)[0, 1]
                    if np.isnan(confidence_correlation):
                        confidence_correlation = 0.0
                else:
                    confidence_correlation = 0.0
                
                return {
                    'recent_mae': recent_mae,
                    'mae_trend': mae_trend,
                    'prediction_count': len(mae_values),
                    'model_consistency': 1.0 - model_consistency,  # ä¸€è²«æ€§ãŒé«˜ã„ã»ã©è‰¯ã„
                    'confidence_correlation': -confidence_correlation  # è² ã®ç›¸é–¢ãŒè‰¯ã„ï¼ˆä¿¡é ¼åº¦é«˜ã„=MAEä½ã„ï¼‰
                }
                
        finally:
            connection.close()

    def get_market_context_features(self, symbol: str) -> Dict:
        """
        å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’å–å¾—
        """
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # æœ€è¿‘ã®ä¾¡æ ¼ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                cursor.execute("""
                    SELECT close_price, date
                    FROM stock_price_history
                    WHERE symbol = %s
                    AND date >= DATE_SUB(NOW(), INTERVAL 30 DAY)
                    ORDER BY date DESC
                    LIMIT 30
                """, (symbol,))
                
                price_data = cursor.fetchall()
                
                if len(price_data) < 5:
                    return {
                        'volatility': 0.0,
                        'price_trend': 0.0,
                        'recent_volume_trend': 0.0
                    }
                
                prices = [float(row[0]) for row in price_data]
                
                # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ï¼ˆæ¨™æº–åå·® / å¹³å‡ï¼‰
                volatility = np.std(prices) / np.mean(prices) if np.mean(prices) > 0 else 0.0
                
                # ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæœ€è¿‘5æ—¥ vs å‰5æ—¥ï¼‰
                if len(prices) >= 10:
                    recent_avg = np.mean(prices[:5])
                    previous_avg = np.mean(prices[5:10])
                    price_trend = (recent_avg - previous_avg) / previous_avg
                else:
                    price_trend = 0.0
                
                return {
                    'volatility': volatility,
                    'price_trend': price_trend,
                    'recent_volume_trend': 0.0  # ç°¡æ˜“å®Ÿè£…ï¼ˆå¾Œã§æ‹¡å¼µå¯èƒ½ï¼‰
                }
                
        finally:
            connection.close()

    def build_mae_enhanced_features(self, symbol: str) -> np.ndarray:
        """
        MAEå¼·åŒ–ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«æ§‹ç¯‰
        """
        # éå»MAEç‰¹å¾´é‡
        mae_features = self.calculate_historical_mae_features(symbol)
        
        # å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡
        market_features = self.get_market_context_features(symbol)
        
        # ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«çµ„ã¿ç«‹ã¦
        feature_vector = np.array([
            mae_features['recent_mae'],
            mae_features['mae_trend'],
            mae_features['prediction_count'],
            mae_features['model_consistency'],
            mae_features['confidence_correlation'],
            market_features['volatility'],
            market_features['price_trend'],
            market_features['recent_volume_trend']
        ])
        
        return feature_vector

    def train_mae_enhanced_model(self, symbol: str, historical_days: int = 60):
        """
        MAEå¼·åŒ–ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        """
        logger.info(f"ğŸ§  {symbol} ã®MAEå¼·åŒ–ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿å–å¾—
                cursor.execute("""
                    SELECT 
                        sph.date,
                        sph.close_price,
                        sph.open_price,
                        sph.high_price,
                        sph.low_price,
                        sph.volume
                    FROM stock_price_history sph
                    WHERE sph.symbol = %s
                    AND sph.date >= DATE_SUB(NOW(), INTERVAL %s DAY)
                    ORDER BY sph.date
                """, (symbol, historical_days))
                
                price_history = cursor.fetchall()
                
                if len(price_history) < 10:
                    logger.warning(f"âš ï¸ {symbol}: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
                    return None
                
                # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæº–å‚™
                X, y = self.prepare_training_data(symbol, price_history)
                
                if len(X) < 5:
                    logger.warning(f"âš ï¸ {symbol}: ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
                    return None
                
                # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
                model = RandomForestRegressor(
                    n_estimators=50,
                    max_depth=10,
                    random_state=42,
                    n_jobs=-1
                )
                
                # ç‰¹å¾´é‡æ¨™æº–åŒ–
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                
                # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
                model.fit(X_scaled, y)
                
                # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
                self.prediction_models[symbol] = {
                    'model': model,
                    'scaler': scaler,
                    'feature_names': [
                        'recent_mae', 'mae_trend', 'prediction_count', 
                        'model_consistency', 'confidence_correlation',
                        'volatility', 'price_trend', 'volume_trend',
                        'price_change_1d', 'price_change_7d', 'volume_ratio'
                    ],
                    'trained_at': datetime.now()
                }
                
                logger.info(f"âœ… {symbol} ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
                return model
                
        finally:
            connection.close()

    def prepare_training_data(self, symbol: str, price_history: List[Tuple]) -> Tuple[np.ndarray, np.ndarray]:
        """
        è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™
        """
        X = []
        y = []
        
        for i in range(7, len(price_history) - 1):  # 7æ—¥åˆ†ã®å±¥æ­´ + 1æ—¥å…ˆã®äºˆæ¸¬
            # åŸºæœ¬MAEç‰¹å¾´é‡
            mae_features = self.build_mae_enhanced_features(symbol)
            
            # ä¾¡æ ¼ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡
            current_price = float(price_history[i][1])
            prev_price_1d = float(price_history[i-1][1])
            prev_price_7d = float(price_history[i-7][1])
            
            price_change_1d = (current_price - prev_price_1d) / prev_price_1d
            price_change_7d = (current_price - prev_price_7d) / prev_price_7d
            
            current_volume = float(price_history[i][5])
            avg_volume_7d = np.mean([float(price_history[j][5]) for j in range(i-6, i+1)])
            volume_ratio = current_volume / avg_volume_7d if avg_volume_7d > 0 else 1.0
            
            # ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«æ§‹ç¯‰
            feature_vector = np.concatenate([
                mae_features,
                [price_change_1d, price_change_7d, volume_ratio]
            ])
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆç¿Œæ—¥ã®ä¾¡æ ¼ï¼‰
            next_day_price = float(price_history[i+1][1])
            
            X.append(feature_vector)
            y.append(next_day_price)
        
        return np.array(X), np.array(y)

    def predict_with_mae_enhancement(self, symbol: str) -> Dict:
        """
        MAEå¼·åŒ–äºˆæ¸¬å®Ÿè¡Œ
        """
        if symbol not in self.prediction_models:
            logger.warning(f"âš ï¸ {symbol}: ãƒ¢ãƒ‡ãƒ«æœªè¨“ç·´ã€è¨“ç·´ã‚’å®Ÿè¡Œä¸­...")
            model = self.train_mae_enhanced_model(symbol)
            if model is None:
                return None
        
        model_info = self.prediction_models[symbol]
        model = model_info['model']
        scaler = model_info['scaler']
        
        # ç¾åœ¨ã®ç‰¹å¾´é‡å–å¾—
        current_features = self.build_mae_enhanced_features(symbol)
        
        # æœ€æ–°ä¾¡æ ¼æƒ…å ±å–å¾—
        connection = self.get_connection()
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT close_price, volume, date
                    FROM stock_price_history
                    WHERE symbol = %s
                    ORDER BY date DESC
                    LIMIT 7
                """, (symbol,))
                
                recent_data = cursor.fetchall()
                
                if len(recent_data) < 2:
                    return None
                
                current_price = float(recent_data[0][0])
                prev_price = float(recent_data[1][0])
                price_change_1d = (current_price - prev_price) / prev_price
                
                if len(recent_data) >= 7:
                    week_ago_price = float(recent_data[6][0])
                    price_change_7d = (current_price - week_ago_price) / week_ago_price
                else:
                    price_change_7d = 0.0
                
                current_volume = float(recent_data[0][1])
                avg_volume = np.mean([float(row[1]) for row in recent_data])
                volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1.0
                
        finally:
            connection.close()
        
        # å®Œå…¨ãªç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«æ§‹ç¯‰
        full_features = np.concatenate([
            current_features,
            [price_change_1d, price_change_7d, volume_ratio]
        ])
        
        # äºˆæ¸¬å®Ÿè¡Œ
        features_scaled = scaler.transform([full_features])
        predicted_price = model.predict(features_scaled)[0]
        
        # äºˆæ¸¬ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹ã®å‹•çš„ä¿¡é ¼åº¦ï¼‰
        mae_based_confidence = self.calculate_mae_based_confidence(symbol, current_features)
        
        result = {
            'symbol': symbol,
            'predicted_price': predicted_price,
            'current_price': current_price,
            'predicted_change': predicted_price - current_price,
            'predicted_change_percent': ((predicted_price - current_price) / current_price) * 100,
            'mae_enhanced_confidence': mae_based_confidence,
            'model_type': 'mae_enhanced_rf',
            'features_used': model_info['feature_names'],
            'prediction_timestamp': datetime.now()
        }
        
        return result

    def calculate_mae_based_confidence(self, symbol: str, features: np.ndarray) -> float:
        """
        MAEãƒ™ãƒ¼ã‚¹ã®å‹•çš„ä¿¡é ¼åº¦è¨ˆç®—
        """
        recent_mae = features[0]  # recent_maeç‰¹å¾´é‡
        mae_trend = features[1]   # mae_trendç‰¹å¾´é‡
        model_consistency = features[3]  # model_consistencyç‰¹å¾´é‡
        
        # åŸºæœ¬ä¿¡é ¼åº¦ï¼ˆMAEãŒä½ã„ã»ã©é«˜ã„ï¼‰
        if recent_mae > 0:
            base_confidence = 1.0 / (1.0 + recent_mae / 10.0)  # 10ã§æ­£è¦åŒ–
        else:
            base_confidence = 0.9
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´ï¼ˆMAEãŒæ”¹å–„å‚¾å‘ãªã‚‰ä¿¡é ¼åº¦å‘ä¸Šï¼‰
        trend_adjustment = -mae_trend * 0.1  # ãƒˆãƒ¬ãƒ³ãƒ‰ãŒè² ï¼ˆæ”¹å–„ï¼‰ãªã‚‰æ­£ã®èª¿æ•´
        
        # ä¸€è²«æ€§èª¿æ•´
        consistency_adjustment = model_consistency * 0.1
        
        # æœ€çµ‚ä¿¡é ¼åº¦è¨ˆç®—
        final_confidence = base_confidence + trend_adjustment + consistency_adjustment
        
        # 0.3-0.95ã®ç¯„å›²ã«åˆ¶é™
        final_confidence = max(0.3, min(0.95, final_confidence))
        
        return round(final_confidence, 3)

    def run_mae_enhanced_batch_prediction(self, target_symbols: List[str] = None):
        """
        MAEå¼·åŒ–ãƒãƒƒãƒäºˆæ¸¬å®Ÿè¡Œ
        """
        start_time = datetime.now()
        logger.info(f"ğŸš€ MAEå¼·åŒ–ãƒãƒƒãƒäºˆæ¸¬é–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if target_symbols is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŠ˜æŸ„
            target_symbols = ['AAPL', 'MSFT', 'GOOGL', '7203', '6758', 'NVDA', 'AMZN']
        
        results = []
        success_count = 0
        
        for symbol in target_symbols:
            logger.info(f"ğŸ“Š {symbol} MAEå¼·åŒ–äºˆæ¸¬å®Ÿè¡Œä¸­...")
            
            try:
                # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                if symbol not in self.prediction_models:
                    self.train_mae_enhanced_model(symbol)
                
                # MAEå¼·åŒ–äºˆæ¸¬å®Ÿè¡Œ
                prediction_result = self.predict_with_mae_enhancement(symbol)
                
                if prediction_result:
                    results.append(prediction_result)
                    success_count += 1
                    
                    logger.info(f"âœ… {symbol}: Â¥{prediction_result['predicted_price']:.2f} "
                              f"({prediction_result['predicted_change_percent']:+.2f}%) "
                              f"[ä¿¡é ¼åº¦: {prediction_result['mae_enhanced_confidence']:.3f}]")
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                    self.save_mae_enhanced_prediction(prediction_result)
                else:
                    logger.warning(f"âš ï¸ {symbol}: äºˆæ¸¬å¤±æ•—")
                    
            except Exception as e:
                logger.error(f"âŒ {symbol} ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 80)
        logger.info("ğŸ“Š MAEå¼·åŒ–ãƒãƒƒãƒäºˆæ¸¬å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’")
        logger.info(f"ğŸ¯ å¯¾è±¡éŠ˜æŸ„: {len(target_symbols)}éŠ˜æŸ„")
        logger.info(f"âœ… æˆåŠŸ: {success_count}éŠ˜æŸ„")
        logger.info(f"âŒ å¤±æ•—: {len(target_symbols) - success_count}éŠ˜æŸ„")
        logger.info("=" * 80)
        
        return results

    def save_mae_enhanced_prediction(self, prediction_result: Dict):
        """
        MAEå¼·åŒ–äºˆæ¸¬çµæœä¿å­˜
        """
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    INSERT INTO stock_predictions 
                    (symbol, prediction_date, predicted_price, predicted_change_percent,
                     confidence_score, model_type, model_version, prediction_horizon,
                     created_at, is_active, notes)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), 1, %s)
                """, (
                    prediction_result['symbol'],
                    prediction_result['prediction_timestamp'] + timedelta(days=1),  # ç¿Œæ—¥äºˆæ¸¬
                    prediction_result['predicted_price'],
                    prediction_result['predicted_change_percent'],
                    prediction_result['mae_enhanced_confidence'],
                    prediction_result['model_type'],
                    'v3.0_mae_enhanced',
                    1,  # 1æ—¥å…ˆäºˆæ¸¬
                    f"MAE enhanced prediction using features: {', '.join(prediction_result['features_used'][:5])}"
                ))
                
                connection.commit()
                
        finally:
            connection.close()

if __name__ == "__main__":
    mae_predictor = MAEEnhancedPredictionSystem()
    
    try:
        # MAEå¼·åŒ–äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ
        results = mae_predictor.run_mae_enhanced_batch_prediction()
        
        # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        if results:
            logger.info("ğŸ¯ äºˆæ¸¬çµæœã‚µãƒãƒªãƒ¼:")
            for result in results:
                logger.info(f"  {result['symbol']}: "
                          f"ç¾åœ¨Â¥{result['current_price']:.2f} â†’ äºˆæ¸¬Â¥{result['predicted_price']:.2f} "
                          f"({result['predicted_change_percent']:+.2f}%) "
                          f"[ä¿¡é ¼åº¦:{result['mae_enhanced_confidence']:.3f}]")
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢")
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()