taskGroups:
  - taskSpec:
      runnables:
        - container:
            imageUri: "us-central1-docker.pkg.dev/pricewise-huqkr/miraikakaku-docker/batch-stable:latest"
            entrypoint: "/bin/bash"
            commands:
              - "-c"
              - |
                echo "ğŸš€ ç°¡å˜ãªäºˆæ¸¬ç”Ÿæˆãƒãƒƒãƒé–‹å§‹..."
                cd /app
                
                # è»½é‡ãªäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                python3 -c "
                import json
                from datetime import datetime, timedelta
                print('ğŸ”„ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒƒã‚¯å®Ÿè¡Œä¸­...')
                
                symbols = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'NVDA']
                models = ['LSTM_v1', 'XGBoost', 'Ensemble']
                
                total_predictions = 0
                for symbol in symbols:
                    for model in models:
                        for day in range(1, 4):  # 1-3æ—¥å¾Œ
                            prediction_date = datetime.now().date()
                            target_date = prediction_date + timedelta(days=day)
                            
                            prediction = {
                                'symbol': symbol,
                                'model': model,
                                'prediction_date': str(prediction_date),
                                'target_date': str(target_date),
                                'horizon_days': day
                            }
                            
                            total_predictions += 1
                
                print(f'âœ… äºˆæ¸¬ç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {total_predictions}ä»¶')
                print('ğŸ“Š å¯¾è±¡éŠ˜æŸ„:', ', '.join(symbols))
                print('ğŸ“ˆ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«:', ', '.join(models))
                
                # ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                with open('/tmp/predictions_test.json', 'w') as f:
                    json.dump({
                        'total_predictions': total_predictions,
                        'symbols': symbols,
                        'models': models,
                        'generated_at': str(datetime.now())
                    }, f)
                
                print('ğŸ’¾ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: /tmp/predictions_test.json')
                
                # Cloud Loggingã«çµæœå‡ºåŠ›
                print(f'ğŸ¯ ãƒãƒƒãƒå®Ÿè¡Œçµæœ:')
                print(f'  - äºˆæ¸¬ä»¶æ•°: {total_predictions}')
                print(f'  - éŠ˜æŸ„æ•°: {len(symbols)}')
                print(f'  - ãƒ¢ãƒ‡ãƒ«æ•°: {len(models)}')
                print('âœ… äºˆæ¸¬ç”Ÿæˆãƒãƒƒãƒå®Œäº†')
                "
                
                echo "ğŸ‰ ãƒãƒƒãƒå‡¦ç†å®Œäº†ï¼"
      computeResource:
        cpuMilli: "1000"
        memoryMib: "2048"
      maxRetryCount: 1
      maxRunDuration: "300s"
      environment:
        variables:
          BATCH_MODE: "predictions_test"
    taskCount: 1
    parallelism: 1

allocationPolicy:
  instances:
    - policy:
        machineType: "e2-standard-2"
  location:
    allowedLocations:
      - "regions/us-central1"

logsPolicy:
  destination: "CLOUD_LOGGING"

labels:
  app: "miraikakaku"
  type: "predictions-test"
  environment: "production"