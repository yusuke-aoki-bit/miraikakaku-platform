#!/usr/bin/env python3
"""
Enhanced Resource Cloud Batch LSTM System
ãƒªã‚½ãƒ¼ã‚¹å¢—å¼·ç‰ˆCloud Batchã‚·ã‚¹ãƒ†ãƒ ã§LSTM & VertexAIå®Ÿè¡Œ
"""

import os
import sys
import json
import time
import logging
import subprocess
from datetime import datetime, timedelta
from typing import Dict, Any
import tempfile

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedResourceBatch:
    """ãƒªã‚½ãƒ¼ã‚¹å¢—å¼·Cloud Batchã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, project_id="pricewise-huqkr", location="us-central1"):
        self.project_id = project_id
        self.location = location

    def create_high_resource_job(self) -> Dict[str, Any]:
        """é«˜ãƒªã‚½ãƒ¼ã‚¹ãƒ»è»½é‡åŒ–ãƒãƒƒãƒã‚¸ãƒ§ãƒ–"""

        # è»½é‡åŒ–ãƒ»é«˜é€ŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        script = '''#!/bin/bash
set -e
export DEBIAN_FRONTEND=noninteractive

echo "ğŸš€ Enhanced Resource LSTM & VertexAI System"
echo "é–‹å§‹æ™‚åˆ»: $(date)"
echo "=========================================="

# 1. é«˜é€Ÿã‚·ã‚¹ãƒ†ãƒ æº–å‚™
echo "âš¡ é«˜é€Ÿã‚·ã‚¹ãƒ†ãƒ æº–å‚™ä¸­..."
apt-get update -qq >/dev/null 2>&1
apt-get install -y python3-pip curl -qq >/dev/null 2>&1

# 2. é«˜é€Ÿpipè¨­å®š
echo "ğŸ“¦ é«˜é€Ÿãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip3 install --upgrade pip --quiet
pip3 install --no-cache-dir --quiet psycopg2-binary==2.9.9 numpy==1.24.4 pandas==2.1.4

# 3. TensorFlow CPUè»½é‡ç‰ˆ
echo "ğŸ§  TensorFlowè»½é‡ç‰ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip3 install --no-cache-dir --quiet tensorflow-cpu==2.13.0

# 4. Google Cloudè»½é‡ç‰ˆ
echo "ğŸ¤– VertexAIè»½é‡ç‰ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip3 install --no-cache-dir --quiet google-cloud-aiplatform==1.36.0

# 5. å®Ÿè¡Œæº–å‚™ç¢ºèª
echo "ğŸ” ç’°å¢ƒç¢ºèª..."
python3 -c "
import tensorflow as tf
import psycopg2
import numpy as np
import pandas as pd
print(f'âœ… TensorFlow: {tf.__version__}')
print('âœ… All packages loaded successfully')
"

# 6. è»½é‡LSTMäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ
echo "ğŸ§  è»½é‡LSTMäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œä¸­..."
python3 -c "
import os
import warnings
warnings.filterwarnings('ignore')

# ç’°å¢ƒæœ€é©åŒ–
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['OMP_NUM_THREADS'] = '8'
os.environ['TF_NUM_INTEROP_THREADS'] = '8'
os.environ['TF_NUM_INTRAOP_THREADS'] = '8'

import psycopg2
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler

# VertexAIï¼ˆè»½é‡ç‰ˆï¼‰
try:
    from google.cloud import aiplatform
    aiplatform.init(project='pricewise-huqkr', location='us-central1')
    vertexai_available = True
    print('âœ… VertexAI initialized')
except:
    vertexai_available = False
    print('âš ï¸ VertexAI unavailable, using basic mode')

print(f'ğŸ§  TensorFlow: {tf.__version__}')
print(f'ğŸ”§ CPU Threads: {tf.config.threading.get_inter_op_parallelism_threads()}')

def create_optimized_lstm_model(seq_len):
    \"\"\"Optimized lightweight LSTM model\"\"\"
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(32, return_sequences=False, input_shape=(seq_len, 1)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(16),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

def fast_lstm_predict(prices, days_ahead=1):
    \"\"\"Fast LSTM prediction\"\"\"
    try:
        if len(prices) < 8:
            return None, 0.3

        # é«˜é€Ÿãƒ‡ãƒ¼ã‚¿æº–å‚™
        scaler = MinMaxScaler()
        scaled = scaler.fit_transform(np.array(prices[-20:]).reshape(-1, 1))

        seq_len = min(8, len(scaled) - 1)
        X, y = [], []
        for i in range(seq_len, len(scaled)):
            X.append(scaled[i-seq_len:i, 0])
            y.append(scaled[i, 0])

        if len(X) < 2:
            return None, 0.3

        X, y = np.array(X), np.array(y)
        X = X.reshape(X.shape[0], X.shape[1], 1)

        # è»½é‡ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        model = create_optimized_lstm_model(seq_len)
        model.fit(X, y, epochs=8, batch_size=1, verbose=0)

        # é«˜é€Ÿäºˆæ¸¬
        last_seq = X[-1].reshape(1, seq_len, 1)
        pred = model.predict(last_seq, verbose=0)[0, 0]
        final_pred = scaler.inverse_transform([[pred]])[0, 0]

        # VertexAIå¼·åŒ–ä¿¡é ¼åº¦
        base_confidence = max(0.5, 0.9 - (days_ahead * 0.03))
        if vertexai_available:
            base_confidence += 0.05

        return float(final_pred), float(base_confidence)

    except Exception as e:
        print(f'LSTMäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}')
        return None, 0.4

def execute_enhanced_predictions():
    \"\"\"Enhanced resource prediction execution\"\"\"
    print('ğŸ”Œ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šä¸­...')
    conn = psycopg2.connect(
        host='34.173.9.214',
        user='postgres',
        password='os.getenv('DB_PASSWORD', '')',
        database='miraikakaku',
        connect_timeout=20
    )
    cursor = conn.cursor()
    print('âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ')

    # åŠ¹ç‡çš„éŠ˜æŸ„é¸æŠï¼ˆä¸Šä½25éŠ˜æŸ„ã®ã¿ï¼‰
    cursor.execute(\"\"\"
        SELECT symbol, COUNT(*) as cnt
        FROM stock_prices
        WHERE date >= CURRENT_DATE - INTERVAL '30 days'
        AND close_price > 0
        GROUP BY symbol
        HAVING COUNT(*) >= 15
        ORDER BY COUNT(*) DESC
        LIMIT 25
    \"\"\")

    symbols = cursor.fetchall()
    total_predictions = 0
    successful_symbols = 0

    print(f'ğŸ¯ åŠ¹ç‡å¯¾è±¡éŠ˜æŸ„: {len(symbols)}')

    for symbol, cnt in symbols:
        try:
            # åŠ¹ç‡çš„ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
            cursor.execute(\"\"\"
                SELECT close_price FROM stock_prices
                WHERE symbol = %s AND date >= CURRENT_DATE - INTERVAL '20 days'
                AND close_price > 0
                ORDER BY date ASC
            \"\"\", (symbol,))

            prices = [float(row[0]) for row in cursor.fetchall()]

            if len(prices) >= 10:
                print(f'âš¡ {symbol}: é«˜é€ŸLSTMäºˆæ¸¬ç”Ÿæˆä¸­...')

                predictions_made = 0
                for days in [1, 7, 30]:  # 3æœŸé–“ã®ã¿ã§é«˜é€ŸåŒ–
                    pred_price, confidence = fast_lstm_predict(prices, days)

                    if pred_price:
                        pred_date = datetime.now() + timedelta(days=days)

                        cursor.execute(\"\"\"
                            INSERT INTO stock_predictions
                            (symbol, prediction_date, prediction_days, current_price,
                             predicted_price, confidence_score, model_type, created_at)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT (symbol, prediction_date, prediction_days)
                            DO UPDATE SET predicted_price = EXCLUDED.predicted_price,
                                         confidence_score = EXCLUDED.confidence_score,
                                         model_type = EXCLUDED.model_type,
                                         created_at = EXCLUDED.created_at
                        \"\"\", (
                            symbol, pred_date.date(), days, prices[-1],
                            pred_price, confidence,
                            'ENHANCED_RESOURCE_LSTM_VERTEXAI_V1',
                            datetime.now()
                        ))
                        predictions_made += 1
                        total_predictions += 1

                if predictions_made > 0:
                    successful_symbols += 1
                    print(f'  âœ… {symbol}: {predictions_made}ä»¶ç”Ÿæˆ')

                # é«˜é€Ÿã‚³ãƒŸãƒƒãƒˆ
                if total_predictions % 10 == 0:
                    conn.commit()

        except Exception as e:
            print(f'âš ï¸ {symbol}: {e}')
            continue

    conn.commit()

    print('=========================================')
    print('ğŸ‰ Enhanced Resource LSTM å®Œäº†')
    print('=========================================')
    print(f'âœ… æˆåŠŸéŠ˜æŸ„: {successful_symbols}/{len(symbols)}')
    print(f'âœ… ç·äºˆæ¸¬æ•°: {total_predictions}')
    print(f'âš¡ é«˜é€Ÿå‡¦ç†: Enhanced Resource Mode')
    print(f'ğŸ§  TensorFlow: {tf.__version__}')
    print('=========================================')

    conn.close()

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
execute_enhanced_predictions()
"

echo "ğŸ‰ Enhanced Resource LSTM å®Ÿè¡Œå®Œäº†"
echo "çµ‚äº†æ™‚åˆ»: $(date)"
'''

        return {
            "taskGroups": [{
                "taskSpec": {
                    "runnables": [{
                        "script": {
                            "text": script.strip()
                        }
                    }],
                    "computeResource": {
                        "cpuMilli": 8000,      # 8ã‚³ã‚¢ï¼ˆ2å€å¢—å¼·ï¼‰
                        "memoryMib": 16384     # 16GBï¼ˆ2å€å¢—å¼·ï¼‰
                    },
                    "maxRetryCount": 1,
                    "maxRunDuration": "3600s"  # 1æ™‚é–“ï¼ˆå®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ï¼‰
                },
                "taskCount": 1,
                "parallelism": 1
            }],
            "allocationPolicy": {
                "instances": [{
                    "policy": {
                        "machineType": "e2-standard-8",  # 8ã‚³ã‚¢16GBãƒã‚·ãƒ³
                        "provisioningModel": "STANDARD"
                    }
                }]
            },
            "logsPolicy": {
                "destination": "CLOUD_LOGGING"
            }
        }

    def stop_failing_jobs(self):
        """å¤±æ•—ä¸­ã®ã‚¸ãƒ§ãƒ–ã‚’åœæ­¢"""
        try:
            logger.info("ğŸ›‘ Stopping failing batch jobs...")

            cmd = [
                "gcloud", "batch", "jobs", "list",
                f"--location={self.location}",
                "--filter=name~stable-lstm-vertexai AND (status.state=SCHEDULED OR status.state=RUNNING)",
                "--format=value(name)"
            ]

            result = subprocess.run(cmd, capture_output=True, text=True)
            failing_jobs = result.stdout.strip().split('\n') if result.stdout.strip() else []

            stopped_count = 0
            for job_name in failing_jobs:
                if job_name:
                    job_id = job_name.split('/')[-1]
                    try:
                        stop_cmd = [
                            "gcloud", "batch", "jobs", "delete",
                            job_id,
                            f"--location={self.location}",
                            "--quiet"
                        ]
                        subprocess.run(stop_cmd, check=True)
                        logger.info(f"ğŸ—‘ï¸ Stopped: {job_id}")
                        stopped_count += 1
                    except:
                        continue

            logger.info(f"âœ… Stopped {stopped_count} failing jobs")
            return stopped_count

        except Exception as e:
            logger.error(f"âŒ Failed to stop jobs: {e}")
            return 0

    def deploy_enhanced_jobs(self, num_jobs: int = 2) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹å¢—å¼·ã‚¸ãƒ§ãƒ–ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤"""
        logger.info("ğŸš€ Deploying Enhanced Resource LSTM Jobs")

        # ã¾ãšå¤±æ•—ä¸­ã®ã‚¸ãƒ§ãƒ–ã‚’åœæ­¢
        self.stop_failing_jobs()
        time.sleep(5)

        # ãƒªã‚½ãƒ¼ã‚¹å¢—å¼·ã‚¸ãƒ§ãƒ–ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
        successful_jobs = 0
        for i in range(num_jobs):
            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
            job_name = f"enhanced-lstm-vertexai-{timestamp}-{i+1}"

            try:
                job_config = self.create_high_resource_job()

                with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                    json.dump(job_config, f, indent=2)
                    config_file = f.name

                try:
                    cmd = [
                        "gcloud", "batch", "jobs", "submit",
                        job_name,
                        f"--location={self.location}",
                        f"--config={config_file}"
                    ]

                    result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                    logger.info(f"âœ… Enhanced job deployed: {job_name}")
                    successful_jobs += 1

                finally:
                    os.unlink(config_file)

                time.sleep(10)  # ã‚¸ãƒ§ãƒ–é–“éš”

            except Exception as e:
                logger.error(f"âŒ Failed to deploy {job_name}: {e}")
                continue

        logger.info(f"ğŸ‰ Enhanced Resource Jobs: {successful_jobs}/{num_jobs} deployed")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    enhancer = EnhancedResourceBatch()
    enhancer.deploy_enhanced_jobs(num_jobs=3)

if __name__ == "__main__":
    main()