#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import subprocess
import json
import logging
from datetime import datetime, timedelta

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BatchJobFailureAnalyzer:
    def __init__(self):
        pass

    def get_recent_failed_jobs(self):
        """æœ€è¿‘ã®å¤±æ•—ã‚¸ãƒ§ãƒ–å–å¾—"""
        try:
            result = subprocess.run([
                'gcloud', 'batch', 'jobs', 'list',
                '--filter=status.state:FAILED',
                '--format=json',
                '--limit=10'
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                jobs = json.loads(result.stdout)
                logger.info(f"ğŸ“Š æœ€è¿‘ã®å¤±æ•—ã‚¸ãƒ§ãƒ–: {len(jobs)}ä»¶")
                return jobs
            else:
                logger.error(f"ã‚¸ãƒ§ãƒ–å–å¾—å¤±æ•—: {result.stderr}")
                return []
                
        except Exception as e:
            logger.error(f"å¤±æ•—ã‚¸ãƒ§ãƒ–å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def analyze_job_failure(self, job_name):
        """å€‹åˆ¥ã‚¸ãƒ§ãƒ–ã®å¤±æ•—åŸå› åˆ†æ"""
        try:
            logger.info(f"ğŸ” ã‚¸ãƒ§ãƒ–åˆ†æ: {job_name}")
            
            # ã‚¸ãƒ§ãƒ–è©³ç´°å–å¾—
            result = subprocess.run([
                'gcloud', 'batch', 'jobs', 'describe', job_name,
                '--format=json'
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode != 0:
                logger.error(f"ã‚¸ãƒ§ãƒ–è©³ç´°å–å¾—å¤±æ•—: {result.stderr}")
                return None
            
            job_detail = json.loads(result.stdout)
            
            # çŠ¶æ…‹ã¨ã‚¤ãƒ™ãƒ³ãƒˆç¢ºèª
            status = job_detail.get('status', {})
            state = status.get('state', 'UNKNOWN')
            
            logger.info(f"   çŠ¶æ…‹: {state}")
            
            # å¤±æ•—ã‚¤ãƒ™ãƒ³ãƒˆç¢ºèª
            status_events = status.get('statusEvents', [])
            
            failure_reasons = []
            for event in status_events:
                description = event.get('description', '')
                if 'failed' in description.lower() or 'error' in description.lower():
                    failure_reasons.append(description)
                    logger.info(f"   å¤±æ•—ç†ç”±: {description}")
            
            # ã‚¿ã‚¹ã‚¯å¤±æ•—è©³ç´°
            task_groups = status.get('taskGroups', {})
            for group_name, group_info in task_groups.items():
                task_count = group_info.get('taskCount', 0)
                failed_count = group_info.get('counts', {}).get('failed', 0)
                
                if failed_count > 0:
                    logger.info(f"   ã‚¿ã‚¹ã‚¯ã‚°ãƒ«ãƒ¼ãƒ— {group_name}: {failed_count}/{task_count} å¤±æ•—")
            
            return {
                'job_name': job_name,
                'state': state,
                'failure_reasons': failure_reasons,
                'task_failures': task_groups
            }
            
        except Exception as e:
            logger.error(f"ã‚¸ãƒ§ãƒ–åˆ†æã‚¨ãƒ©ãƒ¼ {job_name}: {e}")
            return None

    def get_job_logs(self, job_name, limit=20):
        """ã‚¸ãƒ§ãƒ–ãƒ­ã‚°ã®å–å¾—"""
        try:
            logger.info(f"ğŸ“‹ ãƒ­ã‚°å–å¾—: {job_name}")
            
            # ç›´è¿‘24æ™‚é–“ã®ãƒ­ã‚°å–å¾—
            since_time = (datetime.now() - timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')
            
            result = subprocess.run([
                'gcloud', 'logging', 'read',
                f'resource.type=batch_task AND labels.job_id="{job_name.split("/")[-1]}"',
                f'--format=value(timestamp,severity,textPayload)',
                f'--limit={limit}',
                f'--freshness=24h'
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0 and result.stdout.strip():
                logs = result.stdout.strip().split('\n')
                logger.info(f"   ãƒ­ã‚°å–å¾—: {len(logs)}è¡Œ")
                
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’é‡ç‚¹çš„ã«ç¢ºèª
                error_logs = []
                for log in logs:
                    if any(keyword in log.lower() for keyword in ['error', 'failed', 'exception', 'traceback']):
                        error_logs.append(log)
                
                if error_logs:
                    logger.info("   ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°:")
                    for error_log in error_logs[:5]:
                        logger.info(f"      {error_log[:100]}...")
                
                return logs
            else:
                logger.warning(f"   âš ï¸ ãƒ­ã‚°å–å¾—å¤±æ•—: {result.stderr}")
                return []
                
        except Exception as e:
            logger.error(f"ãƒ­ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼ {job_name}: {e}")
            return []

    def identify_common_failure_patterns(self, failed_jobs):
        """å…±é€šå¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š"""
        logger.info("ğŸ” å…±é€šå¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        
        failure_patterns = {}
        
        for job in failed_jobs:
            job_name = job.get('name', '').split('/')[-1]
            
            # ã‚¸ãƒ§ãƒ–åˆ†æ
            analysis = self.analyze_job_failure(job.get('name', ''))
            
            if analysis:
                for reason in analysis['failure_reasons']:
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
                    if 'ModuleNotFoundError' in reason:
                        pattern = 'ModuleNotFoundError'
                    elif 'timeout' in reason.lower():
                        pattern = 'Timeout'
                    elif 'exit code 1' in reason:
                        pattern = 'ExitCode1'
                    elif 'collation' in reason.lower():
                        pattern = 'CollationError'
                    else:
                        pattern = 'OtherError'
                    
                    failure_patterns[pattern] = failure_patterns.get(pattern, 0) + 1
        
        logger.info("ğŸ“Š å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆ:")
        for pattern, count in sorted(failure_patterns.items(), key=lambda x: x[1], reverse=True):
            logger.info(f"   {pattern}: {count}ä»¶")
        
        return failure_patterns

    def comprehensive_batch_analysis(self):
        """åŒ…æ‹¬çš„ãƒãƒƒãƒåˆ†æ"""
        logger.info("ğŸ” åŒ…æ‹¬çš„ãƒãƒƒãƒã‚¸ãƒ§ãƒ–å¤±æ•—åˆ†æé–‹å§‹")
        
        # 1. å¤±æ•—ã‚¸ãƒ§ãƒ–å–å¾—
        failed_jobs = self.get_recent_failed_jobs()
        
        if not failed_jobs:
            logger.info("âœ… æœ€è¿‘ã®å¤±æ•—ã‚¸ãƒ§ãƒ–ãªã—")
            return
        
        # 2. å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        patterns = self.identify_common_failure_patterns(failed_jobs)
        
        # 3. å€‹åˆ¥è©³ç´°åˆ†æï¼ˆæœ€æ–°5ä»¶ï¼‰
        logger.info("=== å€‹åˆ¥è©³ç´°åˆ†æ ===")
        for job in failed_jobs[:5]:
            job_name = job.get('name', '')
            self.analyze_job_failure(job_name)
            self.get_job_logs(job_name, limit=10)
        
        # 4. æ¨å¥¨ä¿®æ­£æ¡ˆ
        logger.info("=== æ¨å¥¨ä¿®æ­£æ¡ˆ ===")
        
        if patterns.get('ModuleNotFoundError', 0) > 0:
            logger.info("ğŸ“¦ ModuleNotFoundErrorå¯¾ç­–:")
            logger.info("   - Dockerfileã®ä¾å­˜é–¢ä¿‚ç¢ºèª")
            logger.info("   - requirements.txtã®æ›´æ–°")
            logger.info("   - ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®å†ãƒ“ãƒ«ãƒ‰")
        
        if patterns.get('CollationError', 0) > 0:
            logger.info("ğŸ”¤ CollationErrorå¯¾ç­–:")
            logger.info("   - âœ… æ—¢ã«ä¿®æ­£æ¸ˆã¿ï¼ˆä»Šå›ã®ä¿®æ­£ï¼‰")
        
        if patterns.get('Timeout', 0) > 0:
            logger.info("â° Timeoutå¯¾ç­–:")
            logger.info("   - maxRunDurationã®å»¶é•·")
            logger.info("   - å‡¦ç†ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å‰Šæ¸›")
        
        if patterns.get('ExitCode1', 0) > 0:
            logger.info("ğŸ’¥ ExitCode1å¯¾ç­–:")
            logger.info("   - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ”¹å–„")
            logger.info("   - ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®è©³ç´°åŒ–")

def main():
    analyzer = BatchJobFailureAnalyzer()
    analyzer.comprehensive_batch_analysis()

if __name__ == "__main__":
    main()