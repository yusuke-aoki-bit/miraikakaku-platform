#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import psycopg2
import psycopg2.extras
import yfinance as yf
import logging
import time
import random
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class OptimizedRealDataExpansion:
    def __init__(self):
        self.db_config = {
            "host": "34.173.9.214",
            "user": "postgres",
            "password": "miraikakaku-postgres-secure-2024", 
            "database": "miraikakaku",
            "port": 5432
        }

    def get_missing_symbols_optimized(self, limit=500):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¸è¶³éŠ˜æŸ„ã‚’å„ªå…ˆåº¦é †ã§å–å¾—"""
        try:
            connection = psycopg2.connect(**self.db_config)
            with connection.cursor() as cursor:
                # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„éŠ˜æŸ„ã‚’å„ªå…ˆåº¦é †ã§å–å¾—
                cursor.execute("""
                    SELECT symbol, name, country, exchange, sector 
                    FROM stock_master 
                    WHERE is_active = 1 
                    AND symbol NOT IN (
                        SELECT DISTINCT symbol FROM stock_price_history 
                        WHERE data_source = 'yfinance'
                    )
                    ORDER BY 
                        CASE 
                            WHEN country IN ('US', 'United States') THEN 1
                            WHEN country = 'Japan' THEN 2
                            WHEN exchange IN ('NYSE', 'NASDAQ', 'TSE') THEN 3
                            ELSE 4
                        END,
                        RAND()
                    LIMIT %s
                """, (limit,))
                return cursor.fetchall()
        except Exception as e:
            logger.error(f"éŠ˜æŸ„å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        finally:
            if 'connection' in locals():
                connection.close()

    def fetch_yfinance_data_smart(self, symbol, country=None):
        """æ”¹è‰¯ç‰ˆyfinanceãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            # ã‚·ãƒ³ãƒœãƒ«å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯
            if country == 'Japan' and symbol.isdigit() and len(symbol) >= 4:
                yf_symbol = f"{symbol}.T"
            elif symbol.endswith('=X'):  # é€šè²¨ãƒšã‚¢
                yf_symbol = symbol
            else:
                yf_symbol = symbol
            
            # yfinanceä½¿ç”¨
            ticker = yf.Ticker(yf_symbol)
            
            # éå»1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
            end_date = datetime.now()
            start_date = end_date - timedelta(days=365)
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆè¤‡æ•°è©¦è¡Œï¼‰
            hist_data = None
            for attempt in range(3):
                try:
                    hist_data = ticker.history(
                        start=start_date.strftime('%Y-%m-%d'),
                        end=end_date.strftime('%Y-%m-%d'),
                        interval='1d'
                    )
                    if not hist_data.empty:
                        break
                except Exception as e:
                    logger.warning(f"yfinanceè©¦è¡Œ{attempt+1}: {yf_symbol} - {e}")
                    time.sleep(1)
            
            if hist_data is None or hist_data.empty:
                return None
                
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            price_data = []
            for date, row in hist_data.iterrows():
                try:
                    if any(pd.isna([row['Open'], row['High'], row['Low'], row['Close'], row['Volume']])):
                        continue
                    
                    price_data.append({
                        'symbol': symbol,
                        'date': date.strftime('%Y-%m-%d'),
                        'open_price': float(row['Open']),
                        'high_price': float(row['High']),
                        'low_price': float(row['Low']),
                        'close_price': float(row['Close']),
                        'adjusted_close': float(row['Close']),
                        'volume': int(row['Volume']),
                        'data_source': 'yfinance',
                        'is_valid': 1,
                        'data_quality_score': 0.95
                    })
                except Exception as e:
                    continue
            
            logger.info(f"âœ… {symbol}({yf_symbol}): {len(price_data)}ä»¶å–å¾—")
            return price_data
            
        except Exception as e:
            logger.warning(f"âŒ {symbol}: yfinanceå–å¾—å¤±æ•— - {e}")
            return None

    def save_price_data_batch(self, price_data_list):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ä¿å­˜"""
        if not price_data_list:
            return 0
            
        try:
            connection = psycopg2.connect(**self.db_config)
            with connection.cursor() as cursor:
                insert_data = []
                for data in price_data_list:
                    insert_data.append((
                        data['symbol'], data['date'],
                        data['open_price'], data['high_price'],
                        data['low_price'], data['close_price'],
                        data['volume'], data['adjusted_close'],
                        data['data_source'], data['is_valid'],
                        data['data_quality_score']
                    ))
                
                cursor.executemany("""
                    INSERT IGNORE INTO stock_price_history 
                    (symbol, date, open_price, high_price, low_price, close_price,
                     volume, adjusted_close, data_source, is_valid, data_quality_score, created_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                """, insert_data)
                
                connection.commit()
                return cursor.rowcount
                
        except Exception as e:
            logger.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
        finally:
            if 'connection' in locals():
                connection.close()

    def process_symbol(self, symbol_info):
        """å˜ä¸€éŠ˜æŸ„ã®å‡¦ç†"""
        symbol, name, country, exchange, sector = symbol_info
        
        try:
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
            price_data = self.fetch_yfinance_data_smart(symbol, country)
            
            if price_data and len(price_data) > 0:
                # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                saved_count = self.save_price_data_batch(price_data)
                if saved_count > 0:
                    return {
                        'symbol': symbol,
                        'status': 'success',
                        'records': saved_count,
                        'message': f"{saved_count}ä»¶ä¿å­˜"
                    }
                else:
                    return {
                        'symbol': symbol,
                        'status': 'save_failed',
                        'records': 0,
                        'message': "ä¿å­˜å¤±æ•—"
                    }
            else:
                return {
                    'symbol': symbol,
                    'status': 'no_data',
                    'records': 0,
                    'message': "ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—"
                }
                
        except Exception as e:
            return {
                'symbol': symbol,
                'status': 'error',
                'records': 0,
                'message': str(e)
            }

    def expand_real_data_optimized(self, target_symbols=500, max_workers=8):
        """æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ"""
        logger.info(f"ğŸš€ æœ€é©åŒ–å®Ÿãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé–‹å§‹ - ç›®æ¨™: {target_symbols}éŠ˜æŸ„")
        
        # ä¸è¶³éŠ˜æŸ„å–å¾—
        missing_symbols = self.get_missing_symbols_optimized(target_symbols)
        logger.info(f"ğŸ“‹ å‡¦ç†å¯¾è±¡: {len(missing_symbols)}éŠ˜æŸ„")
        
        if not missing_symbols:
            logger.info("âš ï¸ å‡¦ç†å¯¾è±¡éŠ˜æŸ„ãªã—")
            return {'total_processed': 0, 'successful': 0, 'failed': 0}
        
        # ä¸¦åˆ—å‡¦ç†
        results = {
            'total_processed': 0,
            'successful': 0, 
            'failed': 0,
            'total_records': 0,
            'details': []
        }
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ã‚¿ã‚¹ã‚¯é€ä¿¡
            future_to_symbol = {
                executor.submit(self.process_symbol, symbol_info): symbol_info[0] 
                for symbol_info in missing_symbols
            }
            
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    result = future.result()
                    results['total_processed'] += 1
                    results['details'].append(result)
                    
                    if result['status'] == 'success':
                        results['successful'] += 1
                        results['total_records'] += result['records']
                        logger.info(f"âœ… {symbol}: {result['records']}ä»¶ä¿å­˜")
                    else:
                        results['failed'] += 1
                        logger.warning(f"âš ï¸ {symbol}: {result['message']}")
                    
                    # é€²æ—å ±å‘Š
                    if results['total_processed'] % 50 == 0:
                        progress = (results['total_processed'] / len(missing_symbols)) * 100
                        success_rate = (results['successful'] / results['total_processed']) * 100
                        logger.info(f"ğŸ“ˆ é€²æ—: {progress:.1f}% | æˆåŠŸç‡: {success_rate:.1f}% | ãƒ‡ãƒ¼ã‚¿: {results['total_records']:,}ä»¶")
                    
                    # APIåˆ¶é™å¯¾ç­–
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"âŒ {symbol}: å‡¦ç†ã‚¨ãƒ©ãƒ¼ - {e}")
                    results['failed'] += 1
        
        # æœ€çµ‚çµæœ
        success_rate = (results['successful'] / results['total_processed'] * 100) if results['total_processed'] > 0 else 0
        logger.info(f"ğŸ¯ æœ€é©åŒ–å®Ÿãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†:")
        logger.info(f"   - å‡¦ç†éŠ˜æŸ„: {results['total_processed']}")
        logger.info(f"   - æˆåŠŸéŠ˜æŸ„: {results['successful']} ({success_rate:.1f}%)")
        logger.info(f"   - å¤±æ•—éŠ˜æŸ„: {results['failed']}")
        logger.info(f"   - åé›†ãƒ‡ãƒ¼ã‚¿: {results['total_records']:,}ä»¶")
        
        return results

def main():
    logger.info("ğŸ”¥ æœ€é©åŒ–å®Ÿãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    
    expander = OptimizedRealDataExpansion()
    
    # æ®µéšçš„æ‹¡å¼µ: ã¾ãš300éŠ˜æŸ„
    result = expander.expand_real_data_optimized(target_symbols=300, max_workers=6)
    
    if result['successful'] > 0:
        logger.info("âœ… æœ€é©åŒ–å®Ÿãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆåŠŸ")
        
        # æ‹¡å¼µå¾Œã®çŠ¶æ³è©•ä¾¡
        logger.info("ğŸ“Š æ‹¡å¼µå¾Œãƒ‡ãƒ¼ã‚¿çŠ¶æ³è©•ä¾¡ä¸­...")
        import subprocess
        subprocess.run([
            "python3", 
            "collation_safe_data_assessment.py"
        ])
    else:
        logger.error("âŒ å®Ÿãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå¤±æ•—")

if __name__ == "__main__":
    main()