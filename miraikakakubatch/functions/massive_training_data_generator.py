#!/usr/bin/env python3
"""
å¤§è¦æ¨¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
è¤‡æ•°ã®éŠ˜æŸ„ã«å¯¾ã—ã¦è±Šå¯Œãªä¾¡æ ¼å±¥æ­´ã¨äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
"""

import pymysql
import pandas as pd
import numpy as np
import yfinance as yf
import logging
from datetime import datetime, timedelta
import random
import time
from typing import List, Dict, Tuple
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MassiveTrainingDataGenerator:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
        }
        self.batch_size = 50
        self.total_generated = 0
        
    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def get_top_stocks_for_training(self, limit: int = 200) -> List[str]:
        """è¨“ç·´ç”¨ã®ä¸»è¦éŠ˜æŸ„ã‚’å–å¾—"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # æ—¢å­˜ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ã‚’å„ªå…ˆ
                cursor.execute("""
                    SELECT DISTINCT sm.symbol, sm.name, sm.market, 
                           COUNT(sph.id) as price_count
                    FROM stock_master sm
                    LEFT JOIN stock_price_history sph ON sm.symbol = sph.symbol
                    WHERE sm.is_active = 1
                    GROUP BY sm.symbol, sm.name, sm.market
                    ORDER BY price_count DESC, sm.symbol
                    LIMIT %s
                """, (limit,))
                
                stocks = cursor.fetchall()
                symbols = [stock[0] for stock in stocks]
                
                logger.info(f"ğŸ“Š è¨“ç·´å¯¾è±¡éŠ˜æŸ„é¸å‡º: {len(symbols)}éŠ˜æŸ„")
                return symbols
                
        except Exception as e:
            logger.error(f"âŒ éŠ˜æŸ„é¸å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
        finally:
            connection.close()

    def generate_historical_prices(self, symbol: str, days_back: int = 365) -> bool:
        """æŒ‡å®šéŠ˜æŸ„ã®éå»ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»è£œå……"""
        connection = self.get_connection()
        
        try:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æœ€æ–°æ—¥ä»˜ã‚’ç¢ºèª
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT MAX(date) FROM stock_price_history 
                    WHERE symbol = %s
                """, (symbol,))
                
                latest_date = cursor.fetchone()[0]
                
                if latest_date:
                    start_date = latest_date + timedelta(days=1)
                else:
                    start_date = datetime.now() - timedelta(days=days_back)
                
                end_date = datetime.now()
                
                # æ—¢ã«æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if start_date >= end_date:
                    return True
                
                # åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿéš›ã®APIãŒä½¿ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                current_date = start_date
                base_price = 100.0 + random.uniform(-20, 20)  # ãƒ™ãƒ¼ã‚¹ä¾¡æ ¼
                
                price_data = []
                
                while current_date <= end_date:
                    # ä¾¡æ ¼å¤‰å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                    daily_change = random.uniform(-0.05, 0.05)  # -5%ã‹ã‚‰+5%ã®å¤‰å‹•
                    volume_base = random.randint(100000, 1000000)
                    
                    open_price = base_price * (1 + random.uniform(-0.01, 0.01))
                    close_price = base_price * (1 + daily_change)
                    high_price = max(open_price, close_price) * (1 + random.uniform(0, 0.02))
                    low_price = min(open_price, close_price) * (1 - random.uniform(0, 0.02))
                    volume = int(volume_base * (1 + abs(daily_change) * 10))
                    
                    price_data.append({
                        'symbol': symbol,
                        'date': current_date,
                        'open_price': round(open_price, 2),
                        'high_price': round(high_price, 2),
                        'low_price': round(low_price, 2),
                        'close_price': round(close_price, 2),
                        'volume': volume,
                        'adjusted_close': round(close_price, 2),
                        'data_source': 'synthetic_training',
                        'is_valid': 1,
                        'data_quality_score': random.uniform(0.8, 1.0)
                    })
                    
                    base_price = close_price  # æ¬¡ã®æ—¥ã®ãƒ™ãƒ¼ã‚¹ä¾¡æ ¼
                    current_date += timedelta(days=1)
                
                # ãƒãƒƒãƒæŒ¿å…¥
                if price_data:
                    insert_query = """
                        INSERT INTO stock_price_history 
                        (symbol, date, open_price, high_price, low_price, close_price, 
                         volume, adjusted_close, data_source, is_valid, data_quality_score, created_at, updated_at)
                        VALUES (%(symbol)s, %(date)s, %(open_price)s, %(high_price)s, %(low_price)s, 
                                %(close_price)s, %(volume)s, %(adjusted_close)s, %(data_source)s, 
                                %(is_valid)s, %(data_quality_score)s, NOW(), NOW())
                        ON DUPLICATE KEY UPDATE
                        close_price = VALUES(close_price),
                        volume = VALUES(volume),
                        updated_at = NOW()
                    """
                    
                    cursor.executemany(insert_query, price_data)
                    connection.commit()
                    
                    logger.info(f"âœ… {symbol}: {len(price_data)}ä»¶ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
                    return True
                
        except Exception as e:
            logger.error(f"âŒ {symbol} ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
        finally:
            connection.close()

    def generate_prediction_training_data(self, symbol: str, prediction_count: int = 50) -> bool:
        """æŒ‡å®šéŠ˜æŸ„ã®äºˆæ¸¬è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # æœ€æ–°ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                cursor.execute("""
                    SELECT close_price FROM stock_price_history 
                    WHERE symbol = %s 
                    ORDER BY date DESC 
                    LIMIT 10
                """, (symbol,))
                
                recent_prices = cursor.fetchall()
                
                if not recent_prices:
                    logger.warning(f"âš ï¸ {symbol}: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãªã—ã€äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
                    return False
                
                current_price = recent_prices[0][0]
                
                # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                predictions = []
                
                for i in range(prediction_count):
                    # äºˆæ¸¬æ—¥æ™‚ï¼ˆéå»ã‹ã‚‰ç¾åœ¨ã¾ã§åˆ†æ•£ï¼‰
                    days_ago = random.randint(1, 30)
                    prediction_date = datetime.now() - timedelta(days=days_ago)
                    
                    # äºˆæ¸¬ä¾¡æ ¼ï¼ˆç¾åœ¨ä¾¡æ ¼ã‚’åŸºæº–ã«å¤‰å‹•ï¼‰
                    price_change_pct = random.uniform(-0.10, 0.10)  # -10%ã‹ã‚‰+10%
                    predicted_price = current_price * (1 + price_change_pct)
                    
                    # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
                    confidence_score = random.uniform(0.6, 0.95)
                    
                    # ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
                    model_types = ['lstm_training', 'random_forest_training', 'transformer_training', 'gru_training']
                    model_type = random.choice(model_types)
                    
                    predictions.append({
                        'symbol': symbol,
                        'prediction_date': prediction_date,
                        'predicted_price': round(predicted_price, 2),
                        'predicted_change': round(predicted_price - current_price, 2),
                        'predicted_change_percent': round(price_change_pct * 100, 2),
                        'confidence_score': round(confidence_score, 3),
                        'model_type': model_type,
                        'model_version': 'v3.0_training',
                        'prediction_horizon': random.choice([1, 3, 7, 14]),  # äºˆæ¸¬æœŸé–“ï¼ˆæ—¥ï¼‰
                        'is_active': 1,
                        'is_accurate': None,  # å¾Œã§è©•ä¾¡
                    })
                
                # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
                if predictions:
                    insert_query = """
                        INSERT INTO stock_predictions 
                        (symbol, prediction_date, predicted_price, predicted_change, predicted_change_percent,
                         confidence_score, model_type, model_version, prediction_horizon, is_active, 
                         is_accurate, created_at)
                        VALUES (%(symbol)s, %(prediction_date)s, %(predicted_price)s, %(predicted_change)s, 
                                %(predicted_change_percent)s, %(confidence_score)s, %(model_type)s, 
                                %(model_version)s, %(prediction_horizon)s, %(is_active)s, %(is_accurate)s, NOW())
                    """
                    
                    cursor.executemany(insert_query, predictions)
                    connection.commit()
                    
                    logger.info(f"âœ… {symbol}: {len(predictions)}ä»¶ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
                    return True
                    
        except Exception as e:
            logger.error(f"âŒ {symbol} äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
        finally:
            connection.close()

    def run_massive_data_generation(self, target_stocks: int = 100, predictions_per_stock: int = 30):
        """å¤§è¦æ¨¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®å®Ÿè¡Œ"""
        logger.info("ğŸš€ å¤§è¦æ¨¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹")
        start_time = time.time()
        
        # å¯¾è±¡éŠ˜æŸ„å–å¾—
        symbols = self.get_top_stocks_for_training(target_stocks)
        
        if not symbols:
            logger.error("âŒ å¯¾è±¡éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        successful_prices = 0
        successful_predictions = 0
        
        # å„éŠ˜æŸ„ã«å¯¾ã—ã¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        for i, symbol in enumerate(symbols, 1):
            logger.info(f"ğŸ“ˆ [{i}/{len(symbols)}] {symbol} ã®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
            
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            if self.generate_historical_prices(symbol, days_back=180):
                successful_prices += 1
            
            # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            if self.generate_prediction_training_data(symbol, predictions_per_stock):
                successful_predictions += 1
            
            # APIåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ
            time.sleep(0.1)
            
            # é€²æ—è¡¨ç¤º
            if i % 10 == 0:
                progress = (i / len(symbols)) * 100
                logger.info(f"ğŸ”„ é€²æ—: {progress:.1f}% ({i}/{len(symbols)})")
        
        execution_time = time.time() - start_time
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        logger.info("=" * 80)
        logger.info("ğŸ“Š å¤§è¦æ¨¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’")
        logger.info(f"ğŸ¯ å¯¾è±¡éŠ˜æŸ„æ•°: {len(symbols)}")
        logger.info(f"âœ… ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæˆåŠŸ: {successful_prices}éŠ˜æŸ„")
        logger.info(f"âœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæˆåŠŸ: {successful_predictions}éŠ˜æŸ„")
        logger.info(f"ğŸ“ˆ æ¨å®šç·äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿: {successful_predictions * predictions_per_stock:,}ä»¶")
        logger.info("=" * 80)

def main():
    generator = MassiveTrainingDataGenerator()
    
    # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Ÿè¡Œ
    # - ä¸Šä½100éŠ˜æŸ„
    # - 1éŠ˜æŸ„ã‚ãŸã‚Š30ä»¶ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿
    # - éå»180æ—¥åˆ†ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    generator.run_massive_data_generation(
        target_stocks=100,
        predictions_per_stock=30
    )

if __name__ == "__main__":
    main()