#!/usr/bin/env python3
"""
æœ€é©ãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ - ç¢ºå®Ÿã§é«˜é€Ÿãªãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
"""

import sys, os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from database.cloud_sql_only import db
from sqlalchemy import text
import numpy as np
from datetime import datetime, timedelta
import random
import logging
import time

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

def generate_ai_factors_optimized():
    """æœ€é©åŒ–ã•ã‚ŒãŸAIæ±ºå®šè¦å› ç”Ÿæˆ"""
    logger.info("ğŸ§  AIæ±ºå®šè¦å› ç”Ÿæˆé–‹å§‹")
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    templates = [
        ("technical", "RSIåˆ†æ", "RSIæŒ‡æ¨™ã«ã‚ˆã‚‹è²·å£²åˆ¤å®š"),
        ("technical", "ç§»å‹•å¹³å‡åˆ†æ", "çŸ­æœŸãƒ»é•·æœŸç§»å‹•å¹³å‡ã®ä½ç½®é–¢ä¿‚"),
        ("technical", "ãƒœãƒªãƒ¥ãƒ¼ãƒ åˆ†æ", "å‡ºæ¥é«˜ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã‚ˆã‚‹å¼·å¼±åˆ¤å®š"),
        ("fundamental", "PERè©•ä¾¡", "æ ªä¾¡åç›Šç‡ã«ã‚ˆã‚‹å‰²å®‰æ€§è©•ä¾¡"),
        ("fundamental", "æˆé•·ç‡åˆ†æ", "æ¥­ç¸¾æˆé•·ç‡ã®æŒç¶šæ€§è©•ä¾¡"),
        ("sentiment", "å¸‚å ´å¿ƒç†", "æŠ•è³‡å®¶ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆæŒ‡æ¨™"),
        ("pattern", "ãƒãƒ£ãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³", "ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜"),
        ("news", "æ¥­ç¸¾å½±éŸ¿", "æ±ºç®—ãƒ»æ¥­ç¸¾ç™ºè¡¨ã«ã‚ˆã‚‹å½±éŸ¿åº¦")
    ]
    
    added = 0
    batch_size = 1000
    
    try:
        # äºˆæ¸¬IDã‚’åˆ†å‰²å–å¾—
        with db.engine.connect() as conn:
            total_predictions = conn.execute(text("SELECT COUNT(*) FROM stock_predictions")).scalar()
            logger.info(f"å¯¾è±¡äºˆæ¸¬æ•°: {total_predictions:,}")
            
            # ãƒãƒƒãƒå‡¦ç†
            for offset in range(0, min(total_predictions, 20000), batch_size):
                prediction_ids = conn.execute(text('''
                    SELECT id FROM stock_predictions 
                    ORDER BY id LIMIT :limit OFFSET :offset
                '''), {'limit': batch_size, 'offset': offset}).fetchall()
                
                batch_data = []
                for (pred_id,) in prediction_ids:
                    # å„äºˆæ¸¬ã«3-5å€‹ã®è¦å› 
                    num_factors = random.randint(3, 5)
                    selected = random.sample(templates, num_factors)
                    
                    for factor_type, name, desc in selected:
                        batch_data.append({
                            'prediction_id': pred_id,
                            'factor_type': factor_type,
                            'factor_name': name,
                            'influence_score': round(random.uniform(50, 90), 2),
                            'description': desc,
                            'confidence': round(random.uniform(70, 95), 2)
                        })
                
                # ãƒãƒƒãƒæŒ¿å…¥
                if batch_data:
                    conn.execute(text('''
                        INSERT IGNORE INTO ai_decision_factors 
                        (prediction_id, factor_type, factor_name, influence_score, 
                         description, confidence, created_at)
                        VALUES (:prediction_id, :factor_type, :factor_name, :influence_score,
                                :description, :confidence, NOW())
                    '''), batch_data)
                    conn.commit()
                    added += len(batch_data)
                    
                    logger.info(f"ãƒãƒƒãƒå®Œäº†: {added:,}ä»¶è¿½åŠ æ¸ˆã¿")
                    
                # å®‰å…¨ãªé–“éš”
                time.sleep(0.1)
                
    except Exception as e:
        logger.error(f"AIè¦å› ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    logger.info(f"âœ… AIæ±ºå®šè¦å› å®Œäº†: {added:,}ä»¶è¿½åŠ ")
    return added

def generate_theme_insights_optimized():
    """æœ€é©åŒ–ã•ã‚ŒãŸãƒ†ãƒ¼ãƒæ´å¯Ÿç”Ÿæˆ"""
    logger.info("ğŸ¯ ãƒ†ãƒ¼ãƒæ´å¯Ÿç”Ÿæˆé–‹å§‹")
    
    # å³é¸ãƒ†ãƒ¼ãƒ
    themes = [
        ("AI Technology", "technology", "äººå·¥çŸ¥èƒ½æŠ€è¡“ã®æ€¥é€Ÿãªç™ºå±•"),
        ("Green Energy", "energy", "å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¸ã®è»¢æ›åŠ é€Ÿ"),
        ("Digital Health", "healthcare", "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã®æ™®åŠ"),
        ("Fintech Growth", "finance", "é‡‘èãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã®é©æ–°"),
        ("E-commerce Boom", "consumer", "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å•†å–å¼•ã®æ‹¡å¤§"),
        ("5G Revolution", "communication", "ç¬¬5ä¸–ä»£é€šä¿¡æŠ€è¡“ã®å±•é–‹"),
        ("EV Adoption", "transportation", "é›»æ°—è‡ªå‹•è»Šã®æ™®åŠæ‹¡å¤§"),
        ("Cybersecurity", "technology", "ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£éœ€è¦å¢—"),
        ("Cloud Computing", "technology", "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã®æˆé•·"),
        ("Sustainable Investing", "finance", "ESGæŠ•è³‡ã®ä¸»æµåŒ–")
    ]
    
    stocks = ["AAPL", "GOOGL", "MSFT", "AMZN", "TSLA", "NVDA", "META", "JPM", "JNJ", "V"]
    
    added = 0
    batch_data = []
    
    try:
        with db.engine.connect() as conn:
            for theme_name, category, driver in themes:
                # å„ãƒ†ãƒ¼ãƒ50å€‹ã®æ´å¯Ÿ
                for i in range(50):
                    insight_date = datetime.now().date() - timedelta(days=random.randint(0, 60))
                    
                    batch_data.append({
                        'theme_name': f"{theme_name} #{i+1}",
                        'theme_category': category,
                        'insight_date': insight_date,
                        'key_drivers': f"{driver}, å¸‚å ´æˆé•·ç‡{random.randint(20,80)}%, æŠ•è³‡æ‹¡å¤§",
                        'affected_stocks': ", ".join(random.sample(stocks, random.randint(3, 6))),
                        'impact_score': round(random.uniform(60, 95), 1),
                        'prediction_accuracy': round(random.uniform(0.70, 0.90), 3)
                    })
                    
                    # ãƒãƒƒãƒã‚µã‚¤ã‚º100ã§æŒ¿å…¥
                    if len(batch_data) >= 100:
                        conn.execute(text('''
                            INSERT INTO theme_insights 
                            (theme_name, theme_category, insight_date, key_drivers,
                             affected_stocks, impact_score, prediction_accuracy, created_at)
                            VALUES (:theme_name, :theme_category, :insight_date, :key_drivers,
                                    :affected_stocks, :impact_score, :prediction_accuracy, NOW())
                        '''), batch_data)
                        conn.commit()
                        added += len(batch_data)
                        batch_data = []
                        
                        logger.info(f"ãƒ†ãƒ¼ãƒæ´å¯Ÿ: {added:,}ä»¶è¿½åŠ æ¸ˆã¿")
                        time.sleep(0.1)
                        
            # æ®‹ã‚Šã‚’æŒ¿å…¥
            if batch_data:
                conn.execute(text('''
                    INSERT INTO theme_insights 
                    (theme_name, theme_category, insight_date, key_drivers,
                     affected_stocks, impact_score, prediction_accuracy, created_at)
                    VALUES (:theme_name, :theme_category, :insight_date, :key_drivers,
                            :affected_stocks, :impact_score, :prediction_accuracy, NOW())
                '''), batch_data)
                conn.commit()
                added += len(batch_data)
                
    except Exception as e:
        logger.error(f"ãƒ†ãƒ¼ãƒæ´å¯Ÿç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    logger.info(f"âœ… ãƒ†ãƒ¼ãƒæ´å¯Ÿå®Œäº†: {added:,}ä»¶è¿½åŠ ")
    return added

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    start_time = time.time()
    
    logger.info("="*60)
    logger.info("ğŸš€ æœ€é©ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹")
    logger.info("="*60)
    
    # ä¸¦è¡Œå®Ÿè¡Œ
    ai_added = generate_ai_factors_optimized()
    theme_added = generate_theme_insights_optimized()
    
    # çµæœç¢ºèª
    with db.engine.connect() as conn:
        ai_total = conn.execute(text("SELECT COUNT(*) FROM ai_decision_factors")).scalar()
        theme_total = conn.execute(text("SELECT COUNT(*) FROM theme_insights")).scalar()
        
        # ä¾¡æ ¼ãƒ»äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚‚ç¢ºèª
        price_total = conn.execute(text("SELECT COUNT(*) FROM stock_prices")).scalar()
        pred_total = conn.execute(text("SELECT COUNT(*) FROM stock_predictions")).scalar()
        
        # å……è¶³ç‡è¨ˆç®—
        symbols = conn.execute(text("SELECT COUNT(*) FROM stock_master WHERE is_active = 1")).scalar()
        
        price_rate = (price_total / (symbols * 1000)) * 100 if symbols > 0 else 0
        pred_rate = (pred_total / (symbols * 100)) * 100 if symbols > 0 else 0
        
    elapsed = time.time() - start_time
    
    logger.info("="*60)
    logger.info("ğŸ¯ æœ€é©ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
    logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {elapsed:.2f}ç§’")
    logger.info(f"ğŸ§  AIæ±ºå®šè¦å› : {ai_total:,}ä»¶ (+{ai_added:,})")
    logger.info(f"ğŸ¯ ãƒ†ãƒ¼ãƒæ´å¯Ÿ: {theme_total:,}ä»¶ (+{theme_added:,})")
    logger.info(f"ğŸ’° ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿: {price_total:,}ä»¶ (å……è¶³ç‡: {price_rate:.1f}%)")
    logger.info(f"ğŸ”® äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿: {pred_total:,}ä»¶ (å……è¶³ç‡: {pred_rate:.1f}%)")
    logger.info("="*60)

if __name__ == "__main__":
    main()