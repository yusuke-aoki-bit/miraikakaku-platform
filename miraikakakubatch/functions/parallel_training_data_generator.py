#!/usr/bin/env python3
"""
‰∏¶ÂàóË®ìÁ∑¥„Éá„Éº„ÇøÁîüÊàêÂô® - Google Cloud BatchÁî®
Áí∞Â¢ÉÂ§âÊï∞„Åã„ÇâË®≠ÂÆö„ÇíÂèñÂæó„Åó„ÄÅÊåáÂÆö„Åï„Çå„ÅüÁØÑÂõ≤„ÅÆÈäòÊüÑ„ÇíÂá¶ÁêÜ
"""

import os
import sys
import psycopg2
import psycopg2.extras
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
import random
import time
from typing import List, Dict, Tuple, Optional
import json

# „É≠„Ç∞Ë®≠ÂÆö
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/tmp/training_data_generator.log')
    ]
)
logger = logging.getLogger(__name__)

class ParallelTrainingDataGenerator:
    def __init__(self):
        # Áí∞Â¢ÉÂ§âÊï∞„Åã„ÇâË®≠ÂÆöÂèñÂæó
        self.db_config = {
            "host": os.getenv("DB_HOST", "34.58.103.36"),
            "user": os.getenv("DB_USER", "miraikakaku-user"),
            "password": os.getenv("DB_PASSWORD", "miraikakaku-secure-pass-2024"),
            "database": os.getenv("DB_NAME", "miraikakaku"),
            "port": 5432
        }
        
        self.batch_size = int(os.getenv("BATCH_SIZE", "100"))
        self.predictions_per_stock = int(os.getenv("PREDICTIONS_PER_STOCK", "50"))
        self.pod_index = int(os.getenv("POD_INDEX", "0"))
        
        logger.info(f"üöÄ ‰∏¶Âàó„Éá„Éº„ÇøÁîüÊàêÂô®ÈñãÂßã - Pod {self.pod_index}")
        logger.info(f"üìä „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: {self.batch_size}ÈäòÊüÑ")
        logger.info(f"üîÆ ‰∫àÊ∏¨„Éá„Éº„Çø: {self.predictions_per_stock}‰ª∂/ÈäòÊüÑ")

    def get_connection(self):
        return psycopg2.connect(**self.db_config)

    def get_stock_batch(self) -> List[Dict]:
        """„Åì„ÅÆPod„ÅåÂá¶ÁêÜ„Åô„Åπ„ÅçÈäòÊüÑ„Éê„ÉÉ„ÉÅ„ÇíÂèñÂæó"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # „Ç™„Éï„Çª„ÉÉ„ÉàË®àÁÆó
                offset = self.pod_index * self.batch_size
                
                cursor.execute("""
                    SELECT symbol, name, market, sector, country
                    FROM stock_master 
                    WHERE is_active = 1 
                    ORDER BY symbol
                    LIMIT %s OFFSET %s
                """, (self.batch_size, offset))
                
                stocks = cursor.fetchall()
                
                stock_list = []
                for stock in stocks:
                    stock_info = {
                        'symbol': stock[0],
                        'name': stock[1] or 'Unknown Company',
                        'market': stock[2] or 'OTHER',
                        'sector': stock[3] or 'Unknown',
                        'country': stock[4] or 'Unknown'
                    }
                    stock_list.append(stock_info)
                
                logger.info(f"üìä Pod {self.pod_index}: {len(stock_list)}ÈäòÊüÑ„ÇíÂá¶ÁêÜÂØæË±°„Å´ÈÅ∏ÂÆö")
                return stock_list
                
        except Exception as e:
            logger.error(f"‚ùå ÈäòÊüÑÂèñÂæó„Ç®„É©„Éº: {e}")
            return []
        finally:
            connection.close()

    def generate_realistic_price_data(self, stock_info: Dict, days_back: int = 365) -> List[Dict]:
        """„É™„Ç¢„É´„Å™‰æ°Ê†º„Éá„Éº„ÇøÁîüÊàêÔºàÂ∏ÇÂ†¥„Éª„Çª„ÇØ„Çø„ÉºÁâπÊÄß„ÇíËÄÉÊÖÆÔºâ"""
        symbol = stock_info['symbol']
        market = stock_info['market']
        sector = stock_info['sector']
        
        # Â∏ÇÂ†¥„Éª„Çª„ÇØ„Çø„ÉºÂà•„Éë„É©„É°„Éº„Çø
        market_params = {
            'US': {'base_price': 150, 'volatility': 0.02, 'trend': 0.0003},
            'JP': {'base_price': 2500, 'volatility': 0.015, 'trend': 0.0001},  
            'OTHER': {'base_price': 50, 'volatility': 0.025, 'trend': 0.0002}
        }
        
        sector_multipliers = {
            'Technology': {'volatility': 1.5, 'trend': 1.2},
            'Healthcare': {'volatility': 0.8, 'trend': 1.0},
            'Energy': {'volatility': 1.3, 'trend': 0.9},
            'Financial': {'volatility': 1.1, 'trend': 1.0},
            'Unknown': {'volatility': 1.0, 'trend': 1.0}
        }
        
        params = market_params.get(market, market_params['OTHER'])
        multipliers = sector_multipliers.get(sector, sector_multipliers['Unknown'])
        
        base_price = params['base_price']
        volatility = params['volatility'] * multipliers['volatility']
        trend = params['trend'] * multipliers['trend']
        
        # ‰æ°Ê†º„Éá„Éº„ÇøÁîüÊàê
        price_data = []
        current_price = base_price * random.uniform(0.7, 1.3)
        start_date = datetime.now() - timedelta(days=days_back)
        
        for i in range(days_back):
            date = start_date + timedelta(days=i)
            
            trend_component = trend * i
            random_component = random.gauss(0, volatility)
            
            price_change = current_price * (trend_component + random_component)
            new_price = max(current_price + price_change, 0.01)
            
            intraday_volatility = volatility * 0.5
            open_price = current_price
            close_price = new_price
            
            high_price = max(open_price, close_price) * (1 + abs(random.gauss(0, intraday_volatility)))
            low_price = min(open_price, close_price) * (1 - abs(random.gauss(0, intraday_volatility)))
            
            volume_base = random.randint(100000, 5000000)
            volume_multiplier = 1 + abs(random_component) * 10
            volume = int(volume_base * volume_multiplier)
            
            price_data.append({
                'symbol': symbol,
                'date': date,
                'open_price': round(open_price, 2),
                'high_price': round(high_price, 2),
                'low_price': round(low_price, 2),
                'close_price': round(close_price, 2),
                'volume': volume,
                'adjusted_close': round(close_price, 2),
                'data_source': f'batch_parallel_pod_{self.pod_index}',
                'is_valid': 1,
                'data_quality_score': random.uniform(0.85, 1.0)
            })
            
            current_price = new_price
        
        return price_data

    def generate_advanced_predictions(self, stock_info: Dict, price_data: List[Dict]) -> List[Dict]:
        """È´òÂ∫¶„Å™‰∫àÊ∏¨„Éá„Éº„ÇøÁîüÊàê"""
        symbol = stock_info['symbol']
        sector = stock_info['sector']
        
        if len(price_data) < 30:
            logger.warning(f"‚ö†Ô∏è {symbol}: ‰æ°Ê†º„Éá„Éº„Çø‰∏çË∂≥")
            return []
        
        recent_prices = [p['close_price'] for p in price_data[-30:]]
        current_price = recent_prices[-1]
        
        # „ÉÜ„ÇØ„Éã„Ç´„É´ÊåáÊ®ôË®àÁÆó
        ma_5 = np.mean(recent_prices[-5:])
        ma_20 = np.mean(recent_prices[-20:])
        
        returns = np.diff(recent_prices) / recent_prices[:-1]
        volatility = np.std(returns)
        
        # „Çª„ÇØ„Çø„ÉºÂà•Á≤æÂ∫¶
        sector_accuracy = {
            'Technology': 0.75,
            'Healthcare': 0.70,
            'Energy': 0.65,
            'Financial': 0.72,
            'Unknown': 0.68
        }
        base_accuracy = sector_accuracy.get(sector, 0.68)
        
        predictions = []
        
        # Ë§áÊï∞„É¢„Éá„É´„Åß‰∫àÊ∏¨ÁîüÊàê
        model_configs = [
            {'type': 'lstm_batch_v4', 'version': 'v4.0', 'weight': 0.3},
            {'type': 'transformer_batch_v2', 'version': 'v2.1', 'weight': 0.25},
            {'type': 'rf_ensemble_batch', 'version': 'v3.2', 'weight': 0.2},
            {'type': 'gru_attention_batch', 'version': 'v1.5', 'weight': 0.15},
            {'type': 'xgb_hybrid_batch', 'version': 'v2.0', 'weight': 0.1}
        ]
        
        predictions_per_model = self.predictions_per_stock // len(model_configs)
        
        for model_config in model_configs:
            for i in range(predictions_per_model):
                horizon = random.choice([1, 3, 5, 7, 14, 21, 30])
                
                # „ÉÜ„ÇØ„Éã„Ç´„É´ÂàÜÊûê„Éô„Éº„Çπ‰∫àÊ∏¨
                technical_signal = 0
                if ma_5 > ma_20:
                    technical_signal += 0.1
                    
                random_factor = random.gauss(0, volatility * np.sqrt(horizon))
                total_change = technical_signal + random_factor
                predicted_price = current_price * (1 + total_change)
                
                # ‰ø°È†ºÂ∫¶Ë®àÁÆó
                confidence_factors = [
                    base_accuracy,
                    max(0.3, 1 - volatility * 10),
                    model_config['weight'] * 2,
                    max(0.3, 1 - horizon / 30),
                ]
                confidence_score = np.mean(confidence_factors) + random.uniform(-0.1, 0.1)
                confidence_score = max(0.3, min(0.95, confidence_score))
                
                days_ago = random.randint(0, min(horizon, 20))
                prediction_date = datetime.now() - timedelta(days=days_ago)
                
                predictions.append({
                    'symbol': symbol,
                    'prediction_date': prediction_date,
                    'predicted_price': round(predicted_price, 2),
                    'predicted_change': round(predicted_price - current_price, 2),
                    'predicted_change_percent': round((predicted_price - current_price) / current_price * 100, 2),
                    'confidence_score': round(confidence_score, 3),
                    'model_type': model_config['type'],
                    'model_version': model_config['version'],
                    'prediction_horizon': horizon,
                    'is_active': 1,
                    'is_accurate': None,
                    'notes': f'Pod{self.pod_index}_BatchGen_{datetime.now().strftime("%Y%m%d")}'
                })
        
        return predictions

    def bulk_insert_data(self, table_name: str, data: List[Dict], batch_size: int = 500) -> int:
        """È´òÂäπÁéá„Éê„É´„ÇØÊåøÂÖ•"""
        if not data:
            return 0
        
        connection = self.get_connection()
        
        try:
            inserted_count = 0
            
            for i in range(0, len(data), batch_size):
                batch = data[i:i + batch_size]
                
                with connection.cursor() as cursor:
                    if table_name == 'stock_price_history':
                        insert_query = """
                            INSERT IGNORE INTO stock_price_history 
                            (symbol, date, open_price, high_price, low_price, close_price, 
                             volume, adjusted_close, data_source, is_valid, data_quality_score, 
                             created_at, updated_at)
                            VALUES (%(symbol)s, %(date)s, %(open_price)s, %(high_price)s, %(low_price)s, 
                                    %(close_price)s, %(volume)s, %(adjusted_close)s, %(data_source)s, 
                                    %(is_valid)s, %(data_quality_score)s, NOW(), NOW())
                        """
                    elif table_name == 'stock_predictions':
                        insert_query = """
                            INSERT INTO stock_predictions 
                            (symbol, prediction_date, predicted_price, predicted_change, predicted_change_percent,
                             confidence_score, model_type, model_version, prediction_horizon, is_active, 
                             is_accurate, notes, created_at)
                            VALUES (%(symbol)s, %(prediction_date)s, %(predicted_price)s, %(predicted_change)s, 
                                    %(predicted_change_percent)s, %(confidence_score)s, %(model_type)s, 
                                    %(model_version)s, %(prediction_horizon)s, %(is_active)s, %(is_accurate)s, 
                                    %(notes)s, NOW())
                        """
                    
                    cursor.executemany(insert_query, batch)
                    connection.commit()
                    inserted_count += len(batch)
                    
                    if i % (batch_size * 2) == 0 and i > 0:
                        logger.info(f"üîÑ Pod {self.pod_index} - {table_name}: {inserted_count:,}‰ª∂ÊåøÂÖ•ÂÆå‰∫Ü")
            
            return inserted_count
                
        except Exception as e:
            logger.error(f"‚ùå Pod {self.pod_index} - {table_name} „Éê„É´„ÇØÊåøÂÖ•„Ç®„É©„Éº: {e}")
            return 0
        finally:
            connection.close()

    def run_parallel_generation(self):
        """‰∏¶Âàó„Éá„Éº„ÇøÁîüÊàêÂÆüË°å"""
        start_time = time.time()
        logger.info(f"üöÄ Pod {self.pod_index}: ‰∏¶ÂàóË®ìÁ∑¥„Éá„Éº„ÇøÁîüÊàêÈñãÂßã")
        
        # Âá¶ÁêÜÂØæË±°ÈäòÊüÑÂèñÂæó
        stock_list = self.get_stock_batch()
        
        if not stock_list:
            logger.error(f"‚ùå Pod {self.pod_index}: Âá¶ÁêÜÂØæË±°ÈäòÊüÑ„Å™„Åó")
            return
        
        total_prices_generated = 0
        total_predictions_generated = 0
        
        # ÂêÑÈäòÊüÑ„ÅÆÂá¶ÁêÜ
        for i, stock_info in enumerate(stock_list, 1):
            symbol = stock_info['symbol']
            logger.info(f"üìä Pod {self.pod_index} [{i}/{len(stock_list)}] {symbol} Âá¶ÁêÜ‰∏≠...")
            
            # ‰æ°Ê†º„Éá„Éº„ÇøÁîüÊàê
            price_data = self.generate_realistic_price_data(stock_info, days_back=365)
            if price_data:
                inserted = self.bulk_insert_data('stock_price_history', price_data, batch_size=200)
                total_prices_generated += inserted
            
            # ‰∫àÊ∏¨„Éá„Éº„ÇøÁîüÊàê
            prediction_data = self.generate_advanced_predictions(stock_info, price_data)
            if prediction_data:
                inserted = self.bulk_insert_data('stock_predictions', prediction_data, batch_size=200)
                total_predictions_generated += inserted
            
            # ÈÄ≤ÊçóË°®Á§∫
            if i % 10 == 0:
                progress = (i / len(stock_list)) * 100
                elapsed = time.time() - start_time
                eta = (elapsed / i) * (len(stock_list) - i)
                logger.info(f"üîÑ Pod {self.pod_index} ÈÄ≤Êçó: {progress:.1f}% | ÁµåÈÅé: {elapsed:.0f}s | ÊÆã„Çä: {eta:.0f}s")
        
        execution_time = time.time() - start_time
        
        # ÊúÄÁµÇ„É¨„Éù„Éº„Éà
        logger.info("=" * 80)
        logger.info(f"üìä Pod {self.pod_index} ‰∏¶Âàó„Éá„Éº„ÇøÁîüÊàêÂÆå‰∫Ü„É¨„Éù„Éº„Éà")
        logger.info(f"‚è±Ô∏è  ÂÆüË°åÊôÇÈñì: {execution_time:.1f}Áßí")
        logger.info(f"üéØ Âá¶ÁêÜÈäòÊüÑÊï∞: {len(stock_list)}")
        logger.info(f"üìà ÁîüÊàê‰æ°Ê†º„Éá„Éº„Çø: {total_prices_generated:,}‰ª∂")
        logger.info(f"üîÆ ÁîüÊàê‰∫àÊ∏¨„Éá„Éº„Çø: {total_predictions_generated:,}‰ª∂")
        logger.info(f"üíæ Á∑è„Éá„Éº„Çø„Çµ„Ç§„Ç∫: {(total_prices_generated + total_predictions_generated):,}‰ª∂")
        logger.info(f"‚ö° Âá¶ÁêÜÈÄüÂ∫¶: {(total_prices_generated + total_predictions_generated) / execution_time:.0f}‰ª∂/Áßí")
        logger.info("=" * 80)

def main():
    generator = ParallelTrainingDataGenerator()
    generator.run_parallel_generation()

if __name__ == "__main__":
    main()