#!/usr/bin/env python3
"""
äºˆæ¸¬ç²¾åº¦è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
å¹³å‡çµ¶å¯¾èª¤å·®(MAE)ã‚’ä½¿ç”¨ã—ã¦LSTM vs VertexAIäºˆæ¸¬ç²¾åº¦ã‚’æ¯”è¼ƒ
"""

import psycopg2
import psycopg2.extras
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import pandas as pd
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PredictionAccuracyEvaluator:
    def __init__(self):
        self.db_config = {
            "host": "34.173.9.214",
            "user": "postgres", 
            "password": "miraikakaku-postgres-secure-2024",
            "database": "miraikakaku",
        }
        self.accuracy_results = {
            "lstm": {
                "total_predictions": 0,
                "mae": 0.0,
                "symbols_evaluated": 0,
                "symbol_results": {}
            },
            "vertexai": {
                "total_predictions": 0,
                "mae": 0.0,
                "symbols_evaluated": 0,
                "symbol_results": {}
            }
        }

    def get_connection(self):
        return psycopg2.connect(**self.db_config)

    def get_past_predictions_with_actual_data(self, days_back=30):
        """
        éå»ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã¨å®Ÿéš›ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        """
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # éå»ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã§å®Ÿéš›ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‚‚ã®ã‚’å–å¾—
                cursor.execute("""
                    SELECT 
                        sp.symbol,
                        sp.prediction_date,
                        sp.predicted_price,
                        sp.predicted_change_percent,
                        sp.confidence_score,
                        sp.model_type,
                        sp.created_at,
                        sph.close_price as actual_price,
                        sph.date as actual_date
                    FROM stock_predictions sp
                    JOIN stock_price_history sph ON (
                        sp.symbol = sph.symbol 
                        AND DATE(sp.prediction_date) = DATE(sph.date)
                    )
                    WHERE sp.prediction_date < NOW()
                    AND sp.prediction_date >= DATE_SUB(NOW(), INTERVAL %s DAY)
                    AND sp.model_type IN ('lstm_test_v2', 'vertexai_test_v2', 'lstm_v2', 'vertexai_v2')
                    ORDER BY sp.symbol, sp.prediction_date, sp.model_type
                """, (days_back,))
                
                results = cursor.fetchall()
                logger.info(f"ğŸ“Š è©•ä¾¡å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(results)}ä»¶ã®äºˆæ¸¬-å®Ÿç¸¾ãƒšã‚¢")
                
                return results
                
        finally:
            connection.close()

    def calculate_mae_for_symbol(self, predictions: List[Tuple]) -> Dict:
        """
        å˜ä¸€éŠ˜æŸ„ã®MAEè¨ˆç®—
        """
        lstm_predictions = []
        vertexai_predictions = []
        
        for pred in predictions:
            symbol, pred_date, pred_price, pred_change, confidence, model_type, created_at, actual_price, actual_date = pred
            
            if model_type in ['lstm_test_v2', 'lstm_v2']:
                lstm_predictions.append({
                    'predicted': pred_price,
                    'actual': actual_price,
                    'date': pred_date,
                    'confidence': confidence
                })
            elif model_type in ['vertexai_test_v2', 'vertexai_v2']:
                vertexai_predictions.append({
                    'predicted': pred_price,
                    'actual': actual_price,
                    'date': pred_date,
                    'confidence': confidence
                })
        
        result = {
            'symbol': predictions[0][0] if predictions else None,
            'lstm': self._calculate_mae(lstm_predictions),
            'vertexai': self._calculate_mae(vertexai_predictions)
        }
        
        return result

    def _calculate_mae(self, predictions: List[Dict]) -> Dict:
        """
        MAEï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰è¨ˆç®—
        MAE = Î£|predicted - actual| / n
        """
        if not predictions:
            return {
                'mae': float('inf'),
                'count': 0,
                'avg_confidence': 0.0,
                'error_details': []
            }
        
        absolute_errors = []
        confidences = []
        error_details = []
        
        for pred in predictions:
            predicted = pred['predicted']
            actual = pred['actual']
            absolute_error = abs(predicted - actual)
            
            absolute_errors.append(absolute_error)
            confidences.append(pred['confidence'])
            error_details.append({
                'date': pred['date'],
                'predicted': predicted,
                'actual': actual,
                'absolute_error': absolute_error,
                'relative_error_percent': (absolute_error / actual) * 100 if actual != 0 else 0
            })
        
        mae = np.mean(absolute_errors)
        avg_confidence = np.mean(confidences)
        
        return {
            'mae': mae,
            'count': len(predictions),
            'avg_confidence': avg_confidence,
            'error_details': error_details,
            'median_error': np.median(absolute_errors),
            'std_error': np.std(absolute_errors)
        }

    def evaluate_all_predictions(self, days_back=30):
        """
        å…¨äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦è©•ä¾¡
        """
        logger.info(f"ğŸ” éå»{days_back}æ—¥é–“ã®äºˆæ¸¬ç²¾åº¦è©•ä¾¡é–‹å§‹")
        
        # äºˆæ¸¬-å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿å–å¾—
        prediction_data = self.get_past_predictions_with_actual_data(days_back)
        
        if not prediction_data:
            logger.warning("âŒ è©•ä¾¡å¯èƒ½ãªäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # éŠ˜æŸ„åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        symbol_groups = {}
        for pred in prediction_data:
            symbol = pred[0]
            if symbol not in symbol_groups:
                symbol_groups[symbol] = []
            symbol_groups[symbol].append(pred)
        
        # éŠ˜æŸ„åˆ¥ç²¾åº¦è©•ä¾¡
        all_lstm_errors = []
        all_vertexai_errors = []
        
        logger.info(f"ğŸ“ˆ {len(symbol_groups)}éŠ˜æŸ„ã®ç²¾åº¦è©•ä¾¡å®Ÿæ–½")
        
        for symbol, predictions in symbol_groups.items():
            symbol_result = self.calculate_mae_for_symbol(predictions)
            
            # çµæœã‚’è“„ç©
            if symbol_result['lstm']['count'] > 0:
                lstm_mae = symbol_result['lstm']['mae']
                all_lstm_errors.extend([detail['absolute_error'] for detail in symbol_result['lstm']['error_details']])
                self.accuracy_results['lstm']['symbol_results'][symbol] = symbol_result['lstm']
                self.accuracy_results['lstm']['symbols_evaluated'] += 1
                logger.info(f"  ğŸ§  LSTM {symbol}: MAE={lstm_mae:.2f} ({symbol_result['lstm']['count']}ä»¶)")
            
            if symbol_result['vertexai']['count'] > 0:
                vertexai_mae = symbol_result['vertexai']['mae']
                all_vertexai_errors.extend([detail['absolute_error'] for detail in symbol_result['vertexai']['error_details']])
                self.accuracy_results['vertexai']['symbol_results'][symbol] = symbol_result['vertexai']
                self.accuracy_results['vertexai']['symbols_evaluated'] += 1
                logger.info(f"  ğŸ¯ VertexAI {symbol}: MAE={vertexai_mae:.2f} ({symbol_result['vertexai']['count']}ä»¶)")
        
        # å…¨ä½“MAEè¨ˆç®—
        if all_lstm_errors:
            self.accuracy_results['lstm']['mae'] = np.mean(all_lstm_errors)
            self.accuracy_results['lstm']['total_predictions'] = len(all_lstm_errors)
        
        if all_vertexai_errors:
            self.accuracy_results['vertexai']['mae'] = np.mean(all_vertexai_errors)
            self.accuracy_results['vertexai']['total_predictions'] = len(all_vertexai_errors)

    def save_accuracy_results(self):
        """
        ç²¾åº¦è©•ä¾¡çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        """
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # ç²¾åº¦è©•ä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS model_accuracy_evaluation (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        model_type VARCHAR(50),
                        symbol VARCHAR(20),
                        mae FLOAT,
                        prediction_count INT,
                        avg_confidence FLOAT,
                        median_error FLOAT,
                        std_error FLOAT,
                        evaluation_date DATETIME,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # LSTMçµæœä¿å­˜
                for symbol, result in self.accuracy_results['lstm']['symbol_results'].items():
                    cursor.execute("""
                        INSERT INTO model_accuracy_evaluation 
                        (model_type, symbol, mae, prediction_count, avg_confidence, 
                         median_error, std_error, evaluation_date)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, NOW())
                    """, (
                        'LSTM', symbol, result['mae'], result['count'], 
                        result['avg_confidence'], result['median_error'], result['std_error']
                    ))
                
                # VertexAIçµæœä¿å­˜
                for symbol, result in self.accuracy_results['vertexai']['symbol_results'].items():
                    cursor.execute("""
                        INSERT INTO model_accuracy_evaluation 
                        (model_type, symbol, mae, prediction_count, avg_confidence, 
                         median_error, std_error, evaluation_date)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, NOW())
                    """, (
                        'VertexAI', symbol, result['mae'], result['count'], 
                        result['avg_confidence'], result['median_error'], result['std_error']
                    ))
                
                connection.commit()
                logger.info("âœ… ç²¾åº¦è©•ä¾¡çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜å®Œäº†")
                
        finally:
            connection.close()

    def generate_accuracy_report(self):
        """
        ç²¾åº¦è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        """
        logger.info("=" * 80)
        logger.info("ğŸ“Š äºˆæ¸¬ç²¾åº¦è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå¹³å‡çµ¶å¯¾èª¤å·® MAEï¼‰")
        logger.info("=" * 80)
        
        # å…¨ä½“æ¯”è¼ƒ
        lstm_mae = self.accuracy_results['lstm']['mae']
        vertexai_mae = self.accuracy_results['vertexai']['mae']
        lstm_count = self.accuracy_results['lstm']['total_predictions']
        vertexai_count = self.accuracy_results['vertexai']['total_predictions']
        
        logger.info("ğŸ¯ å…¨ä½“ç²¾åº¦æ¯”è¼ƒ:")
        logger.info(f"  ğŸ§  LSTM:")
        logger.info(f"    MAE: {lstm_mae:.2f}")
        logger.info(f"    äºˆæ¸¬ä»¶æ•°: {lstm_count:,}ä»¶")
        logger.info(f"    è©•ä¾¡éŠ˜æŸ„æ•°: {self.accuracy_results['lstm']['symbols_evaluated']}éŠ˜æŸ„")
        
        logger.info(f"  ğŸ¯ VertexAI:")
        logger.info(f"    MAE: {vertexai_mae:.2f}")
        logger.info(f"    äºˆæ¸¬ä»¶æ•°: {vertexai_count:,}ä»¶")
        logger.info(f"    è©•ä¾¡éŠ˜æŸ„æ•°: {self.accuracy_results['vertexai']['symbols_evaluated']}éŠ˜æŸ„")
        
        # å‹è€…åˆ¤å®š
        if lstm_mae < vertexai_mae:
            logger.info(f"ğŸ† å‹è€…: LSTM (MAEå·®: {vertexai_mae - lstm_mae:.2f})")
        elif vertexai_mae < lstm_mae:
            logger.info(f"ğŸ† å‹è€…: VertexAI (MAEå·®: {lstm_mae - vertexai_mae:.2f})")
        else:
            logger.info("ğŸ¤ åŒç‚¹")
        
        logger.info("")
        
        # éŠ˜æŸ„åˆ¥è©³ç´°
        logger.info("ğŸ“ˆ éŠ˜æŸ„åˆ¥ç²¾åº¦è©³ç´°:")
        all_symbols = set(self.accuracy_results['lstm']['symbol_results'].keys()) | \
                     set(self.accuracy_results['vertexai']['symbol_results'].keys())
        
        for symbol in sorted(all_symbols):
            lstm_result = self.accuracy_results['lstm']['symbol_results'].get(symbol)
            vertexai_result = self.accuracy_results['vertexai']['symbol_results'].get(symbol)
            
            logger.info(f"  {symbol}:")
            if lstm_result:
                logger.info(f"    ğŸ§  LSTM: MAE={lstm_result['mae']:.2f} ({lstm_result['count']}ä»¶)")
            if vertexai_result:
                logger.info(f"    ğŸ¯ VertexAI: MAE={vertexai_result['mae']:.2f} ({vertexai_result['count']}ä»¶)")
            
            # éŠ˜æŸ„åˆ¥å‹è€…
            if lstm_result and vertexai_result:
                if lstm_result['mae'] < vertexai_result['mae']:
                    logger.info(f"    ğŸ† {symbol}å‹è€…: LSTM")
                elif vertexai_result['mae'] < lstm_result['mae']:
                    logger.info(f"    ğŸ† {symbol}å‹è€…: VertexAI")
                else:
                    logger.info(f"    ğŸ¤ {symbol}: åŒç‚¹")
        
        logger.info("=" * 80)

    def run_accuracy_evaluation(self, days_back=30):
        """
        ç²¾åº¦è©•ä¾¡å®Ÿè¡Œ
        """
        start_time = datetime.now()
        logger.info(f"ğŸš€ äºˆæ¸¬ç²¾åº¦è©•ä¾¡é–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # ç²¾åº¦è©•ä¾¡å®Ÿè¡Œ
            self.evaluate_all_predictions(days_back)
            
            # çµæœä¿å­˜
            self.save_accuracy_results()
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self.generate_accuracy_report()
            
        except Exception as e:
            logger.error(f"âŒ ç²¾åº¦è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        logger.info(f"âœ… ç²¾åº¦è©•ä¾¡å®Œäº† (å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’)")

if __name__ == "__main__":
    evaluator = PredictionAccuracyEvaluator()
    
    try:
        # éå»30æ—¥é–“ã®äºˆæ¸¬ç²¾åº¦ã‚’è©•ä¾¡
        evaluator.run_accuracy_evaluation(days_back=30)
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢")
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()