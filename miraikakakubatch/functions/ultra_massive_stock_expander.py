#!/usr/bin/env python3
"""
è¶…å¤§è¦æ¨¡å®Ÿæ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ  - 354éŠ˜æŸ„ã‹ã‚‰1000+éŠ˜æŸ„ã¸
ä¸–ç•Œã®ä¸»è¦æ ªå¼å¸‚å ´ã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å¤§å¹…åé›†
"""

import yfinance as yf
import pymysql
import logging
import time
from datetime import datetime
from typing import Dict, List
from concurrent.futures import ThreadPoolExecutor, as_completed

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class UltraMassiveStockExpander:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
        }
        self.expansion_stats = {
            "stocks_added": 0,
            "successful_updates": 0,
            "failed_updates": 0,
            "markets_covered": 0
        }

    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def get_ultra_comprehensive_stock_universe(self) -> Dict[str, List[str]]:
        """è¶…åŒ…æ‹¬çš„ãªä¸–ç•Œæ ªå¼ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ - 1000+éŠ˜æŸ„"""
        
        return {
            # ğŸ‡ºğŸ‡¸ ç±³å›½å¸‚å ´ - S&P 500 å¤§å¹…æ‹¡å¼µ
            "US_MEGA_CAP_EXTENDED": [
                "AAPL", "MSFT", "GOOGL", "GOOG", "AMZN", "NVDA", "TSLA", "META", 
                "NFLX", "ADBE", "CRM", "ORCL", "CSCO", "INTC", "QCOM", "TXN",
                "AVGO", "IBM", "NOW", "AMD", "MU", "AMAT", "ADI", "LRCX", "MRVL",
                "PYPL", "SNOW", "UBER", "SHOP", "SQ", "ROKU", "DOCU", "ZM", "OKTA",
                "TWLO", "NET", "DDOG", "CRWD", "ZS", "PANW", "FTNT", "CYBR"
            ],
            
            "US_FINANCIAL_EXTENDED": [
                "JPM", "BAC", "WFC", "GS", "MS", "C", "USB", "PNC", "TFC", "COF",
                "AXP", "BLK", "SPGI", "CME", "ICE", "CB", "PGR", "AIG", "MET", "PRU",
                "V", "MA", "PYPL", "FIS", "FISV", "ADP", "PAYX", "TRV", "AFL",
                "ALL", "HIG", "LNC", "PFG", "TMK", "AIZ", "CNA", "RGA", "UNM"
            ],
            
            "US_HEALTHCARE_EXTENDED": [
                "JNJ", "PFE", "UNH", "CVS", "MRK", "ABBV", "TMO", "DHR", "ABT", 
                "LLY", "BMY", "AMGN", "GILD", "ISRG", "SYK", "BSX", "MDT", "ZTS",
                "MRNA", "BNTX", "REGN", "VRTX", "BIIB", "ILMN", "IQV", "A", 
                "EW", "DXCM", "ALGN", "IDXX", "RMD", "HOLX", "TECH", "ZBH"
            ],
            
            "US_CONSUMER_EXTENDED": [
                "AMZN", "TSLA", "HD", "MCD", "DIS", "NKE", "SBUX", "LOW", "TJX",
                "WMT", "PG", "KO", "PEP", "COST", "TGT", "F", "GM", "NFLX",
                "CMG", "YUM", "QSR", "DPZ", "WING", "EAT", "CAKE", "TXRH",
                "CL", "KMB", "GIS", "K", "CPB", "CAG", "SJM", "HSY", "MDLZ"
            ],
            
            "US_INDUSTRIAL_EXTENDED": [
                "BA", "CAT", "GE", "MMM", "HON", "UPS", "RTX", "LMT", "NOC", 
                "DE", "UNP", "CSX", "NSC", "FDX", "WM", "EMR", "ETN", "PH",
                "ITW", "ROK", "DOV", "IR", "OTIS", "CARR", "PWR", "FLR",
                "JCI", "TT", "GNRC", "WSO", "FAST", "SWK", "PNR", "JBHT"
            ],
            
            "US_ENERGY_EXTENDED": [
                "XOM", "CVX", "COP", "SLB", "EOG", "PSX", "VLO", "MPC", "KMI",
                "OXY", "DVN", "FANG", "APA", "HAL", "BKR", "OIH", "WMB", "ENB",
                "TRP", "EPD", "ET", "MPLX", "PAA", "PAGP", "WES", "DKL"
            ],
            
            "US_MATERIALS": [
                "LIN", "APD", "SHW", "FCX", "NEM", "ALB", "VMC", "MLM", "NUE",
                "STLD", "X", "CLF", "MT", "PKG", "IP", "WRK", "SON", "BALL"
            ],
            
            "US_UTILITIES": [
                "NEE", "SO", "DUK", "AEP", "SRE", "PEG", "EXC", "XEL", "WEC",
                "ES", "AWK", "PPL", "FE", "AES", "NI", "LNT", "ATO", "CMS"
            ],
            
            "US_TELECOM": [
                "T", "VZ", "CHTR", "CMCSA", "TMUS", "DIS", "DISH", "SIRI"
            ],
            
            # ğŸ‡¯ğŸ‡µ æ—¥æœ¬å¸‚å ´ - æ—¥çµŒ225ãƒ»TOPIXå¤§å¹…æ‹¡å¼µ
            "JP_MAJOR_EXTENDED": [
                "7203.T", "6758.T", "9984.T", "4519.T", "6861.T", "9432.T",
                "8306.T", "7267.T", "6367.T", "8031.T", "9433.T", "4063.T",
                "6503.T", "7741.T", "4568.T", "8316.T", "9020.T", "7974.T",
                "6752.T", "6954.T", "4755.T", "9613.T", "4543.T", "8411.T"
            ],
            
            "JP_AUTOMOTIVE_EXTENDED": [
                "7203.T", "7267.T", "7201.T", "7269.T", "7211.T", "7270.T",
                "6902.T", "7259.T", "7261.T", "7205.T", "4080.T", "5108.T",
                "7004.T", "7003.T", "7238.T", "7240.T", "7248.T"
            ],
            
            "JP_ELECTRONICS_EXTENDED": [
                "6758.T", "6861.T", "6954.T", "6963.T", "6971.T", "6976.T",
                "6981.T", "6857.T", "6779.T", "6702.T", "6753.T", "6762.T",
                "6501.T", "6502.T", "6504.T", "6674.T", "6723.T", "6724.T"
            ],
            
            "JP_FINANCIAL_EXTENDED": [
                "8306.T", "8316.T", "8411.T", "8601.T", "8604.T", "8628.T",
                "8630.T", "8766.T", "8750.T", "8697.T", "8331.T", "8332.T",
                "8354.T", "8355.T", "8356.T", "8360.T", "8795.T"
            ],
            
            "JP_RETAIL_CONSUMER": [
                "9983.T", "3382.T", "8267.T", "9831.T", "7832.T", "9843.T",
                "3086.T", "8028.T", "8233.T", "3049.T", "7550.T", "2730.T"
            ],
            
            "JP_MANUFACTURING": [
                "6501.T", "6502.T", "6504.T", "6506.T", "6508.T", "6841.T",
                "6845.T", "6849.T", "6856.T", "6869.T", "6923.T", "6925.T"
            ],
            
            # ğŸ‡ªğŸ‡º æ¬§å·å¸‚å ´ - Euro Stoxx 600å¤§å¹…æ‹¡å¼µ
            "EU_MEGA_CAP": [
                "ASML", "SAP", "NESN.SW", "NOVO-B.CO", "RMS.PA", "SAN.PA",
                "INGA.AS", "ADYEN.AS", "MC.PA", "OR.PA", "AI.PA", "SU.PA",
                "TTE.PA", "BNP.PA", "ACA.PA", "CAP.PA", "BN.PA", "DG.PA"
            ],
            
            "EU_LUXURY_EXTENDED": [
                "MC.PA", "CDI.PA", "CFR.SW", "RMS.PA", "KER.PA", "BUR.L",
                "MONC.MI", "FER.MI", "BOSS.DE", "RIC.PA", "PUGOY"
            ],
            
            "EU_AUTOMOTIVE_EXTENDED": [
                "VOW3.DE", "BMW.DE", "MBG.DE", "STLA", "RNO.PA", "RACE",
                "VOLV-B.ST", "SCAM.MI", "IFX.DE", "CON.DE", "LEO.PA"
            ],
            
            "EU_BANKING": [
                "BNP.PA", "ACA.PA", "GLE.PA", "SAN.MC", "BBVA.MC", "IBE.MC",
                "INGA.AS", "ING.AS", "ABN.AS", "KBC.BR", "ABI.BR"
            ],
            
            "EU_ENERGY": [
                "TTE.PA", "SHEL", "BP", "ENI.MI", "EQNR", "REP.MC",
                "GALP.LS", "OMV.VI", "MOL.BD", "PKN.WA"
            ],
            
            "EU_PHARMA": [
                "NOVO-B.CO", "NVO", "ASND.AS", "GSK.L", "AZN.L", "SAF.PA",
                "SAN.PA", "ROG.SW", "BAYN.DE", "MRK.DE"
            ],
            
            # ğŸ‡¬ğŸ‡§ è‹±å›½å¸‚å ´æ‹¡å¼µ
            "UK_MAJOR_EXTENDED": [
                "SHEL", "AZN", "BP", "ULVR.L", "VOD.L", "BT-A.L", "BARC.L",
                "LLOY.L", "HSBA.L", "GSK.L", "DGE.L", "NG.L", "CNA.L",
                "LSEG.L", "RTO.L", "EXPN.L", "REL.L", "RR.L", "BA.L"
            ],
            
            # ğŸ‡¨ğŸ‡³ ä¸­å›½ãƒ»é¦™æ¸¯å¸‚å ´æ‹¡å¼µ
            "CN_MEGA_CAP": [
                "BABA", "JD", "BIDU", "TCEHY", "NTES", "PDD", "NIO", "XPEV", "LI",
                "BILI", "TME", "VIPS", "WB", "DIDI", "BEKE", "ZTO", "YMM",
                "EDU", "TAL", "GOTU", "COE", "TIGR", "FUTU", "DOYU"
            ],
            
            "CN_FINTECH": [
                "BABA", "TCEHY", "JD", "MOMO", "QFIN", "LX", "PAGS", "STNE",
                "StoneCo", "NU", "MELI", "GLOB", "CPNG"
            ],
            
            # ğŸ‡°ğŸ‡· éŸ“å›½å¸‚å ´æ‹¡å¼µ
            "KR_MAJOR_EXTENDED": [
                "005930.KS", "000660.KS", "035420.KS", "051910.KS", "006400.KS",
                "035720.KS", "028260.KS", "068270.KS", "207940.KS", "005380.KS",
                "005490.KS", "000270.KS", "032830.KS", "003550.KS"
            ],
            
            # ğŸ‡®ğŸ‡³ ã‚¤ãƒ³ãƒ‰å¸‚å ´æ‹¡å¼µ
            "IN_MAJOR_EXTENDED": [
                "INFY", "WIT", "HDB", "IBN", "TCOM", "BABA", "SIFY", "RDY",
                "VEDL", "TTM", "SSTK", "IFS", "REDF", "WNS", "CTSH"
            ],
            
            # ğŸ‡¨ğŸ‡¦ ã‚«ãƒŠãƒ€å¸‚å ´
            "CA_MAJOR": [
                "SHOP", "RY.TO", "TD.TO", "CNQ.TO", "SU.TO", "ENB.TO",
                "TRP.TO", "CNR.TO", "CP.TO", "WCN.TO", "ATD.TO"
            ],
            
            # ğŸ‡¦ğŸ‡º ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢å¸‚å ´
            "AU_MAJOR": [
                "BHP.AX", "CBA.AX", "CSL.AX", "ANZ.AX", "WBC.AX", "NAB.AX",
                "WES.AX", "MQG.AX", "TLS.AX", "RIO.AX", "WDS.AX"
            ],
            
            # ğŸ‡§ğŸ‡· ãƒ–ãƒ©ã‚¸ãƒ«å¸‚å ´
            "BR_MAJOR": [
                "VALE", "ITUB", "BBD", "PBR", "ABEV", "NU", "SBS", "UGP",
                "ERJ", "CIG", "BAK", "CBD", "TIMB", "PAGS", "STNE"
            ],
            
            # ğŸ‡²ğŸ‡½ ãƒ¡ã‚­ã‚·ã‚³å¸‚å ´
            "MX_MAJOR": [
                "AMX", "TV", "KOF", "GFNORTEO", "CEMEXCPO", "WALMEX",
                "FEMSAUBD", "GRUMAB", "ORBIA", "PINFRA"
            ],
            
            # ğŸ‡ªğŸ‡¬ æ–°èˆˆå¸‚å ´
            "EMERGING_MARKETS": [
                "TSM", "UMC", "ASX", "GOLD", "NMR", "SCCO", "FCX", "VALE",
                "RIO", "BHP", "MT", "NUE", "STLD", "X", "CLF", "PKX"
            ]
        }

    def fetch_stock_data_batch(self, symbols: List[str], market_name: str) -> List[Dict]:
        """ãƒãƒƒãƒã§æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        logger.info(f"=== {market_name}å¸‚å ´ {len(symbols)}éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ ===")
        
        successful_fetches = []
        failed_symbols = []
        
        for symbol in symbols:
            try:
                ticker = yf.Ticker(symbol)
                
                # åŸºæœ¬æƒ…å ±å–å¾—
                info = ticker.info
                hist = ticker.history(period="5d")
                
                if hist.empty or not info:
                    failed_symbols.append(symbol)
                    continue
                    
                # æœ€æ–°ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
                latest_data = hist.iloc[-1]
                latest_date = hist.index[-1].strftime('%Y-%m-%d')
                
                # å‰æ—¥æ¯”è¨ˆç®—
                if len(hist) > 1:
                    prev_close = hist.iloc[-2]['Close']
                    change = latest_data['Close'] - prev_close
                    change_percent = (change / prev_close) * 100
                else:
                    change = 0
                    change_percent = 0
                
                # ä¼æ¥­æƒ…å ±
                company_data = {
                    'symbol': symbol.replace('.T', '').replace('.SW', '').replace('.L', '').replace('.PA', '').replace('.DE', '').replace('.AS', '').replace('.CO', '').replace('.KS', '').replace('.AX', '').replace('.TO', '').replace('.MI', '').replace('.MC', '').replace('.ST', '').replace('.BR', '').replace('.VI', '').replace('.BD', '').replace('.WA', '').replace('.LS', ''),
                    'name': info.get('longName', info.get('shortName', symbol)),
                    'sector': info.get('sector', 'Unknown'),
                    'industry': info.get('industry', 'Unknown'), 
                    'country': self.get_country_from_symbol(symbol),
                    'exchange': self.get_exchange_from_symbol(symbol),
                    'market_cap': info.get('marketCap', 0),
                    'current_price': float(latest_data['Close']),
                    'change': float(change),
                    'change_percent': float(change_percent),
                    'volume': int(latest_data['Volume']),
                    'date': latest_date,
                    'market_name': market_name,
                    'price_data': {
                        'open': float(latest_data['Open']),
                        'high': float(latest_data['High']),
                        'low': float(latest_data['Low']),
                        'close': float(latest_data['Close']),
                        'volume': int(latest_data['Volume'])
                    }
                }
                
                successful_fetches.append(company_data)
                logger.info(f"âœ… {symbol}: ${latest_data['Close']:.2f} ({change_percent:+.2f}%)")
                
                time.sleep(0.05)  # ã‚ˆã‚ŠçŸ­ã„ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                
            except Exception as e:
                failed_symbols.append(symbol)
                logger.warning(f"âš ï¸ {symbol} ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
                continue
        
        if failed_symbols:
            logger.warning(f"âŒ {market_name}å¸‚å ´ å¤±æ•—éŠ˜æŸ„ ({len(failed_symbols)}): {failed_symbols[:10]}...")
            
        logger.info(f"âœ… {market_name}å¸‚å ´ æˆåŠŸ: {len(successful_fetches)}/{len(symbols)} éŠ˜æŸ„")
        return successful_fetches

    def get_country_from_symbol(self, symbol: str) -> str:
        """ã‚·ãƒ³ãƒœãƒ«ã‹ã‚‰å›½ã‚’åˆ¤å®š"""
        if '.T' in symbol:
            return 'JP'
        elif '.SW' in symbol:
            return 'CH'
        elif '.DE' in symbol:
            return 'DE'
        elif '.L' in symbol:
            return 'UK'
        elif '.PA' in symbol:
            return 'FR'
        elif '.AS' in symbol:
            return 'NL'
        elif '.CO' in symbol:
            return 'DK'
        elif '.KS' in symbol:
            return 'KR'
        elif '.AX' in symbol:
            return 'AU'
        elif '.TO' in symbol:
            return 'CA'
        elif '.MI' in symbol:
            return 'IT'
        elif '.MC' in symbol:
            return 'ES'
        elif '.ST' in symbol:
            return 'SE'
        elif '.BR' in symbol:
            return 'BE'
        elif '.VI' in symbol:
            return 'AT'
        elif '.BD' in symbol:
            return 'HU'
        elif '.WA' in symbol:
            return 'PL'
        elif '.LS' in symbol:
            return 'PT'
        else:
            return 'US'

    def get_exchange_from_symbol(self, symbol: str) -> str:
        """ã‚·ãƒ³ãƒœãƒ«ã‹ã‚‰å–å¼•æ‰€ã‚’åˆ¤å®š"""
        if '.T' in symbol:
            return 'TSE'
        elif '.SW' in symbol:
            return 'SWX'
        elif '.DE' in symbol:
            return 'XETRA'
        elif '.L' in symbol:
            return 'LSE'
        elif '.PA' in symbol:
            return 'EPA'
        elif '.AS' in symbol:
            return 'AMS'
        elif '.CO' in symbol:
            return 'CSE'
        elif '.KS' in symbol:
            return 'KRX'
        elif '.AX' in symbol:
            return 'ASX'
        elif '.TO' in symbol:
            return 'TSX'
        else:
            return 'NASDAQ'

    def save_stocks_to_database(self, stock_data_list: List[Dict]):
        """æ ªå¼ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¸€æ‹¬ä¿å­˜"""
        if not stock_data_list:
            return
            
        connection = self.get_connection()
        saved_count = 0
        
        try:
            with connection.cursor() as cursor:
                for stock_data in stock_data_list:
                    try:
                        # æ ªå¼ãƒã‚¹ã‚¿æ›´æ–°
                        cursor.execute("""
                            INSERT INTO stock_master (symbol, name, exchange, sector, industry, country, created_at, updated_at, is_active)
                            VALUES (%s, %s, %s, %s, %s, %s, NOW(), NOW(), 1)
                            ON DUPLICATE KEY UPDATE
                            name = VALUES(name),
                            sector = VALUES(sector),
                            industry = VALUES(industry),
                            updated_at = NOW()
                        """, (
                            stock_data['symbol'],
                            stock_data['name'][:200],
                            stock_data['exchange'],
                            stock_data['sector'][:100],
                            stock_data['industry'][:100],
                            stock_data['country']
                        ))
                        
                        # ä¾¡æ ¼å±¥æ­´æ›´æ–°
                        cursor.execute("""
                            INSERT INTO stock_price_history 
                            (symbol, date, open_price, high_price, low_price, close_price, volume, data_source, created_at, updated_at, is_valid, data_quality_score)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), 1, 0.95)
                            ON DUPLICATE KEY UPDATE
                            close_price = VALUES(close_price),
                            volume = VALUES(volume),
                            updated_at = NOW()
                        """, (
                            stock_data['symbol'],
                            stock_data['date'],
                            stock_data['price_data']['open'],
                            stock_data['price_data']['high'],
                            stock_data['price_data']['low'],
                            stock_data['price_data']['close'],
                            stock_data['price_data']['volume'],
                            f"Ultra Massive Real - {stock_data['market_name']}"
                        ))
                        
                        saved_count += 1
                        
                    except Exception as e:
                        logger.error(f"âŒ {stock_data['symbol']} ä¿å­˜å¤±æ•—: {e}")
                        continue
                        
            connection.commit()
            self.expansion_stats['stocks_added'] += saved_count
            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: {saved_count}éŠ˜æŸ„")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            connection.rollback()
        finally:
            connection.close()

    def run_ultra_massive_expansion(self):
        """è¶…å¤§è¦æ¨¡å®Ÿæ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å®Ÿè¡Œ"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ è¶…å¤§è¦æ¨¡å®Ÿæ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("ğŸ¯ ç›®æ¨™: 354éŠ˜æŸ„ â†’ 1000+ éŠ˜æŸ„ã¸ã®è¶…æ‹¡å¼µ")
        
        # æ ªå¼ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹å–å¾—
        stock_universe = self.get_ultra_comprehensive_stock_universe()
        
        all_stock_data = []
        total_symbols = 0
        
        # å„å¸‚å ´ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦åˆ—å‡¦ç†ã§å–å¾—
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            
            for market_name, symbols in stock_universe.items():
                total_symbols += len(symbols)
                logger.info(f"ğŸ“Š {market_name}: {len(symbols)}éŠ˜æŸ„")
                
                # ä¸¦åˆ—ã§ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
                future = executor.submit(self.fetch_stock_data_batch, symbols, market_name)
                futures.append((future, market_name))
            
            # çµæœã‚’åé›†
            for future, market_name in futures:
                try:
                    market_data = future.result()
                    all_stock_data.extend(market_data)
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆãƒãƒƒãƒã”ã¨ï¼‰
                    if market_data:
                        self.save_stocks_to_database(market_data)
                        
                except Exception as e:
                    logger.error(f"âŒ {market_name} ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.expansion_stats['markets_covered'] = len(stock_universe)
        success_rate = (len(all_stock_data) / total_symbols) * 100 if total_symbols > 0 else 0
        
        # å®Œäº†å ±å‘Š
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 70)
        logger.info("ğŸ“Š è¶…å¤§è¦æ¨¡å®Ÿæ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†ã‚µãƒãƒªãƒ¼")
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’")
        logger.info(f"ğŸ¯ å‡¦ç†å¯¾è±¡: {total_symbols}éŠ˜æŸ„")
        logger.info(f"âœ… æˆåŠŸå–å¾—: {len(all_stock_data)}éŠ˜æŸ„")
        logger.info(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜: {self.expansion_stats['stocks_added']}éŠ˜æŸ„")
        logger.info(f"ğŸŒ å¸‚å ´ã‚«ãƒãƒ¼: {self.expansion_stats['markets_covered']}å¸‚å ´")
        logger.info(f"ğŸ¯ æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info(f"âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: ULTRA MASSIVE REAL DATA EXPANSION SUCCESS")
        logger.info("=" * 70)

if __name__ == "__main__":
    expander = UltraMassiveStockExpander()
    
    try:
        logger.info("ğŸš€ è¶…å¤§è¦æ¨¡å®Ÿæ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        logger.info("ğŸŒ å¯¾è±¡å¸‚å ´: ä¸–ç•Œ15ã‚«å›½ãƒ»35å¸‚å ´ãƒ»1000+éŠ˜æŸ„")
        expander.run_ultra_massive_expansion()
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()