#!/usr/bin/env python3
"""
æ‹¡å¼µãƒãƒƒãƒä¾¡æ ¼å–å¾—ã‚·ã‚¹ãƒ†ãƒ 
æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã‚’å›é¿ã—ãªãŒã‚‰å¤§é‡éŠ˜æŸ„ã‚’å‡¦ç†
"""

import yfinance as yf
import psycopg2
import psycopg2.extras
import logging
import time
from datetime import datetime
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedBatchFetcher:
    def __init__(self):
        self.db_config = {
            "host": "34.173.9.214",
            "user": "postgres", 
            "password": "miraikakaku-postgres-secure-2024",
            "database": "miraikakaku",
        }
        self.stats = {
            "processed": 0,
            "successful": 0,
            "failed": 0
        }

    def get_connection(self):
        return psycopg2.connect(**self.db_config)

    def fetch_nyse_nasdaq_batch(self, limit=1000):
        """NYSE/NASDAQéŠ˜æŸ„ã‚’å–å¾—"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # NYSE/NASDAQã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«éŠ˜æŸ„ã‚’é¸æŠ
                cursor.execute("""
                    SELECT symbol, name, exchange 
                    FROM stock_master 
                    WHERE exchange IN ('NYSE', 'NASDAQ')
                    AND symbol NOT IN (
                        SELECT DISTINCT symbol FROM stock_price_history
                    )
                    ORDER BY RAND()
                    LIMIT %s
                """, (limit,))
                
                stocks = cursor.fetchall()
                logger.info(f"ğŸ‡ºğŸ‡¸ NYSE/NASDAQ {len(stocks)}éŠ˜æŸ„ã‚’å‡¦ç†é–‹å§‹")
                
                for stock in stocks:
                    symbol = stock[0]
                    name = stock[1][:100] if stock[1] else symbol
                    
                    self.fetch_and_save_price(symbol, name, "US Batch Enhanced")
                    self.stats["processed"] += 1
                    
                    if self.stats["processed"] % 50 == 0:
                        logger.info(f"ğŸ“ˆ é€²æ—: {self.stats['processed']}ä»¶å‡¦ç† (æˆåŠŸ: {self.stats['successful']})")
                    
                    time.sleep(0.08)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                    
        finally:
            connection.close()

    def fetch_japan_batch(self, limit=500):
        """æ—¥æœ¬å¸‚å ´éŠ˜æŸ„ã‚’å–å¾—"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # æ—¥æœ¬å¸‚å ´ï¼ˆPrime/Standard/Growthï¼‰ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
                cursor.execute("""
                    SELECT symbol, name, exchange 
                    FROM stock_master 
                    WHERE (exchange LIKE '%Prime%' 
                        OR exchange LIKE '%Standard%' 
                        OR exchange LIKE '%Growth%')
                    AND exchange LIKE '%Domestic%'
                    AND symbol NOT IN (
                        SELECT DISTINCT symbol FROM stock_price_history
                    )
                    ORDER BY RAND()
                    LIMIT %s
                """, (limit,))
                
                stocks = cursor.fetchall()
                logger.info(f"ğŸ‡¯ğŸ‡µ æ—¥æœ¬å¸‚å ´ {len(stocks)}éŠ˜æŸ„ã‚’å‡¦ç†é–‹å§‹")
                
                for stock in stocks:
                    symbol = stock[0]
                    name = stock[1][:100] if stock[1] else symbol
                    
                    # 4æ¡æ•°å­—ãªã‚‰.Tã‚’ä»˜ã‘ã‚‹
                    yf_symbol = symbol
                    if len(symbol) == 4 and symbol.isdigit():
                        yf_symbol = symbol + '.T'
                    
                    self.fetch_and_save_price_jp(symbol, yf_symbol, name, "JP Batch Enhanced")
                    self.stats["processed"] += 1
                    
                    if self.stats["processed"] % 50 == 0:
                        logger.info(f"ğŸ“ˆ é€²æ—: {self.stats['processed']}ä»¶å‡¦ç† (æˆåŠŸ: {self.stats['successful']})")
                    
                    time.sleep(0.08)
                    
        finally:
            connection.close()

    def fetch_etf_batch(self, limit=300):
        """ETFéŠ˜æŸ„ã‚’å–å¾—"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # ETFéŠ˜æŸ„ã‚’å–å¾—
                cursor.execute("""
                    SELECT symbol, name, exchange 
                    FROM stock_master 
                    WHERE (exchange LIKE '%ETF%' OR name LIKE '%ETF%')
                    AND symbol NOT IN (
                        SELECT DISTINCT symbol FROM stock_price_history
                    )
                    ORDER BY RAND()
                    LIMIT %s
                """, (limit,))
                
                stocks = cursor.fetchall()
                logger.info(f"ğŸ“Š ETF {len(stocks)}éŠ˜æŸ„ã‚’å‡¦ç†é–‹å§‹")
                
                for stock in stocks:
                    symbol = stock[0]
                    name = stock[1][:100] if stock[1] else symbol
                    
                    self.fetch_and_save_price(symbol, name, "ETF Batch Enhanced")
                    self.stats["processed"] += 1
                    
                    if self.stats["processed"] % 50 == 0:
                        logger.info(f"ğŸ“ˆ é€²æ—: {self.stats['processed']}ä»¶å‡¦ç† (æˆåŠŸ: {self.stats['successful']})")
                    
                    time.sleep(0.08)
                    
        finally:
            connection.close()

    def fetch_europe_batch(self, limit=200):
        """æ¬§å·å¸‚å ´éŠ˜æŸ„ã‚’å–å¾—"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # æ¬§å·å¸‚å ´ã‚’å–å¾—
                cursor.execute("""
                    SELECT symbol, name, exchange, country 
                    FROM stock_master 
                    WHERE country IN ('UK', 'DE', 'FR', 'CH', 'NL', 'IT', 'ES')
                    AND symbol NOT IN (
                        SELECT DISTINCT symbol FROM stock_price_history
                    )
                    ORDER BY RAND()
                    LIMIT %s
                """, (limit,))
                
                stocks = cursor.fetchall()
                logger.info(f"ğŸ‡ªğŸ‡º æ¬§å·å¸‚å ´ {len(stocks)}éŠ˜æŸ„ã‚’å‡¦ç†é–‹å§‹")
                
                for stock in stocks:
                    symbol = stock[0]
                    name = stock[1][:100] if stock[1] else symbol
                    country = stock[3]
                    
                    # å¸‚å ´ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä»˜ã‘ã‚‹
                    yf_symbol = symbol
                    if country == 'UK' and not symbol.endswith('.L'):
                        yf_symbol = symbol + '.L'
                    elif country == 'DE' and not symbol.endswith('.DE'):
                        yf_symbol = symbol + '.DE'
                    elif country == 'FR' and not symbol.endswith('.PA'):
                        yf_symbol = symbol + '.PA'
                    elif country == 'CH' and not symbol.endswith('.SW'):
                        yf_symbol = symbol + '.SW'
                    
                    self.fetch_and_save_price_intl(symbol, yf_symbol, name, "EU Batch Enhanced")
                    self.stats["processed"] += 1
                    
                    if self.stats["processed"] % 50 == 0:
                        logger.info(f"ğŸ“ˆ é€²æ—: {self.stats['processed']}ä»¶å‡¦ç† (æˆåŠŸ: {self.stats['successful']})")
                    
                    time.sleep(0.08)
                    
        finally:
            connection.close()

    def fetch_and_save_price(self, symbol, name, source):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ä¿å­˜ï¼ˆç±³å›½ç‰ˆï¼‰"""
        try:
            ticker = yf.Ticker(symbol)
            hist = ticker.history(period="5d")
            
            if hist.empty:
                self.stats["failed"] += 1
                return False
            
            latest_data = hist.iloc[-1]
            latest_date = hist.index[-1].strftime('%Y-%m-%d')
            
            connection = self.get_connection()
            try:
                with connection.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO stock_price_history 
                        (symbol, date, open_price, high_price, low_price, close_price, volume, 
                         data_source, created_at, updated_at, is_valid, data_quality_score)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), 1, 0.95)
                        ON DUPLICATE KEY UPDATE
                        close_price = VALUES(close_price),
                        volume = VALUES(volume),
                        updated_at = NOW()
                    """, (
                        symbol,
                        latest_date,
                        float(latest_data['Open']),
                        float(latest_data['High']),
                        float(latest_data['Low']),
                        float(latest_data['Close']),
                        int(latest_data['Volume']),
                        source
                    ))
                    
                connection.commit()
                self.stats["successful"] += 1
                logger.info(f"âœ… {symbol}: ${latest_data['Close']:.2f}")
                return True
                
            finally:
                connection.close()
                
        except Exception as e:
            self.stats["failed"] += 1
            return False

    def fetch_and_save_price_jp(self, original_symbol, yf_symbol, name, source):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ä¿å­˜ï¼ˆæ—¥æœ¬ç‰ˆï¼‰"""
        try:
            ticker = yf.Ticker(yf_symbol)
            hist = ticker.history(period="5d")
            
            if hist.empty:
                self.stats["failed"] += 1
                return False
            
            latest_data = hist.iloc[-1]
            latest_date = hist.index[-1].strftime('%Y-%m-%d')
            
            connection = self.get_connection()
            try:
                with connection.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO stock_price_history 
                        (symbol, date, open_price, high_price, low_price, close_price, volume, 
                         data_source, created_at, updated_at, is_valid, data_quality_score)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), 1, 0.95)
                        ON DUPLICATE KEY UPDATE
                        close_price = VALUES(close_price),
                        volume = VALUES(volume),
                        updated_at = NOW()
                    """, (
                        original_symbol,
                        latest_date,
                        float(latest_data['Open']),
                        float(latest_data['High']),
                        float(latest_data['Low']),
                        float(latest_data['Close']),
                        int(latest_data['Volume']),
                        source
                    ))
                    
                connection.commit()
                self.stats["successful"] += 1
                logger.info(f"âœ… {yf_symbol}: Â¥{latest_data['Close']:.0f}")
                return True
                
            finally:
                connection.close()
                
        except Exception as e:
            self.stats["failed"] += 1
            return False

    def fetch_and_save_price_intl(self, original_symbol, yf_symbol, name, source):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ä¿å­˜ï¼ˆå›½éš›ç‰ˆï¼‰"""
        try:
            ticker = yf.Ticker(yf_symbol)
            hist = ticker.history(period="5d")
            
            if hist.empty:
                self.stats["failed"] += 1
                return False
            
            latest_data = hist.iloc[-1]
            latest_date = hist.index[-1].strftime('%Y-%m-%d')
            
            connection = self.get_connection()
            try:
                with connection.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO stock_price_history 
                        (symbol, date, open_price, high_price, low_price, close_price, volume, 
                         data_source, created_at, updated_at, is_valid, data_quality_score)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), 1, 0.95)
                        ON DUPLICATE KEY UPDATE
                        close_price = VALUES(close_price),
                        volume = VALUES(volume),
                        updated_at = NOW()
                    """, (
                        original_symbol,
                        latest_date,
                        float(latest_data['Open']),
                        float(latest_data['High']),
                        float(latest_data['Low']),
                        float(latest_data['Close']),
                        int(latest_data['Volume']),
                        source
                    ))
                    
                connection.commit()
                self.stats["successful"] += 1
                logger.info(f"âœ… {yf_symbol}: {latest_data['Close']:.2f}")
                return True
                
            finally:
                connection.close()
                
        except Exception as e:
            self.stats["failed"] += 1
            return False

    def run_enhanced_batch(self):
        """æ‹¡å¼µãƒãƒƒãƒå®Ÿè¡Œ"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ æ‹¡å¼µãƒãƒƒãƒä¾¡æ ¼å–å¾—é–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ç±³å›½å¸‚å ´ï¼ˆ1000éŠ˜æŸ„ï¼‰
        self.fetch_nyse_nasdaq_batch(1000)
        
        # æ—¥æœ¬å¸‚å ´ï¼ˆ500éŠ˜æŸ„ï¼‰
        self.fetch_japan_batch(500)
        
        # ETFï¼ˆ300éŠ˜æŸ„ï¼‰
        self.fetch_etf_batch(300)
        
        # æ¬§å·å¸‚å ´ï¼ˆ200éŠ˜æŸ„ï¼‰
        self.fetch_europe_batch(200)
        
        # æœ€çµ‚å ±å‘Š
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 70)
        logger.info("ğŸ“Š æ‹¡å¼µãƒãƒƒãƒä¾¡æ ¼å–å¾—å®Œäº†ã‚µãƒãƒªãƒ¼")
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’")
        logger.info(f"ğŸ¯ å‡¦ç†éŠ˜æŸ„: {self.stats['processed']}éŠ˜æŸ„")
        logger.info(f"âœ… æˆåŠŸ: {self.stats['successful']}éŠ˜æŸ„")
        logger.info(f"âŒ å¤±æ•—: {self.stats['failed']}éŠ˜æŸ„")
        logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {(self.stats['successful'] / max(1, self.stats['processed'])) * 100:.1f}%")
        logger.info("=" * 70)

if __name__ == "__main__":
    fetcher = EnhancedBatchFetcher()
    
    try:
        fetcher.run_enhanced_batch()
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢")
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()