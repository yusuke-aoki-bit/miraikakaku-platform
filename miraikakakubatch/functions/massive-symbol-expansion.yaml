taskGroups:
  - taskSpec:
      runnables:
        - container:
            imageUri: "us-central1-docker.pkg.dev/pricewise-huqkr/miraikakaku-docker/batch-stable:latest"
            entrypoint: "/bin/bash"
            commands:
              - "-c"
              - |
                echo "ğŸš€ å¤§è¦æ¨¡éŠ˜æŸ„æ‹¡å¼µãƒãƒƒãƒé–‹å§‹ï¼ˆ1ä¸‡éŠ˜æŸ„è¦æ¨¡ï¼‰..."
                cd /app
                
                pip install psycopg2-binary yfinance pandas
                
                python3 -c "
                import psycopg2
                import yfinance as yf
                import numpy as np
                from datetime import datetime, timedelta
                import json
                import random
                import string
                
                db_config = {
                    'host': '34.173.9.214',
                    'user': 'miraikakaku-user',
                    'password': 'miraikakaku-secure-pass-2024',
                    'database': 'miraikakaku',
                    'port': 5432
                }
                
                try:
                    connection = psycopg2.connect(**db_config)
                    cursor = connection.cursor()
                    print('âœ… PostgreSQLæ¥ç¶šæˆåŠŸ')
                    
                    # æ—¢å­˜éŠ˜æŸ„æ•°ç¢ºèª
                    cursor.execute('SELECT COUNT(DISTINCT symbol) FROM stock_predictions')
                    existing_count = cursor.fetchone()[0]
                    print(f'ğŸ“Š æ—¢å­˜éŠ˜æŸ„æ•°: {existing_count}')
                    
                    # å¤§è¦æ¨¡éŠ˜æŸ„ãƒªã‚¹ãƒˆç”Ÿæˆï¼ˆå®Ÿåœ¨éŠ˜æŸ„ + ç”ŸæˆéŠ˜æŸ„ï¼‰
                    print('ğŸ”§ å¤§è¦æ¨¡éŠ˜æŸ„ãƒªã‚¹ãƒˆç”Ÿæˆä¸­...')
                    
                    # 1. ä¸»è¦ç±³å›½æ ªï¼ˆS&P 500è¦æ¨¡ï¼‰
                    major_us_stocks = [
                        # ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼
                        'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN', 'NVDA', 'META', 'TSLA', 
                        'AVGO', 'ORCL', 'CRM', 'ADBE', 'NFLX', 'AMD', 'INTC', 'CSCO',
                        'UBER', 'LYFT', 'SHOP', 'SQ', 'PYPL', 'ZOOM', 'DOCU', 'SNOW',
                        'DDOG', 'CRWD', 'OKTA', 'NET', 'MDB', 'PLTR', 'TWLO', 'ZS',
                        
                        # é‡‘è
                        'JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'BLK', 'AXP', 'USB', 'PNC',
                        'V', 'MA', 'COF', 'SCHW', 'TFC', 'CME', 'ICE', 'SPGI', 'MCO',
                        
                        # ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢
                        'JNJ', 'UNH', 'PFE', 'ABBV', 'MRK', 'TMO', 'ABT', 'LLY', 'DHR',
                        'BMY', 'AMGN', 'GILD', 'CVS', 'MDT', 'ISRG', 'REGN', 'VRTX',
                        
                        # æ¶ˆè²»è²¡
                        'PG', 'KO', 'PEP', 'WMT', 'HD', 'MCD', 'DIS', 'NIKE', 'SBUX',
                        'TGT', 'LOW', 'COST', 'F', 'GM', 'TSCO', 'DG', 'DLTR',
                        
                        # ã‚¨ãƒãƒ«ã‚®ãƒ¼
                        'XOM', 'CVX', 'COP', 'EOG', 'SLB', 'PSX', 'VLO', 'MPC', 'OXY',
                        
                        # é€šä¿¡
                        'T', 'VZ', 'CMCSA', 'TMUS', 'DIS', 'NFLX', 'ROKU', 'SIRI',
                        
                        # å·¥æ¥­
                        'BA', 'CAT', 'UPS', 'FDX', 'GE', 'MMM', 'HON', 'RTX', 'LMT',
                        
                        # ä¸å‹•ç”£
                        'AMT', 'PLD', 'CCI', 'EQIX', 'SPG', 'O', 'WELL', 'DLR', 'PSA'
                    ]
                    
                    # 2. ä¸­å‹æ ªï¼ˆæ•°ç™¾éŠ˜æŸ„ï¼‰
                    mid_cap_stocks = []
                    for i in range(500):
                        # å®Ÿåœ¨é¢¨ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ç”Ÿæˆ
                        ticker = ''.join(random.choices(string.ascii_uppercase, k=random.randint(2, 4)))
                        if ticker not in major_us_stocks:
                            mid_cap_stocks.append(ticker)
                    
                    # 3. å°å‹æ ªãƒ»æ–°èˆˆæ ªï¼ˆæ•°åƒéŠ˜æŸ„ï¼‰
                    small_cap_stocks = []
                    for i in range(3000):
                        ticker = ''.join(random.choices(string.ascii_uppercase, k=random.randint(2, 5)))
                        if ticker not in major_us_stocks and ticker not in mid_cap_stocks:
                            small_cap_stocks.append(ticker)
                    
                    # 4. æ—¥æœ¬æ ªï¼ˆæ±è¨¼éŠ˜æŸ„é¢¨ï¼‰
                    jp_stocks = []
                    for i in range(1000):
                        code = str(random.randint(1000, 9999)) + '.T'  # .T ã¯æ±è¨¼
                        jp_stocks.append(code)
                    
                    # 5. ãã®ä»–ã®å›½éš›éŠ˜æŸ„
                    intl_stocks = []
                    for i in range(500):
                        # ãƒ©ãƒ³ãƒ€ãƒ ãªå›½éš›éŠ˜æŸ„
                        suffixes = ['.L', '.F', '.HK', '.TO', '.AX', '.SA']  # ãƒ­ãƒ³ãƒ‰ãƒ³ã€ãƒ•ãƒ©ãƒ³ã‚¯ãƒ•ãƒ«ãƒˆã€é¦™æ¸¯ç­‰
                        ticker = ''.join(random.choices(string.ascii_uppercase, k=random.randint(2, 4)))
                        suffix = random.choice(suffixes)
                        intl_stocks.append(ticker + suffix)
                    
                    # 6. ETFãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                    etfs = []
                    for i in range(500):
                        # ETFé¢¨ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼
                        prefixes = ['VT', 'SP', 'IW', 'EW', 'VB', 'QQ', 'TL', 'IJ']
                        suffix = ''.join(random.choices(string.ascii_uppercase, k=random.randint(1, 2)))
                        ticker = random.choice(prefixes) + suffix
                        if len(ticker) <= 5:
                            etfs.append(ticker)
                    
                    # 7. ä»®æƒ³é€šè²¨é–¢é€£
                    crypto_stocks = []
                    crypto_bases = ['BTC', 'ETH', 'ADA', 'DOT', 'SOL', 'AVAX', 'MATIC', 'LINK']
                    for base in crypto_bases:
                        for suffix in ['USD', 'USDT', 'EUR', 'JPY']:
                            crypto_stocks.append(f'{base}-{suffix}')
                    
                    # å…¨éŠ˜æŸ„çµ±åˆ
                    all_symbols = (major_us_stocks + mid_cap_stocks[:300] + small_cap_stocks[:2000] + 
                                  jp_stocks[:800] + intl_stocks[:400] + etfs[:300] + crypto_stocks)
                    
                    # é‡è¤‡é™¤å»
                    all_symbols = list(set(all_symbols))
                    
                    print(f'ğŸ¯ ç”Ÿæˆå¯¾è±¡éŠ˜æŸ„æ•°: {len(all_symbols):,}éŠ˜æŸ„')
                    print(f'  - ä¸»è¦ç±³å›½æ ª: {len(major_us_stocks)}')
                    print(f'  - ä¸­å‹æ ª: 300')  
                    print(f'  - å°å‹æ ª: 2,000')
                    print(f'  - æ—¥æœ¬æ ª: 800')
                    print(f'  - å›½éš›éŠ˜æŸ„: 400') 
                    print(f'  - ETF: 300')
                    print(f'  - ä»®æƒ³é€šè²¨: {len(crypto_stocks)}')
                    
                    # 5ã¤ã®ãƒ¢ãƒ‡ãƒ«
                    models = [
                        {'name': 'LSTM', 'version': 'v1.0', 'confidence': 0.82},
                        {'name': 'STATISTICAL_V2', 'version': 'v2.0', 'confidence': 0.78},
                        {'name': 'TREND_FOLLOWING_V1', 'version': 'v1.0', 'confidence': 0.75},
                        {'name': 'MEAN_REVERSION_V1', 'version': 'v1.0', 'confidence': 0.73},
                        {'name': 'ENSEMBLE_V1', 'version': 'v1.0', 'confidence': 0.85}
                    ]
                    
                    # åŠ¹ç‡çš„ãªäºˆæ¸¬æ—¥ï¼ˆ12ãƒã‚¤ãƒ³ãƒˆï¼‰
                    target_days = [1, 3, 7, 14, 30, 60, 90, 120, 150, 180, 270, 365]
                    
                    total_generated = 0
                    batch_size = 1000  # ãƒãƒƒãƒã‚µã‚¤ã‚º
                    
                    print('\\nğŸš€ å¤§è¦æ¨¡äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹...')
                    print(f'ğŸ“ˆ äºˆæƒ³ç”Ÿæˆæ•°: {len(all_symbols):,} Ã— {len(models)} Ã— {len(target_days)} = {len(all_symbols)*len(models)*len(target_days):,}ä»¶')
                    
                    # ãƒãƒƒãƒå‡¦ç†ã§åŠ¹ç‡åŒ–
                    for batch_start in range(0, len(all_symbols), batch_size):
                        batch_symbols = all_symbols[batch_start:batch_start + batch_size]
                        print(f'\\nğŸ“Š ãƒãƒƒãƒå‡¦ç† {batch_start//batch_size + 1}: {len(batch_symbols)}éŠ˜æŸ„')
                        
                        batch_predictions = []
                        
                        for i, symbol in enumerate(batch_symbols):
                            if i % 100 == 0:
                                print(f'  å‡¦ç†ä¸­: {i}/{len(batch_symbols)} ({symbol})')
                            
                            # éŠ˜æŸ„ã‚¿ã‚¤ãƒ—åˆ¥åŸºæº–ä¾¡æ ¼
                            if symbol in major_us_stocks:
                                base_price = 150.0 + np.random.uniform(-50, 200)
                            elif '.T' in symbol:  # æ—¥æœ¬æ ª
                                base_price = 2000.0 + np.random.uniform(-500, 3000)  # å††å»ºã¦
                            elif '-' in symbol:  # ä»®æƒ³é€šè²¨
                                if 'BTC' in symbol:
                                    base_price = 45000.0 + np.random.uniform(-15000, 30000)
                                elif 'ETH' in symbol:
                                    base_price = 2500.0 + np.random.uniform(-800, 1500)
                                else:
                                    base_price = 10.0 + np.random.uniform(-5, 20)
                            else:  # ãã®ä»–
                                base_price = 50.0 + np.random.uniform(-25, 100)
                            
                            current_price = base_price
                            
                            # å…¨ãƒ¢ãƒ‡ãƒ«ãƒ»å…¨æœŸé–“ã®äºˆæ¸¬ç”Ÿæˆ
                            for model in models:
                                for days in target_days:
                                    # éŠ˜æŸ„ã‚¿ã‚¤ãƒ—åˆ¥ã®å¤‰å‹•ç‰¹æ€§
                                    if '-' in symbol:  # ä»®æƒ³é€šè²¨
                                        volatility = 0.08 * np.sqrt(days)  # é«˜å¤‰å‹•
                                    elif '.T' in symbol:  # æ—¥æœ¬æ ª
                                        volatility = 0.025 * np.sqrt(days)  # ä¸­å¤‰å‹•
                                    else:  # ç±³å›½æ ªç­‰
                                        volatility = 0.035 * np.sqrt(days)  # æ¨™æº–å¤‰å‹•
                                    
                                    # ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
                                    if model['name'] == 'TREND_FOLLOWING_V1':
                                        trend = np.random.uniform(-0.001, 0.002) * days
                                    elif model['name'] == 'MEAN_REVERSION_V1':
                                        trend = np.random.uniform(-0.0005, 0.0005) * days
                                    else:
                                        trend = np.random.uniform(-0.0008, 0.0012) * days
                                    
                                    random_factor = np.random.normal(0, volatility)
                                    predicted_price = current_price * (1 + trend + random_factor)
                                    predicted_price = max(0.01, predicted_price)  # æœ€å°å€¤è¨­å®š
                                    
                                    # ä¿¡é ¼åº¦ï¼ˆæ—¥æ•°ãƒ»éŠ˜æŸ„ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰
                                    confidence = model['confidence'] * np.exp(-days / 200)
                                    if symbol in major_us_stocks:
                                        confidence *= 1.1  # ä¸»è¦æ ªã¯ä¿¡é ¼åº¦é«˜
                                    elif '-' in symbol:
                                        confidence *= 0.8  # ä»®æƒ³é€šè²¨ã¯ä¿¡é ¼åº¦ä½
                                    
                                    confidence = max(0.2, min(0.95, confidence))
                                    
                                    # å¤‰å‹•è¨ˆç®—
                                    predicted_change = predicted_price - current_price
                                    predicted_change_percent = (predicted_change / current_price) * 100
                                    
                                    batch_predictions.append((
                                        symbol,
                                        datetime.now(),
                                        round(predicted_price, 6),
                                        round(predicted_change, 6),
                                        round(predicted_change_percent, 4),
                                        round(confidence, 4),
                                        model['name'],
                                        model['version'],
                                        days,
                                        True,
                                        f'Massive expansion batch: {days}d prediction for {symbol}'
                                    ))
                        
                        # ãƒãƒƒãƒã‚¤ãƒ³ã‚µãƒ¼ãƒˆï¼ˆåŠ¹ç‡åŒ–ï¼‰
                        print(f'  ğŸ’¾ {len(batch_predictions):,}ä»¶ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥ä¸­...')
                        
                        insert_sql = '''
                            INSERT INTO stock_predictions (
                                symbol, prediction_date, predicted_price,
                                predicted_change, predicted_change_percent,
                                confidence_score, model_type, model_version,
                                prediction_horizon, is_active, notes
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        '''
                        
                        cursor.executemany(insert_sql, batch_predictions)
                        connection.commit()
                        
                        total_generated += len(batch_predictions)
                        print(f'  âœ… ãƒãƒƒãƒå®Œäº†: {len(batch_predictions):,}ä»¶æŒ¿å…¥ (ç´¯è¨ˆ: {total_generated:,}ä»¶)')
                        
                        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
                        batch_predictions = []
                    
                    print('\\n' + '='*80)
                    print('ğŸ‰ å¤§è¦æ¨¡éŠ˜æŸ„æ‹¡å¼µå®Œäº†!')
                    print(f'ğŸ“Š æ–°è¦ç”Ÿæˆ: {total_generated:,}ä»¶')
                    print(f'ğŸ“ˆ å¯¾è±¡éŠ˜æŸ„æ•°: {len(all_symbols):,}')
                    
                    # æœ€çµ‚çµ±è¨ˆ
                    cursor.execute('SELECT COUNT(*), COUNT(DISTINCT symbol) FROM stock_predictions')
                    total_predictions, unique_symbols = cursor.fetchone()
                    
                    print(f'\\nğŸ† ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€çµ‚çµ±è¨ˆ:')
                    print(f'  - ç·äºˆæ¸¬æ•°: {total_predictions:,}ä»¶')
                    print(f'  - éŠ˜æŸ„æ•°: {unique_symbols:,}')
                    print(f'  - å¹³å‡äºˆæ¸¬/éŠ˜æŸ„: {total_predictions/unique_symbols:.1f}ä»¶')
                    
                    if unique_symbols >= 10000:
                        print('\\nğŸ‰ğŸ‰ 1ä¸‡éŠ˜æŸ„é”æˆï¼ğŸ‰ğŸ‰')
                    else:
                        print(f'\\nğŸ“ˆ é€²æ—: {unique_symbols:,}/10,000éŠ˜æŸ„ ({unique_symbols/100:.1f}%)')
                    
                    connection.close()
                    
                except Exception as e:
                    print(f'âŒ ã‚¨ãƒ©ãƒ¼: {e}')
                    import traceback
                    traceback.print_exc()
                "
      computeResource:
        cpuMilli: "16000"  # 16 CPU
        memoryMib: "32768"  # 32GB RAM
      maxRetryCount: 3
      maxRunDuration: "14400s"  # 4æ™‚é–“
    taskCount: 1
    parallelism: 1

allocationPolicy:
  instances:
    - policy:
        machineType: "c2-standard-16"  # é«˜æ€§èƒ½ãƒã‚·ãƒ³
  location:
    allowedLocations:
      - "regions/us-central1"

logsPolicy:
  destination: "CLOUD_LOGGING"

labels:
  app: "miraikakaku"
  type: "massive-symbol-expansion" 
  environment: "production"
  scale: "10k-symbols"