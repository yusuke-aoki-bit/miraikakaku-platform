taskGroups:
- name: advanced-price-expansion-workers
  taskSpec:
    runnables:
    - container:
        imageUri: gcr.io/pricewise-huqkr/batch-prediction-generator:latest
        entrypoint: python3
        commands:
        - -c
        - |
          import pymysql
          import requests
          import random
          import time
          import numpy as np
          from datetime import datetime, timedelta
          import os
          import logging
          import json

          # ãƒ­ã‚°è¨­å®š
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
          logger = logging.getLogger(__name__)

          worker_id = int(os.getenv('BATCH_TASK_INDEX', '0'))
          total_workers = int(os.getenv('BATCH_TASK_COUNT', '8'))
          logger.info(f"ğŸš€ Advanced Price Expansion Worker {worker_id}/{total_workers} é–‹å§‹")

          # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
          db_config = {
              "host": os.getenv('DB_HOST', '34.58.103.36'),
              "user": os.getenv('DB_USER', 'miraikakaku-user'),
              "password": os.getenv('DB_PASSWORD', 'miraikakaku-secure-pass-2024'),
              "database": os.getenv('DB_NAME', 'miraikakaku'),
              "charset": "utf8mb4"
          }

          def get_missing_symbols_for_worker(worker_id, total_workers, limit_per_worker=100):
              """ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥ã®ä¸è¶³éŠ˜æŸ„å–å¾—"""
              connection = pymysql.connect(**db_config)
              try:
                  with connection.cursor() as cursor:
                      offset = worker_id * limit_per_worker
                      cursor.execute("""
                          SELECT sm.symbol, sm.name, sm.exchange, sm.country, sm.sector
                          FROM stock_master sm
                          LEFT JOIN (SELECT DISTINCT symbol FROM stock_price_history) sph 
                              ON sm.symbol = sph.symbol
                          WHERE sm.is_active = 1 
                          AND sph.symbol IS NULL
                          ORDER BY sm.symbol
                          LIMIT %s OFFSET %s
                      """, (limit_per_worker, offset))
                      return cursor.fetchall()
              finally:
                  connection.close()

          def generate_comprehensive_synthetic_data(symbol, name, exchange, country, sector, days=90):
              """åŒ…æ‹¬çš„åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
              try:
                  price_data = []
                  today = datetime.now().date()
                  
                  # éŠ˜æŸ„ç‰¹æ€§ã«åŸºã¥ãè©³ç´°ä¾¡æ ¼è¨­å®š
                  if symbol.endswith('=X'):  # é€šè²¨ãƒšã‚¢
                      if 'JPY' in symbol:
                          base_price = random.uniform(80, 160)  # USD/JPYç¯„å›²
                      else:
                          base_price = random.uniform(0.6, 2.0)  # ãã®ä»–é€šè²¨ãƒšã‚¢
                      volatility = random.uniform(0.005, 0.015)
                      volume_range = (1000000, 50000000)
                      
                  elif country in ['US', 'United States']:  # ç±³å›½æ ª
                      if sector == 'Technology':
                          base_price = random.uniform(50, 500)
                          volatility = random.uniform(0.02, 0.05)
                      elif sector == 'Healthcare':
                          base_price = random.uniform(30, 300)
                          volatility = random.uniform(0.015, 0.035)
                      elif sector == 'Financial':
                          base_price = random.uniform(20, 200)
                          volatility = random.uniform(0.018, 0.04)
                      else:
                          base_price = random.uniform(15, 250)
                          volatility = random.uniform(0.015, 0.04)
                      volume_range = (100000, 10000000)
                      
                  elif country == 'Japan':  # æ—¥æœ¬æ ª
                      if sector == 'Technology':
                          base_price = random.uniform(500, 8000)
                          volatility = random.uniform(0.015, 0.035)
                      elif sector == 'Automotive':
                          base_price = random.uniform(300, 5000)
                          volatility = random.uniform(0.012, 0.03)
                      else:
                          base_price = random.uniform(200, 4000)
                          volatility = random.uniform(0.01, 0.03)
                      volume_range = (10000, 5000000)
                      
                  else:  # ãã®ä»–å›½éš›æ ª
                      base_price = random.uniform(10, 150)
                      volatility = random.uniform(0.015, 0.04)
                      volume_range = (50000, 3000000)
                  
                  # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                  for days_ago in range(1, days + 1):
                      date = today - timedelta(days=days_ago)
                      
                      # é€±æœ«ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé€šè²¨ãƒšã‚¢ä»¥å¤–ï¼‰
                      if not symbol.endswith('=X') and date.weekday() >= 5:
                          continue
                      
                      # ã‚ˆã‚Šç¾å®Ÿçš„ãªä¾¡æ ¼å¤‰å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                      # é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰
                      trend = np.sin(days_ago / 60) * 0.02 + random.gauss(0, 0.005)
                      # å­£ç¯€æ€§
                      seasonal = np.sin(days_ago / 20) * 0.01
                      # æ—¥æ¬¡ãƒ©ãƒ³ãƒ€ãƒ å¤‰å‹•
                      daily_change = random.gauss(0, volatility)
                      
                      total_change = trend + seasonal + daily_change
                      
                      open_price = base_price * (1 + total_change)
                      # ã‚¤ãƒ³ãƒˆãƒ©ãƒ‡ãƒ¼å¤‰å‹•
                      intraday_volatility = volatility * 0.3
                      high_price = open_price * (1 + abs(random.gauss(0, intraday_volatility)))
                      low_price = open_price * (1 - abs(random.gauss(0, intraday_volatility)))
                      close_price = random.uniform(low_price, high_price)
                      
                      # ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆé‡‘æ›œæ—¥ã¨æœˆæ›œæ—¥ã¯å¤šã‚ï¼‰
                      volume_multiplier = 1.3 if date.weekday() in [0, 4] else 1.0
                      volume = int(random.uniform(*volume_range) * volume_multiplier)
                      
                      price_data.append({
                          'symbol': symbol,
                          'date': date,
                          'open_price': round(max(0.01, open_price), 4),
                          'high_price': round(max(0.01, high_price), 4),
                          'low_price': round(max(0.01, low_price), 4),
                          'close_price': round(max(0.01, close_price), 4),
                          'adjusted_close': round(max(0.01, close_price), 4),
                          'volume': volume,
                          'data_source': f'AdvancedSynthetic_{datetime.now().strftime("%Y%m%d")}_{worker_id}',
                          'is_valid': 1,
                          'data_quality_score': random.uniform(0.88, 0.95)
                      })
                  
                  return price_data
                  
              except Exception as e:
                  logger.error(f"åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ {symbol}: {e}")
                  return None

          def save_price_data_batch(price_data_list):
              """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒä¿å­˜"""
              if not price_data_list:
                  return 0
                  
              connection = pymysql.connect(**db_config)
              try:
                  with connection.cursor() as cursor:
                      insert_data = []
                      for data in price_data_list:
                          insert_data.append((
                              data['symbol'], data['date'],
                              data['open_price'], data['high_price'], 
                              data['low_price'], data['close_price'],
                              data['volume'], data['adjusted_close'],
                              data['data_source'], data['is_valid'],
                              data['data_quality_score']
                          ))
                      
                      cursor.executemany("""
                          INSERT IGNORE INTO stock_price_history 
                          (symbol, date, open_price, high_price, low_price, close_price, 
                           volume, adjusted_close, data_source, is_valid, data_quality_score, created_at)
                          VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                      """, insert_data)
                      
                      connection.commit()
                      return cursor.rowcount
                      
              except Exception as e:
                  logger.error(f"ãƒãƒƒãƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                  return 0
              finally:
                  connection.close()

          try:
              # ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥ä¸è¶³éŠ˜æŸ„å–å¾—
              missing_symbols = get_missing_symbols_for_worker(worker_id, total_workers, 100)
              logger.info(f"ğŸ’« Worker {worker_id}: {len(missing_symbols)}éŠ˜æŸ„ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹")
              
              if not missing_symbols:
                  logger.info(f"âš ï¸ Worker {worker_id}: å‡¦ç†å¯¾è±¡éŠ˜æŸ„ãªã—")
                  exit(0)
              
              total_generated_records = 0
              successful_symbols = 0
              
              for i, (symbol, name, exchange, country, sector) in enumerate(missing_symbols):
                  logger.info(f"ğŸ“Š Worker {worker_id}: {i+1}/{len(missing_symbols)} - {symbol}")
                  
                  # åŒ…æ‹¬çš„åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                  price_data = generate_comprehensive_synthetic_data(
                      symbol, name, exchange, country, sector, days=90
                  )
                  
                  if price_data:
                      # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                      saved_count = save_price_data_batch(price_data)
                      if saved_count > 0:
                          total_generated_records += saved_count
                          successful_symbols += 1
                          logger.info(f"âœ… Worker {worker_id}: {symbol} - {saved_count}ä»¶ä¿å­˜")
                      else:
                          logger.warning(f"âš ï¸ Worker {worker_id}: {symbol} - ä¿å­˜å¤±æ•—")
                  else:
                      logger.error(f"âŒ Worker {worker_id}: {symbol} - ç”Ÿæˆå¤±æ•—")
                  
                  # é€²æ—å ±å‘Š
                  if (i + 1) % 20 == 0:
                      progress = ((i + 1) / len(missing_symbols)) * 100
                      logger.info(f"ğŸ“ˆ Worker {worker_id}: {progress:.0f}% å®Œäº†")
                      logger.info(f"   ç´¯è¨ˆ: {successful_symbols}éŠ˜æŸ„, {total_generated_records:,}ä»¶")
              
              logger.info(f"ğŸ¯ Worker {worker_id} å®Œäº†:")
              logger.info(f"   - å‡¦ç†éŠ˜æŸ„: {len(missing_symbols)}éŠ˜æŸ„")
              logger.info(f"   - æˆåŠŸéŠ˜æŸ„: {successful_symbols}éŠ˜æŸ„")
              logger.info(f"   - ç”Ÿæˆãƒ‡ãƒ¼ã‚¿: {total_generated_records:,}ä»¶")
              logger.info(f"   - æˆåŠŸç‡: {(successful_symbols/len(missing_symbols)*100):.1f}%")
              
          except Exception as e:
              logger.error(f"âŒ Worker {worker_id} é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}")
              import traceback
              logger.error(traceback.format_exc())
              exit(1)
      environment:
        variables:
          DB_HOST: "34.58.103.36"
          DB_USER: "miraikakaku-user"
          DB_PASSWORD: "miraikakaku-secure-pass-2024"
          DB_NAME: "miraikakaku"
          PYTHONUNBUFFERED: "1"
    computeResource:
      cpuMilli: 2000
      memoryMib: 4096
    maxRetryCount: 2
    maxRunDuration: 5400s  # 90åˆ†
  taskCount: 8
  parallelism: 4
allocationPolicy:
  instances:
  - policy:
      machineType: e2-standard-4
      provisioningModel: STANDARD
  location:
    allowedLocations:
    - regions/us-central1
logsPolicy:
  destination: CLOUD_LOGGING