#!/usr/bin/env python3
"""
æ‹¡å¼µã‚·ãƒ³ãƒœãƒ«ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ - ã‚ˆã‚Šå¤šãã®éŠ˜æŸ„ã‚’åé›†ã™ã‚‹ãŸã‚ã®ã‚·ã‚¹ãƒ†ãƒ 
"""

import psycopg2
import yfinance as yf
import logging
from datetime import datetime, timedelta
import time
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ExpandedSymbolCollector:
    def __init__(self):
        self.db_config = {
            "host": "34.173.9.214",
            "user": "postgres",
            "password": "os.getenv('DB_PASSWORD', '')",
            "database": "miraikakaku",
            "port": 5432
        }

    def get_expanded_symbol_list(self):
        """å¤§å¹…ã«æ‹¡å¼µã•ã‚ŒãŸéŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return [
            # US ãƒ¡ã‚¬ã‚­ãƒ£ãƒƒãƒ— ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ (100+)
            'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN', 'NVDA', 'TSLA', 'META',
            'NFLX', 'ADBE', 'CRM', 'ORCL', 'CSCO', 'INTC', 'QCOM', 'TXN',
            'AVGO', 'IBM', 'NOW', 'AMD', 'MU', 'AMAT', 'ADI', 'LRCX', 'MRVL',
            'KLAC', 'CDNS', 'SNPS', 'FTNT', 'PANW', 'CRWD', 'ZS', 'OKTA',
            'DDOG', 'NET', 'SNOW', 'MDB', 'PLTR', 'PALANTIR', 'RBLX',

            # US é‡‘è (50+)
            'JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'USB', 'PNC', 'TFC', 'COF',
            'AXP', 'BLK', 'SPGI', 'CME', 'ICE', 'CB', 'PGR', 'AIG', 'MET', 'PRU',
            'AFL', 'ALL', 'TRV', 'HIG', 'CMA', 'FITB', 'KEY', 'RF', 'CFG', 'HBAN',

            # US ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ (50+)
            'JNJ', 'PFE', 'UNH', 'CVS', 'MRK', 'ABBV', 'TMO', 'DHR', 'ABT',
            'LLY', 'BMY', 'AMGN', 'GILD', 'ISRG', 'SYK', 'BSX', 'MDT', 'ZTS',
            'VRTX', 'REGN', 'BIIB', 'ILMN', 'MRNA', 'NVAX', 'BNT', 'PFE',
            'BNTX', 'JNJ', 'RGEN', 'ALNY', 'BMRN', 'BLUE', 'CRSP',

            # US ã‚¨ãƒãƒ«ã‚®ãƒ¼ (30+)
            'XOM', 'CVX', 'COP', 'EOG', 'SLB', 'PSX', 'VLO', 'MPC', 'OXY', 'BKR',
            'HAL', 'APA', 'DVN', 'FANG', 'EQT', 'CNX', 'AR', 'SM', 'MRO', 'CHK',

            # US æ¶ˆè²»è²¡ (50+)
            'PG', 'KO', 'PEP', 'WMT', 'HD', 'MCD', 'NKE', 'SBUX', 'TGT', 'LOW',
            'COST', 'KMB', 'CL', 'CLX', 'CHD', 'GIS', 'K', 'CPB', 'CAG', 'TSN',
            'HRL', 'SJM', 'MKC', 'LW', 'PM', 'MO', 'BTI', 'IMBBY',

            # æ—¥æœ¬ä¸»è¦éŠ˜æŸ„ (200+)
            # è‡ªå‹•è»Š
            '7203.T', '7267.T', '7269.T', '7270.T', '7201.T', '7202.T', '7211.T',
            '7261.T', '7272.T', '7259.T', '7244.T', '7205.T', '7240.T',

            # é‡‘è
            '8306.T', '8316.T', '8354.T', '8355.T', '8411.T', '8473.T', '8604.T',
            '8750.T', '8766.T', '8795.T', '8801.T', '8802.T', '8830.T',

            # ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼
            '6758.T', '6861.T', '6503.T', '6504.T', '6506.T', '6594.T', '6674.T',
            '6701.T', '6702.T', '6703.T', '6723.T', '6724.T', '6752.T', '6753.T',
            '6762.T', '6770.T', '6806.T', '6841.T', '6856.T', '6857.T',

            # é€šä¿¡ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢
            '9432.T', '9433.T', '9434.T', '9613.T', '9984.T', '9983.T', '4755.T',
            '4689.T', '4751.T', '4324.T', '4385.T', '4776.T',

            # è£½è–¬ãƒ»åŒ–å­¦
            '4519.T', '4568.T', '4523.T', '4578.T', '4508.T', '4506.T', '4507.T',
            '4041.T', '4042.T', '4043.T', '4061.T', '4063.T', '4080.T',

            # å°å£²ãƒ»æ¶ˆè²»
            '7974.T', '7832.T', '7751.T', '8233.T', '8267.T', '8252.T', '9843.T',

            # æ¬§å·ä¸»è¦éŠ˜æŸ„ (100+)
            'ASML', 'SAP', 'NESN.SW', 'NOVO-B.CO', 'RMS.PA', 'SAN.PA',
            'INGA.AS', 'ADYEN.AS', 'MC.PA', 'OR.PA', 'AI.PA', 'SU.PA',
            'BAS.DE', 'SAP.DE', 'ALV.DE', 'SIE.DE', 'DTE.DE', 'VOW3.DE',
            'BMW.DE', 'MBG.DE', 'FRE.DE', 'HEN3.DE', 'LIN.DE', 'MRK.DE',

            # ä¸­å›½ãƒ»ã‚¢ã‚¸ã‚¢ä¸»è¦ (50+)
            'BABA', 'JD', 'BIDU', 'TCEHY', 'NTES', 'PDD', 'NIO', 'XPEV', 'LI',
            'DIDI', 'TME', 'BILI', 'IQ', 'VIPS', 'FUTU', 'TIGR',
            '005930.KS', '000660.KS', '035420.KS', '207940.KS', '068270.KS',

            # éŸ“å›½ä¸»è¦
            '005930.KS', '000660.KS', '035420.KS', '207940.KS', '005380.KS',
            '017670.KS', '090430.KS', '066570.KS', '003550.KS', '015760.KS',

            # ã‚¤ãƒ³ãƒ‰ä¸»è¦
            'INFY', 'TCS.NS', 'WIPRO.NS', 'HCLTECH.NS', 'TECHM.NS',
            'RELIANCE.NS', 'HINDUNILVR.NS', 'ITC.NS', 'SBIN.NS', 'HDFCBANK.NS',

            # ã‚«ãƒŠãƒ€ä¸»è¦
            'SHOP.TO', 'WEED.TO', 'ACB.TO', 'BB.TO', 'SU.TO', 'CNQ.TO',
            'CP.TO', 'CNR.TO', 'RY.TO', 'TD.TO', 'BNS.TO', 'BMO.TO',

            # ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢ä¸»è¦
            'CBA.AX', 'ANZ.AX', 'WBC.AX', 'NAB.AX', 'BHP.AX', 'RIO.AX',
            'CSL.AX', 'WOW.AX', 'WES.AX', 'TLS.AX', 'TCL.AX',

            # ETFãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            'SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'VTI', 'VXUS', 'BND', 'AGG',
            'GLD', 'SLV', 'USO', 'UNG', 'TLT', 'HYG', 'LQD', 'VNQ',

            # æš—å·é€šè²¨é–¢é€£
            'COIN', 'MSTR', 'RIOT', 'MARA', 'HUT', 'BITF', 'SOS', 'EBON',

            # REIT
            'AMT', 'PLD', 'CCI', 'EQIX', 'PSA', 'O', 'WELL', 'DLR', 'SPG', 'AVB',

            # å•†å“ãƒ»åŸææ–™
            'FCX', 'NEM', 'GOLD', 'AA', 'X', 'CLF', 'MT', 'VALE', 'RIO', 'BHP',

            # å…¬ç›Šäº‹æ¥­
            'NEE', 'DUK', 'SO', 'AEP', 'EXC', 'XEL', 'D', 'PCG', 'ED', 'ES'
        ]

    def collect_expanded_data(self, max_symbols=500, batch_size=50):
        """æ‹¡å¼µã‚·ãƒ³ãƒœãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åé›†"""
        connection = psycopg2.connect(**self.db_config)

        try:
            with connection.cursor() as cursor:
                logger.info("ğŸš€ æ‹¡å¼µã‚·ãƒ³ãƒœãƒ«åé›†é–‹å§‹")

                all_symbols = self.get_expanded_symbol_list()
                symbols_to_process = all_symbols[:max_symbols] if max_symbols else all_symbols

                logger.info(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {len(symbols_to_process)}éŠ˜æŸ„")

                total_successful = 0
                total_errors = 0

                for batch_start in range(0, len(symbols_to_process), batch_size):
                    batch_symbols = symbols_to_process[batch_start:batch_start + batch_size]

                    batch_successful, batch_errors = self.process_symbol_batch(cursor, batch_symbols)
                    total_successful += batch_successful
                    total_errors += batch_errors

                    connection.commit()

                    progress = ((batch_start + len(batch_symbols)) / len(symbols_to_process)) * 100
                    logger.info(f"ğŸ“ˆ é€²æ—: {progress:.1f}% (æˆåŠŸ{total_successful}ä»¶, ã‚¨ãƒ©ãƒ¼{total_errors}ä»¶)")

                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                    time.sleep(2)

                logger.info(f"âœ… æ‹¡å¼µåé›†å®Œäº†: æˆåŠŸ{total_successful}ä»¶, ã‚¨ãƒ©ãƒ¼{total_errors}ä»¶")
                return total_successful

        except Exception as e:
            logger.error(f"âŒ æ‹¡å¼µåé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
        finally:
            connection.close()

    def process_symbol_batch(self, cursor, symbols):
        """ã‚·ãƒ³ãƒœãƒ«ãƒãƒƒãƒã®ä¸¦åˆ—å‡¦ç†"""
        successful_count = 0
        error_count = 0

        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_symbol = {
                executor.submit(self.fetch_symbol_data, symbol): symbol
                for symbol in symbols
            }

            price_updates = []

            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    price_data = future.result()
                    if price_data:
                        price_updates.append(price_data)
                        successful_count += 1
                    else:
                        error_count += 1
                except Exception as e:
                    logger.debug(f"âš ï¸ {symbol}: {e}")
                    error_count += 1

            # ãƒãƒƒãƒæŒ¿å…¥
            if price_updates:
                self.batch_insert_prices(cursor, price_updates)

        return successful_count, error_count

    def fetch_symbol_data(self, symbol):
        """å€‹åˆ¥ã‚·ãƒ³ãƒœãƒ«ã®ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            ticker = yf.Ticker(symbol)

            # éå»5æ—¥ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
            hist = ticker.history(period="5d", interval="1d")

            if hist.empty:
                return None

            # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            latest_data = hist.iloc[-1]
            latest_date = hist.index[-1].date()

            return {
                'symbol': symbol,
                'date': latest_date,
                'open': round(float(latest_data['Open']), 2) if not pd.isna(latest_data['Open']) else 0.0,
                'high': round(float(latest_data['High']), 2) if not pd.isna(latest_data['High']) else 0.0,
                'low': round(float(latest_data['Low']), 2) if not pd.isna(latest_data['Low']) else 0.0,
                'close': round(float(latest_data['Close']), 2) if not pd.isna(latest_data['Close']) else 0.0,
                'volume': int(latest_data['Volume']) if not pd.isna(latest_data['Volume']) else 0
            }

        except Exception as e:
            logger.debug(f"ğŸ” {symbol}: ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— - {e}")
            return None

    def batch_insert_prices(self, cursor, price_data_list):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒæŒ¿å…¥ (PostgreSQLå¯¾å¿œ)"""
        try:
            insert_data = []
            for data in price_data_list:
                insert_data.append((
                    data['symbol'], data['date'], data['open'], data['high'],
                    data['low'], data['close'], data['volume']
                ))

            cursor.executemany("""
                INSERT INTO stock_prices
                (symbol, date, open_price, high_price, low_price, close_price, volume, updated_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s, NOW())
                ON CONFLICT (symbol, date) DO UPDATE SET
                open_price = EXCLUDED.open_price,
                high_price = EXCLUDED.high_price,
                low_price = EXCLUDED.low_price,
                close_price = EXCLUDED.close_price,
                volume = EXCLUDED.volume,
                updated_at = NOW()
            """, insert_data)

        except Exception as e:
            logger.error(f"âŒ ãƒãƒƒãƒæŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    collector = ExpandedSymbolCollector()

    logger.info("ğŸš€ æ‹¡å¼µã‚·ãƒ³ãƒœãƒ«ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼é–‹å§‹")

    # æ‹¡å¼µãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œ
    successful_count = collector.collect_expanded_data(max_symbols=1000, batch_size=100)

    logger.info(f"âœ… æ‹¡å¼µåé›†å®Œäº†: {successful_count}ä»¶æˆåŠŸ")

if __name__ == "__main__":
    import pandas as pd
    main()