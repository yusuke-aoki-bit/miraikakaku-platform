#!/usr/bin/env python3
"""
ã‚¿ãƒ¼ãƒœAIãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼
AIæ±ºå®šè¦å› ã¨ãƒ†ãƒ¼ãƒæ´å¯Ÿã‚’å¤§è¦æ¨¡ç”Ÿæˆ
"""

import sys, os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from database.cloud_sql_only import db
from sqlalchemy import text
import numpy as np
from datetime import datetime, timedelta
import logging
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import random

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TurboAIDataGenerator:
    def __init__(self):
        self.stats = {
            'ai_factors_added': 0,
            'theme_insights_added': 0,
            'errors': 0,
            'start_time': time.time()
        }
        
        # AIæ±ºå®šè¦å› ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆæ‹¡å¼µç‰ˆï¼‰
        self.factor_templates = [
            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ
            ("technical", "RSIéå£²è²·ã‚·ã‚°ãƒŠãƒ«", "RSIæŒ‡æ¨™ãŒ{value:.1f}ã§{signal}ã‚’ç¤ºå”†", 0.65, 0.85),
            ("technical", "ç§»å‹•å¹³å‡ç·šã‚¯ãƒ­ã‚¹", "çŸ­æœŸMA({short}æ—¥)ã¨é•·æœŸMA({long}æ—¥)ã®{cross_type}", 0.60, 0.80),
            ("technical", "ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰", "ä¾¡æ ¼ãŒ{band}ã«æ¥è§¦ã€{action}ã®å¯èƒ½æ€§", 0.55, 0.75),
            ("technical", "MACDè»¢æ›", "MACDç·šãŒã‚·ã‚°ãƒŠãƒ«ç·šã‚’{direction}æŠœã‘", 0.70, 0.85),
            ("technical", "å‡ºæ¥é«˜åˆ†æ", "éå»{days}æ—¥å¹³å‡ã®{ratio:.1f}å€ã®å‡ºæ¥é«˜", 0.50, 0.70),
            ("technical", "ã‚µãƒãƒ¼ãƒˆ/ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹", "{level}å††ãŒå¼·åŠ›ãª{type}ã¨ã—ã¦æ©Ÿèƒ½", 0.60, 0.80),
            ("technical", "ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³", "{trend_type}ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’{action}", 0.65, 0.82),
            ("technical", "ãƒ•ã‚£ãƒœãƒŠãƒƒãƒãƒªãƒˆãƒ¬ãƒ¼ã‚¹ãƒ¡ãƒ³ãƒˆ", "{fib_level}%ãƒ¬ãƒ™ãƒ«ã§{reaction}", 0.58, 0.78),
            
            # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«åˆ†æ
            ("fundamental", "PERè©•ä¾¡", "PER {per:.1f}å€ã¯æ¥­ç•Œå¹³å‡æ¯”{comparison}", 0.70, 0.90),
            ("fundamental", "PBRåˆ†æ", "PBR {pbr:.1f}å€ã€{valuation}è©•ä¾¡", 0.65, 0.85),
            ("fundamental", "ROEæ°´æº–", "ROE {roe:.1f}%ã¯{quality}ã‚’ç¤ºå”†", 0.75, 0.92),
            ("fundamental", "å£²ä¸Šæˆé•·ç‡", "å‰å¹´åŒæœŸæ¯”{growth:.1f}%ã®{trend}", 0.72, 0.88),
            ("fundamental", "å–¶æ¥­åˆ©ç›Šç‡", "å–¶æ¥­åˆ©ç›Šç‡{margin:.1f}%ã¯{efficiency}", 0.68, 0.85),
            ("fundamental", "é…å½“åˆ©å›ã‚Š", "é…å½“åˆ©å›ã‚Š{yield:.2f}%ã¯{attractiveness}", 0.60, 0.80),
            ("fundamental", "è‡ªå·±è³‡æœ¬æ¯”ç‡", "è‡ªå·±è³‡æœ¬æ¯”ç‡{ratio:.1f}%ã§{stability}", 0.65, 0.82),
            ("fundamental", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼", "å–¶æ¥­CF {cf_type}ã§{health}ã‚’ç¤ºå”†", 0.70, 0.87),
            
            # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ
            ("sentiment", "å¸‚å ´å¿ƒç†æŒ‡æ¨™", "Fear&GreedæŒ‡æ•°{value}ã§{sentiment}", 0.45, 0.65),
            ("sentiment", "æŠ•è³‡å®¶å‹•å‘", "æ©Ÿé–¢æŠ•è³‡å®¶ã®{action}ãŒæ´»ç™ºåŒ–", 0.55, 0.75),
            ("sentiment", "SNSãƒˆãƒ¬ãƒ³ãƒ‰", "ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã§{trend}ãŒæ€¥å¢—", 0.40, 0.60),
            ("sentiment", "ã‚¢ãƒŠãƒªã‚¹ãƒˆè©•ä¾¡", "{count}ç¤¾ä¸­{positive}ç¤¾ãŒè²·ã„æ¨å¥¨", 0.60, 0.80),
            ("sentiment", "ç©ºå£²ã‚Šæ¯”ç‡", "ç©ºå£²ã‚Šæ¯”ç‡{ratio:.1f}%ã¯{signal}", 0.50, 0.70),
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜
            ("pattern", "ãƒãƒ£ãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³", "{pattern_name}ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å½¢æˆä¸­", 0.55, 0.75),
            ("pattern", "ã‚¨ãƒªã‚ªãƒƒãƒˆæ³¢å‹•", "ç¬¬{wave}æ³¢å‹•ã®{phase}æ®µéš", 0.50, 0.70),
            ("pattern", "ãƒãƒ¼ãƒ¢ãƒ‹ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³", "{harmonic}ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Œæˆé–“è¿‘", 0.52, 0.72),
            ("pattern", "ä¾¡æ ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", "{candle_pattern}ã®å‡ºç¾ã‚’ç¢ºèª", 0.58, 0.78),
            
            # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆ
            ("news", "æ¥­ç¸¾ç™ºè¡¨å½±éŸ¿", "{quarter}æ±ºç®—ãŒ{impact}ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§", 0.65, 0.85),
            ("news", "æ¥­ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹", "{sector}ã‚»ã‚¯ã‚¿ãƒ¼ã®{event}ãŒå½±éŸ¿", 0.55, 0.75),
            ("news", "ãƒã‚¯ãƒ­çµŒæ¸ˆ", "{indicator}ã®{change}ãŒæ ªä¾¡ã«å½±éŸ¿", 0.60, 0.80),
            ("news", "è¦åˆ¶å¤‰æ›´", "{regulation}ã®{action}ã«ã‚ˆã‚‹å½±éŸ¿", 0.50, 0.70)
        ]
        
        # ãƒ†ãƒ¼ãƒæ´å¯Ÿãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.theme_templates = [
            ("Technology", "tech", ["AIé€²åŒ–", "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", "5Gå±•é–‹", "ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£"]),
            ("Healthcare", "health", ["ãƒã‚¤ã‚ªãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "é éš”åŒ»ç™‚", "å€‹åˆ¥åŒ–åŒ»ç™‚", "åŒ»ç™‚AI"]),
            ("Energy", "energy", ["å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼", "æ°´ç´ çµŒæ¸ˆ", "é›»æ± æŠ€è¡“", "ç‚­ç´ ä¸­ç«‹"]),
            ("Finance", "finance", ["ãƒ‡ã‚¸ã‚¿ãƒ«é€šè²¨", "DeFi", "ãƒã‚ªãƒãƒ³ã‚¯", "ESGæŠ•è³‡"]),
            ("Consumer", "consumer", ["D2C", "ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³", "ä½“é¨“çµŒæ¸ˆ", "ã‚µã‚¹ãƒ†ãƒŠãƒ–ãƒ«æ¶ˆè²»"]),
            ("Industrial", "industrial", ["è‡ªå‹•åŒ–", "IoT", "3Dãƒ—ãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°", "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼"]),
            ("Materials", "materials", ["æ–°ç´ æ", "ãƒªã‚µã‚¤ã‚¯ãƒ«æŠ€è¡“", "ãƒŠãƒãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "ãƒã‚¤ã‚ªãƒãƒ†ãƒªã‚¢ãƒ«"]),
            ("Real Estate", "realestate", ["PropTech", "ã‚¹ãƒãƒ¼ãƒˆã‚·ãƒ†ã‚£", "ã‚°ãƒªãƒ¼ãƒ³ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°", "å…±æœ‰çµŒæ¸ˆ"]),
            ("Transportation", "transport", ["EVé©å‘½", "è‡ªå‹•é‹è»¢", "ç©ºé£›ã¶è»Š", "ãƒã‚¤ãƒ‘ãƒ¼ãƒ«ãƒ¼ãƒ—"]),
            ("Communication", "telecom", ["ãƒ¡ã‚¿ãƒãƒ¼ã‚¹", "AR/VR", "è¡›æ˜Ÿé€šä¿¡", "ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"])
        ]
    
    def generate_ai_factors_batch(self, prediction_ids):
        """AIæ±ºå®šè¦å› ã‚’ãƒãƒƒãƒç”Ÿæˆ"""
        added = 0
        
        try:
            with db.engine.begin() as conn:
                for pred_id in prediction_ids:
                    # å„äºˆæ¸¬ã«å¯¾ã—ã¦3-8å€‹ã®è¦å› ã‚’ç”Ÿæˆ
                    num_factors = random.randint(3, 8)
                    selected_templates = random.sample(self.factor_templates, num_factors)
                    
                    for template in selected_templates:
                        factor_type, name_template, desc_template, min_inf, max_inf = template
                        
                        # å‹•çš„ãªå€¤ã‚’ç”Ÿæˆ
                        values = self._generate_factor_values(factor_type)
                        
                        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å€¤ã‚’é©ç”¨
                        factor_name = name_template.format(**values) if '{' in name_template else name_template
                        description = desc_template.format(**values)
                        
                        influence_score = np.random.uniform(min_inf, max_inf)
                        confidence = np.random.uniform(0.60, 0.95)
                        
                        try:
                            conn.execute(text('''
                                INSERT IGNORE INTO ai_decision_factors 
                                (prediction_id, factor_type, factor_name, influence_score, 
                                 description, confidence, created_at)
                                VALUES (:pred_id, :type, :name, :inf, :desc, :conf, NOW())
                            '''), {
                                'pred_id': pred_id,
                                'type': factor_type,
                                'name': factor_name[:100],  # ã‚«ãƒ©ãƒ é•·åˆ¶é™
                                'inf': round(influence_score, 2),
                                'desc': description[:500],  # ã‚«ãƒ©ãƒ é•·åˆ¶é™
                                'conf': round(confidence, 2)
                            })
                            added += 1
                        except Exception as e:
                            logger.debug(f"Factor insert error: {e}")
                            continue
                
        except Exception as e:
            logger.error(f"Batch AI factors generation error: {e}")
            self.stats['errors'] += 1
        
        self.stats['ai_factors_added'] += added
        return added
    
    def _generate_factor_values(self, factor_type):
        """è¦å› ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‹•çš„å€¤ã‚’ç”Ÿæˆ"""
        values = {}
        
        if factor_type == "technical":
            values['value'] = np.random.uniform(20, 80)
            values['signal'] = random.choice(['è²·ã„ã‚·ã‚°ãƒŠãƒ«', 'å£²ã‚Šã‚·ã‚°ãƒŠãƒ«', 'ä¸­ç«‹'])
            values['short'] = random.choice([5, 10, 20, 25])
            values['long'] = random.choice([50, 75, 100, 200])
            values['cross_type'] = random.choice(['ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹', 'ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹'])
            values['band'] = random.choice(['ä¸Šéƒ¨ãƒãƒ³ãƒ‰', 'ä¸‹éƒ¨ãƒãƒ³ãƒ‰'])
            values['action'] = random.choice(['åç™º', 'çªç ´', 'ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ'])
            values['direction'] = random.choice(['ä¸Š', 'ä¸‹'])
            values['days'] = random.choice([5, 10, 20, 30])
            values['ratio'] = np.random.uniform(1.5, 3.0)
            values['level'] = round(np.random.uniform(100, 5000), 0)
            values['type'] = random.choice(['ã‚µãƒãƒ¼ãƒˆ', 'ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹'])
            values['trend_type'] = random.choice(['ä¸Šæ˜‡', 'ä¸‹é™', 'æ°´å¹³'])
            values['fib_level'] = random.choice([23.6, 38.2, 50.0, 61.8])
            values['reaction'] = random.choice(['åç™ºã®å¯èƒ½æ€§', 'çªç ´ã®å…†å€™'])
            
        elif factor_type == "fundamental":
            values['per'] = np.random.uniform(5, 50)
            values['pbr'] = np.random.uniform(0.5, 5.0)
            values['roe'] = np.random.uniform(5, 30)
            values['growth'] = np.random.uniform(-20, 50)
            values['margin'] = np.random.uniform(5, 25)
            values['yield'] = np.random.uniform(0.5, 5.0)
            values['ratio'] = np.random.uniform(30, 80)
            values['comparison'] = random.choice(['å‰²å®‰', 'å‰²é«˜', 'é©æ­£æ°´æº–'])
            values['valuation'] = random.choice(['å‰²å®‰', 'é©æ­£', 'å‰²é«˜'])
            values['quality'] = random.choice(['é«˜åç›Šæ€§', 'å®‰å®šæˆé•·', 'æ”¹å–„å‚¾å‘'])
            values['trend'] = random.choice(['æˆé•·åŠ é€Ÿ', 'å®‰å®šæˆé•·', 'æ¸›é€Ÿå‚¾å‘'])
            values['efficiency'] = random.choice(['é«˜åŠ¹ç‡çµŒå–¶', 'æ¥­ç•Œå¹³å‡', 'æ”¹å–„ä½™åœ°ã‚ã‚Š'])
            values['attractiveness'] = random.choice(['é«˜é…å½“éŠ˜æŸ„', 'å®‰å®šé…å½“', 'æˆé•·é‡è¦–'])
            values['stability'] = random.choice(['è²¡å‹™å¥å…¨', 'å®‰å®šçš„', 'æ”¹å–„ä¸­'])
            values['cf_type'] = random.choice(['ãƒ—ãƒ©ã‚¹', 'ãƒã‚¤ãƒŠã‚¹'])
            values['health'] = random.choice(['å¥å…¨ãªè³‡é‡‘ç¹°ã‚Š', 'æ³¨æ„ãŒå¿…è¦', 'æ”¹å–„å‚¾å‘'])
            
        elif factor_type == "sentiment":
            values['value'] = random.randint(10, 90)
            values['sentiment'] = random.choice(['æ¥µåº¦ã®ææ€–', 'ææ€–', 'ä¸­ç«‹', 'æ¥½è¦³', 'æ¥µåº¦ã®æ¥½è¦³'])
            values['action'] = random.choice(['è²·ã„', 'å£²ã‚Š', 'ä¿æœ‰'])
            values['trend'] = random.choice(['ãƒã‚¸ãƒ†ã‚£ãƒ–è¨€åŠ', 'ãƒã‚¬ãƒ†ã‚£ãƒ–è¨€åŠ', 'æ³¨ç›®åº¦'])
            values['count'] = random.randint(5, 20)
            values['positive'] = random.randint(3, 15)
            values['ratio'] = np.random.uniform(10, 40)
            values['signal'] = random.choice(['è²·ã„æˆ»ã—åœ§åŠ›', 'å£²ã‚Šåœ§åŠ›ç¶™ç¶š', 'è»¢æ›ç‚¹'])
            
        elif factor_type == "pattern":
            values['pattern_name'] = random.choice(['ä¸‰è§’ä¿ã¡åˆã„', 'ãƒ€ãƒ–ãƒ«ãƒˆãƒƒãƒ—', 'ãƒ€ãƒ–ãƒ«ãƒœãƒˆãƒ ', 
                                                   'ãƒ˜ãƒƒãƒ‰ã‚¢ãƒ³ãƒ‰ã‚·ãƒ§ãƒ«ãƒ€ãƒ¼', 'ã‚«ãƒƒãƒ—ã‚¢ãƒ³ãƒ‰ãƒãƒ³ãƒ‰ãƒ«'])
            values['wave'] = random.randint(1, 5)
            values['phase'] = random.choice(['åˆæœŸ', 'ä¸­æœŸ', 'çµ‚æœŸ'])
            values['harmonic'] = random.choice(['ãƒãƒƒãƒˆ', 'ã‚¬ãƒ¼ãƒˆãƒ¬ãƒ¼', 'ãƒã‚¿ãƒ•ãƒ©ã‚¤', 'ã‚¯ãƒ©ãƒ–'])
            values['candle_pattern'] = random.choice(['ãƒãƒ³ãƒãƒ¼', 'åŒ…ã¿ç·š', 'æ˜ã‘ã®æ˜æ˜Ÿ', 'ä¸‰å…µ'])
            
        elif factor_type == "news":
            values['quarter'] = random.choice(['Q1', 'Q2', 'Q3', 'Q4', 'é€šæœŸ'])
            values['impact'] = random.choice(['ãƒã‚¸ãƒ†ã‚£ãƒ–', 'ãƒã‚¬ãƒ†ã‚£ãƒ–', 'ä¸­ç«‹çš„'])
            values['sector'] = random.choice(['ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼', 'ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢', 'ã‚¨ãƒãƒ«ã‚®ãƒ¼', 'é‡‘è'])
            values['event'] = random.choice(['è¦åˆ¶ç·©å’Œ', 'æ–°æŠ€è¡“å°å…¥', 'æ¥­ç•Œå†ç·¨', 'éœ€è¦å¢—åŠ '])
            values['indicator'] = random.choice(['GDP', 'CPI', 'é›‡ç”¨çµ±è¨ˆ', 'é‡‘åˆ©'])
            values['change'] = random.choice(['ä¸Šæ˜‡', 'ä½ä¸‹', 'äºˆæƒ³ä¸Šå›ã‚‹', 'äºˆæƒ³ä¸‹å›ã‚‹'])
            values['regulation'] = random.choice(['ç’°å¢ƒè¦åˆ¶', 'ãƒ‡ãƒ¼ã‚¿ä¿è­·', 'é‡‘èè¦åˆ¶', 'ç‹¬å ç¦æ­¢'])
            
        return values
    
    def generate_theme_insights_batch(self):
        """ãƒ†ãƒ¼ãƒæ´å¯Ÿã‚’ãƒãƒƒãƒç”Ÿæˆ"""
        added = 0
        
        try:
            with db.engine.begin() as conn:
                for theme_name, category, subtopics in self.theme_templates:
                    # å„ãƒ†ãƒ¼ãƒã«å¯¾ã—ã¦è¤‡æ•°ã®æ´å¯Ÿã‚’ç”Ÿæˆ
                    for i in range(random.randint(5, 10)):
                        subtopic = random.choice(subtopics)
                        
                        # æ´å¯Ÿæ—¥ã‚’éå»30æ—¥é–“ã§ãƒ©ãƒ³ãƒ€ãƒ ã«è¨­å®š
                        insight_date = datetime.now().date() - timedelta(days=random.randint(0, 30))
                        
                        # å½±éŸ¿åº¦ã‚¹ã‚³ã‚¢ã‚’ç”Ÿæˆ
                        impact_score = np.random.uniform(60, 95)
                        
                        # ã‚­ãƒ¼ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ç”Ÿæˆ
                        drivers = self._generate_key_drivers(category, subtopic)
                        
                        # å½±éŸ¿éŠ˜æŸ„ã‚’ç”Ÿæˆ
                        affected_stocks = self._generate_affected_stocks()
                        
                        # äºˆæ¸¬ç²¾åº¦ã‚’ç”Ÿæˆ
                        prediction_accuracy = np.random.uniform(0.65, 0.92)
                        
                        try:
                            conn.execute(text('''
                                INSERT IGNORE INTO theme_insights 
                                (theme_name, theme_category, insight_date, key_drivers, 
                                 affected_stocks, impact_score, prediction_accuracy, created_at)
                                VALUES (:name, :cat, :date, :drivers, :stocks, :impact, :acc, NOW())
                            '''), {
                                'name': f"{theme_name}: {subtopic}",
                                'cat': category,
                                'date': insight_date,
                                'drivers': drivers,
                                'stocks': affected_stocks,
                                'impact': round(impact_score, 1),
                                'acc': round(prediction_accuracy, 3)
                            })
                            added += 1
                        except Exception as e:
                            logger.debug(f"Theme insight insert error: {e}")
                            continue
                
        except Exception as e:
            logger.error(f"Batch theme insights generation error: {e}")
            self.stats['errors'] += 1
        
        self.stats['theme_insights_added'] += added
        return added
    
    def _generate_key_drivers(self, category, subtopic):
        """ã‚­ãƒ¼ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ç”Ÿæˆ"""
        drivers_templates = {
            "tech": [
                f"{subtopic}ã®æŠ€è¡“é©æ–°ãŒåŠ é€Ÿ",
                f"å¤§æ‰‹ä¼æ¥­ã«ã‚ˆã‚‹{subtopic}æŠ•è³‡æ‹¡å¤§",
                f"{subtopic}å¸‚å ´è¦æ¨¡ãŒå‰å¹´æ¯”30%æˆé•·",
                f"è¦åˆ¶ç·©å’Œã«ã‚ˆã‚Š{subtopic}æ™®åŠãŒåŠ é€Ÿ"
            ],
            "health": [
                f"{subtopic}ã®è‡¨åºŠè©¦é¨“ã§æœ‰æœ›ãªçµæœ",
                f"FDAæ‰¿èªã«ã‚ˆã‚Š{subtopic}å¸‚å ´ãŒæ‹¡å¤§",
                f"{subtopic}ã¸ã®ç ”ç©¶é–‹ç™ºæŠ•è³‡ãŒå¢—åŠ ",
                f"é«˜é½¢åŒ–ã«ã‚ˆã‚Š{subtopic}éœ€è¦ãŒæ€¥å¢—"
            ],
            "energy": [
                f"{subtopic}ã®ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒå¤§å¹…æ”¹å–„",
                f"æ”¿åºœã«ã‚ˆã‚‹{subtopic}æ”¯æ´ç­–ã‚’ç™ºè¡¨",
                f"{subtopic}æŠ€è¡“ã®ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼",
                f"ESGæŠ•è³‡ã«ã‚ˆã‚Š{subtopic}ã¸ã®è³‡é‡‘æµå…¥"
            ],
            "finance": [
                f"{subtopic}ã®è¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ç¢ºç«‹",
                f"è‹¥å¹´å±¤ã®{subtopic}åˆ©ç”¨ãŒæ€¥å¢—",
                f"{subtopic}ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æŠ€è¡“ãŒå‘ä¸Š",
                f"å¤§æ‰‹é‡‘èæ©Ÿé–¢ãŒ{subtopic}å‚å…¥"
            ]
        }
        
        base_drivers = drivers_templates.get(category, [f"{subtopic}ã®å¸‚å ´å‹•å‘ãŒæ´»ç™ºåŒ–"])
        selected = random.sample(base_drivers, min(3, len(base_drivers)))
        return ", ".join(selected)
    
    def _generate_affected_stocks(self):
        """å½±éŸ¿ã‚’å—ã‘ã‚‹éŠ˜æŸ„ã‚’ç”Ÿæˆ"""
        # å®Ÿéš›ã®éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        us_stocks = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META', 'NVDA', 'TSLA', 'JPM', 'V', 'JNJ']
        jp_stocks = ['7203', '9984', '6758', '6861', '6902', '8306', '9432', '6501', '4063', '7267']
        
        selected_stocks = random.sample(us_stocks + jp_stocks, random.randint(3, 8))
        return ", ".join(selected_stocks)
    
    def run_turbo_generation(self):
        """ã‚¿ãƒ¼ãƒœç”Ÿæˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ ã‚¿ãƒ¼ãƒœAIãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹")
        logger.info("=" * 80)
        
        with db.engine.connect() as conn:
            # æ—¢å­˜ã®äºˆæ¸¬IDã‚’å–å¾—ï¼ˆAIæ±ºå®šè¦å› ã¨ç´ä»˜ã‘ï¼‰
            result = conn.execute(text('''
                SELECT sp.id 
                FROM stock_predictions sp
                LEFT JOIN ai_decision_factors adf ON sp.id = adf.prediction_id
                WHERE adf.id IS NULL
                ORDER BY sp.created_at DESC
                LIMIT 10000
            ''')).fetchall()
            
            prediction_ids = [row[0] for row in result]
            logger.info(f"ğŸ“Š AIæ±ºå®šè¦å› ç”Ÿæˆå¯¾è±¡: {len(prediction_ids):,}å€‹ã®äºˆæ¸¬")
        
        # ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–
        max_workers = 8
        batch_size = 100
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # AIæ±ºå®šè¦å› ç”Ÿæˆ
            futures = []
            for i in range(0, len(prediction_ids), batch_size):
                batch = prediction_ids[i:i+batch_size]
                future = executor.submit(self.generate_ai_factors_batch, batch)
                futures.append(future)
            
            # ãƒ†ãƒ¼ãƒæ´å¯Ÿç”Ÿæˆï¼ˆä¸¦åˆ—ã§100ãƒãƒƒãƒå®Ÿè¡Œï¼‰
            for _ in range(100):
                future = executor.submit(self.generate_theme_insights_batch)
                futures.append(future)
            
            # å®Œäº†ã‚’å¾…æ©Ÿ
            completed = 0
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=30)
                    completed += 1
                    
                    if completed % 10 == 0:
                        elapsed = time.time() - self.stats['start_time']
                        logger.info(f"é€²æ—: {completed}/{len(futures)} ãƒãƒƒãƒå®Œäº† - "
                                  f"AIè¦å› : {self.stats['ai_factors_added']:,}, "
                                  f"ãƒ†ãƒ¼ãƒ: {self.stats['theme_insights_added']:,}")
                except Exception as e:
                    logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    self.stats['errors'] += 1
        
        # æœ€çµ‚çµæœ
        duration = time.time() - self.stats['start_time']
        logger.info("=" * 80)
        logger.info("ğŸ¯ ã‚¿ãƒ¼ãƒœAIãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.2f}ç§’")
        logger.info(f"ğŸ§  AIæ±ºå®šè¦å› è¿½åŠ : {self.stats['ai_factors_added']:,}ä»¶")
        logger.info(f"ğŸ¯ ãƒ†ãƒ¼ãƒæ´å¯Ÿè¿½åŠ : {self.stats['theme_insights_added']:,}ä»¶")
        logger.info(f"âŒ ã‚¨ãƒ©ãƒ¼: {self.stats['errors']:,}ä»¶")
        logger.info(f"ğŸš€ å‡¦ç†é€Ÿåº¦: {(self.stats['ai_factors_added'] + self.stats['theme_insights_added'])/duration:.1f}ä»¶/ç§’")
        logger.info("=" * 80)
        
        return self.stats

if __name__ == "__main__":
    generator = TurboAIDataGenerator()
    generator.run_turbo_generation()