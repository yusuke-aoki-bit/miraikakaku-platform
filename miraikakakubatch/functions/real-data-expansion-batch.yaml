taskGroups:
- name: real-data-expansion-workers
  taskSpec:
    runnables:
    - container:
        imageUri: gcr.io/pricewise-huqkr/batch-prediction-generator:latest
        entrypoint: python3
        commands:
        - -c
        - |
          import pymysql
          import requests
          import time
          import os
          import logging
          from datetime import datetime, timedelta
          import json

          # ãƒ­ã‚°è¨­å®š
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
          logger = logging.getLogger(__name__)

          worker_id = int(os.getenv('BATCH_TASK_INDEX', '0'))
          total_workers = int(os.getenv('BATCH_TASK_COUNT', '6'))
          logger.info(f"ğŸ” Real Data Expansion Worker {worker_id}/{total_workers} é–‹å§‹")

          # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
          db_config = {
              "host": os.getenv('DB_HOST', '34.58.103.36'),
              "user": os.getenv('DB_USER', 'miraikakaku-user'),
              "password": os.getenv('DB_PASSWORD', 'miraikakaku-secure-pass-2024'),
              "database": os.getenv('DB_NAME', 'miraikakaku'),
              "charset": "utf8mb4"
          }

          def get_missing_symbols_for_worker(worker_id, total_workers, limit_per_worker=100):
              """ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥ã®å®Ÿãƒ‡ãƒ¼ã‚¿ä¸è¶³éŠ˜æŸ„å–å¾—"""
              connection = pymysql.connect(**db_config)
              try:
                  with connection.cursor() as cursor:
                      offset = worker_id * limit_per_worker
                      cursor.execute("""
                          SELECT sm.symbol, sm.name, sm.exchange, sm.country, sm.sector
                          FROM stock_master sm
                          LEFT JOIN stock_price_history sph ON sm.symbol = sph.symbol
                          WHERE sm.is_active = 1
                          AND sph.symbol IS NULL
                          ORDER BY 
                              CASE 
                                  WHEN sm.country IN ('US', 'United States') THEN 1
                                  WHEN sm.country = 'Japan' THEN 2
                                  WHEN sm.exchange IN ('NYSE', 'NASDAQ', 'TSE') THEN 3
                                  ELSE 4
                              END,
                              sm.symbol
                          LIMIT %s OFFSET %s
                      """, (limit_per_worker, offset))
                      return cursor.fetchall()
              finally:
                  connection.close()

          def fetch_yahoo_finance_simple(symbol):
              """ç°¡å˜ãªYahoo Financeç›¸å½“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆCSVå½¢å¼ï¼‰"""
              try:
                  # ã‚·ãƒ³ãƒœãƒ«å¤‰æ›
                  if symbol.isdigit() and len(symbol) >= 4:
                      yf_symbol = f"{symbol}.T"  # æ—¥æœ¬æ ª
                  elif symbol.endswith('=X'):
                      yf_symbol = symbol  # é€šè²¨ãƒšã‚¢
                  else:
                      yf_symbol = symbol  # USæ ªç­‰
                  
                  # Yahoo Finance CSVã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
                  end_date = datetime.now()
                  start_date = end_date - timedelta(days=365)  # 1å¹´åˆ†
                  
                  url = f"https://query1.finance.yahoo.com/v7/finance/download/{yf_symbol}"
                  params = {
                      'period1': int(start_date.timestamp()),
                      'period2': int(end_date.timestamp()),
                      'interval': '1d',
                      'events': 'history',
                      'includeAdjustedClose': 'true'
                  }
                  
                  headers = {
                      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                  }
                  
                  response = requests.get(url, params=params, headers=headers, timeout=15)
                  
                  if response.status_code != 200:
                      logger.warning(f"Yahoo: {symbol} HTTP {response.status_code}")
                      return None
                  
                  # CSVè§£æ
                  lines = response.text.strip().split('\\n')
                  if len(lines) < 2:
                      logger.warning(f"Yahoo: {symbol} ãƒ‡ãƒ¼ã‚¿ãªã—")
                      return None
                  
                  headers = lines[0].split(',')
                  price_data = []
                  
                  for line in lines[1:]:
                      try:
                          values = line.split(',')
                          if len(values) < 7:
                              continue
                          
                          date_str = values[0]
                          open_price = float(values[1])
                          high_price = float(values[2])
                          low_price = float(values[3])
                          close_price = float(values[4])
                          adj_close = float(values[5])
                          volume = int(values[6])
                          
                          # æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
                          if open_price <= 0 or close_price <= 0 or volume < 0:
                              continue
                          
                          price_data.append({
                              'symbol': symbol,
                              'date': datetime.strptime(date_str, '%Y-%m-%d').date(),
                              'open_price': open_price,
                              'high_price': high_price,
                              'low_price': low_price,
                              'close_price': close_price,
                              'adjusted_close': adj_close,
                              'volume': volume,
                              'data_source': f'YahooFinanceCSV_{datetime.now().strftime("%Y%m%d")}_{worker_id}',
                              'is_valid': 1,
                              'data_quality_score': 0.92
                          })
                          
                      except (ValueError, IndexError) as e:
                          logger.warning(f"Yahoo: {symbol} è¡Œè§£æã‚¨ãƒ©ãƒ¼: {e}")
                          continue
                  
                  logger.info(f"Yahoo CSV: {symbol} - {len(price_data)}ä»¶å–å¾—")
                  return price_data
                  
              except Exception as e:
                  logger.error(f"Yahoo CSV: {symbol} å–å¾—ã‚¨ãƒ©ãƒ¼ - {e}")
                  return None

          def save_real_data_batch(price_data_list):
              """å®Ÿãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒä¿å­˜"""
              if not price_data_list:
                  return 0
                  
              connection = pymysql.connect(**db_config)
              try:
                  with connection.cursor() as cursor:
                      insert_data = []
                      for data in price_data_list:
                          insert_data.append((
                              data['symbol'], data['date'],
                              data['open_price'], data['high_price'], 
                              data['low_price'], data['close_price'],
                              data['volume'], data['adjusted_close'],
                              data['data_source'], data['is_valid'],
                              data['data_quality_score']
                          ))
                      
                      cursor.executemany("""
                          INSERT IGNORE INTO stock_price_history 
                          (symbol, date, open_price, high_price, low_price, close_price, 
                           volume, adjusted_close, data_source, is_valid, data_quality_score, created_at)
                          VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                      """, insert_data)
                      
                      connection.commit()
                      return cursor.rowcount
                      
              except Exception as e:
                  logger.error(f"ãƒãƒƒãƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                  return 0
              finally:
                  connection.close()

          try:
              # ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥ä¸è¶³éŠ˜æŸ„å–å¾—
              missing_symbols = get_missing_symbols_for_worker(worker_id, total_workers, 100)
              logger.info(f"ğŸ’« Real Worker {worker_id}: {len(missing_symbols)}éŠ˜æŸ„ã®å®Ÿãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
              
              if not missing_symbols:
                  logger.info(f"âš ï¸ Real Worker {worker_id}: å‡¦ç†å¯¾è±¡éŠ˜æŸ„ãªã—")
                  exit(0)
              
              total_collected_records = 0
              successful_symbols = 0
              failed_symbols = 0
              
              for i, (symbol, name, exchange, country, sector) in enumerate(missing_symbols):
                  logger.info(f"ğŸ” Real Worker {worker_id}: {i+1}/{len(missing_symbols)} - {symbol} ({country or 'N/A'})")
                  
                  # Yahoo Finance CSVã§å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—è©¦è¡Œ
                  price_data = fetch_yahoo_finance_simple(symbol)
                  
                  if price_data and len(price_data) > 0:
                      # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                      saved_count = save_real_data_batch(price_data)
                      if saved_count > 0:
                          total_collected_records += saved_count
                          successful_symbols += 1
                          logger.info(f"âœ… Real Worker {worker_id}: {symbol} - {saved_count}ä»¶ä¿å­˜")
                      else:
                          failed_symbols += 1
                          logger.warning(f"âš ï¸ Real Worker {worker_id}: {symbol} - ä¿å­˜å¤±æ•—")
                  else:
                      failed_symbols += 1
                      logger.warning(f"âŒ Real Worker {worker_id}: {symbol} - å–å¾—å¤±æ•—")
                  
                  # Yahoo APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
                  time.sleep(1.0)
                  
                  # é€²æ—å ±å‘Š
                  if (i + 1) % 20 == 0:
                      progress = ((i + 1) / len(missing_symbols)) * 100
                      success_rate = (successful_symbols / (i + 1)) * 100
                      logger.info(f"ğŸ“ˆ Real Worker {worker_id}: {progress:.0f}% å®Œäº†")
                      logger.info(f"   æˆåŠŸ: {successful_symbols}, å¤±æ•—: {failed_symbols}, æˆåŠŸç‡: {success_rate:.1f}%")
                      logger.info(f"   ç´¯è¨ˆãƒ‡ãƒ¼ã‚¿: {total_collected_records:,}ä»¶")
              
              # æœ€çµ‚çµæœ
              final_success_rate = (successful_symbols / len(missing_symbols)) * 100
              logger.info(f"ğŸ¯ Real Worker {worker_id} å®Œäº†:")
              logger.info(f"   - å‡¦ç†éŠ˜æŸ„: {len(missing_symbols)}éŠ˜æŸ„")
              logger.info(f"   - æˆåŠŸéŠ˜æŸ„: {successful_symbols}éŠ˜æŸ„ ({final_success_rate:.1f}%)")
              logger.info(f"   - å¤±æ•—éŠ˜æŸ„: {failed_symbols}éŠ˜æŸ„")
              logger.info(f"   - åé›†ãƒ‡ãƒ¼ã‚¿: {total_collected_records:,}ä»¶")
              
              if successful_symbols == 0:
                  logger.error(f"âŒ Real Worker {worker_id}: å…¨éŠ˜æŸ„ã§å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                  exit(1)
              
          except Exception as e:
              logger.error(f"âŒ Real Worker {worker_id} é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}")
              import traceback
              logger.error(traceback.format_exc())
              exit(1)
      environment:
        variables:
          DB_HOST: "34.58.103.36"
          DB_USER: "miraikakaku-user"
          DB_PASSWORD: "miraikakaku-secure-pass-2024"
          DB_NAME: "miraikakaku"
          PYTHONUNBUFFERED: "1"
    computeResource:
      cpuMilli: 1500
      memoryMib: 3072
    maxRetryCount: 2
    maxRunDuration: 3600s  # 60åˆ†
  taskCount: 6
  parallelism: 3
allocationPolicy:
  instances:
  - policy:
      machineType: e2-standard-2
      provisioningModel: STANDARD
  location:
    allowedLocations:
    - regions/us-central1
logsPolicy:
  destination: CLOUD_LOGGING