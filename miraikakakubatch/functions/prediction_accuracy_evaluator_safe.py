#!/usr/bin/env python3
"""
äºˆæ¸¬ç²¾åº¦è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ  - ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®‰å…¨ç‰ˆ
å¹³å‡çµ¶å¯¾èª¤å·®(MAE)ã‚’ä½¿ç”¨ã—ã¦LSTM vs VertexAIäºˆæ¸¬ç²¾åº¦ã‚’æ¯”è¼ƒ
"""

import pymysql
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import pandas as pd
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PredictionAccuracyEvaluatorSafe:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
        }
        self.accuracy_results = {
            "lstm": {
                "total_predictions": 0,
                "mae": 0.0,
                "symbols_evaluated": 0,
                "symbol_results": {}
            },
            "vertexai": {
                "total_predictions": 0,
                "mae": 0.0,
                "symbols_evaluated": 0,
                "symbol_results": {}
            }
        }

    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def get_predictions_and_actual_data_separately(self):
        """
        äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã¨å®Ÿéš›ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ã€…ã«å–å¾—ã—ã¦ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œã‚’å›é¿
        """
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # 1. äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                cursor.execute("""
                    SELECT 
                        symbol, prediction_date, predicted_price, predicted_change_percent,
                        confidence_score, model_type, created_at
                    FROM stock_predictions
                    WHERE model_type IN ('lstm_test_accuracy', 'vertexai_test_accuracy', 'lstm_test_v2', 'vertexai_test_v2', 'lstm_v2', 'vertexai_v2')
                    AND prediction_date >= DATE_SUB(NOW(), INTERVAL 30 DAY)
                    ORDER BY symbol, prediction_date, model_type
                """)
                
                predictions = cursor.fetchall()
                logger.info(f"ğŸ“Š å–å¾—ã—ãŸäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿: {len(predictions)}ä»¶")
                
                # 2. å®Ÿéš›ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                cursor.execute("""
                    SELECT symbol, date, close_price
                    FROM stock_price_history
                    WHERE date >= DATE_SUB(NOW(), INTERVAL 30 DAY)
                    ORDER BY symbol, date
                """)
                
                actual_prices = cursor.fetchall()
                logger.info(f"ğŸ“ˆ å–å¾—ã—ãŸå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿: {len(actual_prices)}ä»¶")
                
                return predictions, actual_prices
                
        finally:
            connection.close()

    def match_predictions_with_actuals(self, predictions, actual_prices):
        """
        äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã¨å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒãƒ³ã‚°
        """
        # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸åŒ–ï¼ˆé«˜é€Ÿæ¤œç´¢ç”¨ï¼‰
        actual_dict = {}
        for symbol, date, close_price in actual_prices:
            key = f"{symbol}_{date.strftime('%Y-%m-%d')}"
            actual_dict[key] = close_price
        
        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã¨å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒãƒ³ã‚°
        matched_data = []
        matched_count = 0
        
        for pred in predictions:
            symbol, pred_date, pred_price, pred_change, confidence, model_type, created_at = pred
            pred_date_str = pred_date.strftime('%Y-%m-%d')
            key = f"{symbol}_{pred_date_str}"
            
            if key in actual_dict:
                actual_price = actual_dict[key]
                matched_data.append({
                    'symbol': symbol,
                    'prediction_date': pred_date,
                    'predicted_price': pred_price,
                    'actual_price': actual_price,
                    'confidence': confidence,
                    'model_type': model_type,
                    'created_at': created_at
                })
                matched_count += 1
        
        logger.info(f"ğŸ”— ãƒãƒƒãƒãƒ³ã‚°æˆåŠŸ: {matched_count}ä»¶ã®äºˆæ¸¬-å®Ÿç¸¾ãƒšã‚¢")
        return matched_data

    def calculate_mae_by_model_and_symbol(self, matched_data):
        """
        ãƒ¢ãƒ‡ãƒ«ãƒ»éŠ˜æŸ„åˆ¥ã®MAEè¨ˆç®—
        """
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«ãƒ»éŠ˜æŸ„åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        groups = {}
        
        for data in matched_data:
            symbol = data['symbol']
            model_type = data['model_type']
            key = f"{model_type}_{symbol}"
            
            if key not in groups:
                groups[key] = []
            
            groups[key].append(data)
        
        # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®MAEè¨ˆç®—
        results = {}
        
        for key, group_data in groups.items():
            model_type, symbol = key.split('_', 1)
            
            # MAEè¨ˆç®—
            absolute_errors = []
            confidences = []
            error_details = []
            
            for data in group_data:
                predicted = data['predicted_price']
                actual = data['actual_price']
                absolute_error = abs(predicted - actual)
                relative_error = (absolute_error / actual) * 100 if actual != 0 else 0
                
                absolute_errors.append(absolute_error)
                confidences.append(data['confidence'])
                error_details.append({
                    'date': data['prediction_date'],
                    'predicted': predicted,
                    'actual': actual,
                    'absolute_error': absolute_error,
                    'relative_error_percent': relative_error
                })
            
            mae = np.mean(absolute_errors)
            
            results[key] = {
                'symbol': symbol,
                'model_type': model_type,
                'mae': mae,
                'count': len(absolute_errors),
                'avg_confidence': np.mean(confidences),
                'median_error': np.median(absolute_errors),
                'std_error': np.std(absolute_errors),
                'min_error': np.min(absolute_errors),
                'max_error': np.max(absolute_errors),
                'error_details': error_details
            }
            
            logger.info(f"ğŸ“Š {model_type} {symbol}: MAE={mae:.2f} ({len(absolute_errors)}ä»¶)")
        
        return results

    def aggregate_results_by_model(self, detailed_results):
        """
        ãƒ¢ãƒ‡ãƒ«åˆ¥ã®å…¨ä½“çµæœé›†è¨ˆ
        """
        for key, result in detailed_results.items():
            model_type = result['model_type']
            symbol = result['symbol']
            
            if 'lstm' in model_type.lower():
                model_key = 'lstm'
            elif 'vertexai' in model_type.lower():
                model_key = 'vertexai'
            else:
                continue
            
            # éŠ˜æŸ„åˆ¥çµæœä¿å­˜
            self.accuracy_results[model_key]['symbol_results'][symbol] = result
            self.accuracy_results[model_key]['symbols_evaluated'] += 1
        
        # å…¨ä½“MAEè¨ˆç®—
        for model_key in ['lstm', 'vertexai']:
            all_errors = []
            total_predictions = 0
            
            for symbol, symbol_result in self.accuracy_results[model_key]['symbol_results'].items():
                for detail in symbol_result['error_details']:
                    all_errors.append(detail['absolute_error'])
                total_predictions += symbol_result['count']
            
            if all_errors:
                self.accuracy_results[model_key]['mae'] = np.mean(all_errors)
                self.accuracy_results[model_key]['total_predictions'] = total_predictions
            
            logger.info(f"ğŸ¯ {model_key.upper()} å…¨ä½“MAE: {self.accuracy_results[model_key]['mae']:.2f} ({total_predictions}ä»¶)")

    def generate_comprehensive_accuracy_report(self):
        """
        åŒ…æ‹¬çš„ç²¾åº¦è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        """
        logger.info("=" * 80)
        logger.info("ğŸ“Š äºˆæ¸¬ç²¾åº¦è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå¹³å‡çµ¶å¯¾èª¤å·® MAEï¼‰")
        logger.info("=" * 80)
        
        # å…¨ä½“æ¯”è¼ƒ
        lstm_mae = self.accuracy_results['lstm']['mae']
        vertexai_mae = self.accuracy_results['vertexai']['mae']
        lstm_count = self.accuracy_results['lstm']['total_predictions']
        vertexai_count = self.accuracy_results['vertexai']['total_predictions']
        
        logger.info("ğŸ¯ å…¨ä½“ç²¾åº¦æ¯”è¼ƒ:")
        logger.info(f"  ğŸ§  LSTM:")
        logger.info(f"    MAE: {lstm_mae:.2f}")
        logger.info(f"    äºˆæ¸¬ä»¶æ•°: {lstm_count:,}ä»¶")
        logger.info(f"    è©•ä¾¡éŠ˜æŸ„æ•°: {self.accuracy_results['lstm']['symbols_evaluated']}éŠ˜æŸ„")
        
        logger.info(f"  ğŸ¤– VertexAI:")
        logger.info(f"    MAE: {vertexai_mae:.2f}")
        logger.info(f"    äºˆæ¸¬ä»¶æ•°: {vertexai_count:,}ä»¶")
        logger.info(f"    è©•ä¾¡éŠ˜æŸ„æ•°: {self.accuracy_results['vertexai']['symbols_evaluated']}éŠ˜æŸ„")
        
        # å‹è€…åˆ¤å®š
        if lstm_mae > 0 and vertexai_mae > 0:
            if lstm_mae < vertexai_mae:
                improvement = ((vertexai_mae - lstm_mae) / vertexai_mae) * 100
                logger.info(f"ğŸ† ç·åˆå‹è€…: LSTM (ç²¾åº¦å‘ä¸Š: {improvement:.1f}%)")
            elif vertexai_mae < lstm_mae:
                improvement = ((lstm_mae - vertexai_mae) / lstm_mae) * 100
                logger.info(f"ğŸ† ç·åˆå‹è€…: VertexAI (ç²¾åº¦å‘ä¸Š: {improvement:.1f}%)")
            else:
                logger.info("ğŸ¤ ç·åˆçµæœ: åŒç‚¹")
        
        logger.info("")
        
        # éŠ˜æŸ„åˆ¥è©³ç´°æ¯”è¼ƒ
        logger.info("ğŸ“ˆ éŠ˜æŸ„åˆ¥ç²¾åº¦è©³ç´°æ¯”è¼ƒ:")
        all_symbols = set(self.accuracy_results['lstm']['symbol_results'].keys()) | \
                     set(self.accuracy_results['vertexai']['symbol_results'].keys())
        
        lstm_wins = 0
        vertexai_wins = 0
        ties = 0
        
        for symbol in sorted(all_symbols):
            lstm_result = self.accuracy_results['lstm']['symbol_results'].get(symbol)
            vertexai_result = self.accuracy_results['vertexai']['symbol_results'].get(symbol)
            
            logger.info(f"  ğŸ“Š {symbol}:")
            if lstm_result:
                logger.info(f"    ğŸ§  LSTM: MAE={lstm_result['mae']:.2f} (ä¿¡é ¼åº¦:{lstm_result['avg_confidence']:.2f}, {lstm_result['count']}ä»¶)")
            if vertexai_result:
                logger.info(f"    ğŸ¤– VertexAI: MAE={vertexai_result['mae']:.2f} (ä¿¡é ¼åº¦:{vertexai_result['avg_confidence']:.2f}, {vertexai_result['count']}ä»¶)")
            
            # éŠ˜æŸ„åˆ¥å‹è€…åˆ¤å®š
            if lstm_result and vertexai_result:
                if lstm_result['mae'] < vertexai_result['mae']:
                    logger.info(f"    ğŸ† {symbol} å‹è€…: LSTM")
                    lstm_wins += 1
                elif vertexai_result['mae'] < lstm_result['mae']:
                    logger.info(f"    ğŸ† {symbol} å‹è€…: VertexAI")
                    vertexai_wins += 1
                else:
                    logger.info(f"    ğŸ¤ {symbol}: åŒç‚¹")
                    ties += 1
        
        # éŠ˜æŸ„åˆ¥å‹æ•—ã‚µãƒãƒªãƒ¼
        total_comparisons = lstm_wins + vertexai_wins + ties
        if total_comparisons > 0:
            logger.info("")
            logger.info("ğŸ éŠ˜æŸ„åˆ¥å‹æ•—ã‚µãƒãƒªãƒ¼:")
            logger.info(f"  ğŸ§  LSTMå‹åˆ©: {lstm_wins}éŠ˜æŸ„ ({lstm_wins/total_comparisons*100:.1f}%)")
            logger.info(f"  ğŸ¤– VertexAIå‹åˆ©: {vertexai_wins}éŠ˜æŸ„ ({vertexai_wins/total_comparisons*100:.1f}%)")
            logger.info(f"  ğŸ¤ åŒç‚¹: {ties}éŠ˜æŸ„ ({ties/total_comparisons*100:.1f}%)")
        
        logger.info("=" * 80)

    def save_accuracy_results_safe(self):
        """
        ç²¾åº¦è©•ä¾¡çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å®‰å…¨ã«ä¿å­˜
        """
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS model_accuracy_evaluation (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        model_type VARCHAR(50),
                        symbol VARCHAR(20),
                        mae FLOAT,
                        prediction_count INT,
                        avg_confidence FLOAT,
                        median_error FLOAT,
                        std_error FLOAT,
                        min_error FLOAT,
                        max_error FLOAT,
                        evaluation_date DATETIME,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                saved_count = 0
                
                # çµæœä¿å­˜
                for model_key in ['lstm', 'vertexai']:
                    for symbol, result in self.accuracy_results[model_key]['symbol_results'].items():
                        cursor.execute("""
                            INSERT INTO model_accuracy_evaluation 
                            (model_type, symbol, mae, prediction_count, avg_confidence, 
                             median_error, std_error, min_error, max_error, evaluation_date)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                        """, (
                            model_key.upper(), symbol, result['mae'], result['count'], 
                            result['avg_confidence'], result['median_error'], result['std_error'],
                            result['min_error'], result['max_error']
                        ))
                        saved_count += 1
                
                connection.commit()
                logger.info(f"âœ… ç²¾åº¦è©•ä¾¡çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜å®Œäº† ({saved_count}ä»¶)")
                
        finally:
            connection.close()

    def run_safe_accuracy_evaluation(self):
        """
        å®‰å…¨ãªç²¾åº¦è©•ä¾¡å®Ÿè¡Œ
        """
        start_time = datetime.now()
        logger.info(f"ğŸš€ äºˆæ¸¬ç²¾åº¦è©•ä¾¡é–‹å§‹ (å®‰å…¨ç‰ˆ): {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
            predictions, actual_prices = self.get_predictions_and_actual_data_separately()
            
            if not predictions:
                logger.warning("âŒ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            if not actual_prices:
                logger.warning("âŒ å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            # 2. ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚°
            matched_data = self.match_predictions_with_actuals(predictions, actual_prices)
            
            if not matched_data:
                logger.warning("âŒ äºˆæ¸¬ã¨å®Ÿç¸¾ã®ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # 3. MAEè¨ˆç®—
            detailed_results = self.calculate_mae_by_model_and_symbol(matched_data)
            
            # 4. çµæœé›†è¨ˆ
            self.aggregate_results_by_model(detailed_results)
            
            # 5. çµæœä¿å­˜
            self.save_accuracy_results_safe()
            
            # 6. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self.generate_comprehensive_accuracy_report()
            
        except Exception as e:
            logger.error(f"âŒ ç²¾åº¦è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        logger.info(f"âœ… ç²¾åº¦è©•ä¾¡å®Œäº† (å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’)")

if __name__ == "__main__":
    evaluator = PredictionAccuracyEvaluatorSafe()
    
    try:
        evaluator.run_safe_accuracy_evaluation()
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢")
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()