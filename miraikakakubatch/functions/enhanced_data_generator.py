#!/usr/bin/env python3
"""
æ–°æ©Ÿèƒ½ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒãƒƒãƒ
å·®åˆ¥åŒ–æ©Ÿèƒ½ã®ãŸã‚ã®ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™
"""

import sys
import os
import asyncio
import random
import logging
import traceback
from datetime import datetime, timedelta, date
from typing import List, Dict, Optional

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½ã«ã™ã‚‹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from database.cloud_sql_only import get_cloud_sql_connection
    from sqlalchemy import text
    from sqlalchemy.exc import IntegrityError
except ImportError as e:
    logger.error(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

async def create_enhanced_tables():
    """æ–°æ©Ÿèƒ½ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    conn = await get_cloud_sql_connection()
    
    try:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆSQL
        tables_sql = [
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
            """
            CREATE TABLE IF NOT EXISTS user_profiles (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                user_id VARCHAR(100) UNIQUE NOT NULL,
                username VARCHAR(50),
                email VARCHAR(100),
                investment_style ENUM('conservative', 'moderate', 'aggressive', 'growth', 'value') DEFAULT 'moderate',
                risk_tolerance ENUM('low', 'medium', 'high') DEFAULT 'medium',
                investment_experience ENUM('beginner', 'intermediate', 'advanced', 'expert') DEFAULT 'beginner',
                preferred_sectors JSON,
                investment_goals TEXT,
                total_portfolio_value DECIMAL(15,2),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_user_id (user_id),
                INDEX idx_investment_style (investment_style)
            );
            """,
            # AIåˆ¤æ–­æ ¹æ‹ ãƒ†ãƒ¼ãƒ–ãƒ«
            """
            CREATE TABLE IF NOT EXISTS ai_decision_factors (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                prediction_id BIGINT NOT NULL,
                factor_type ENUM('technical', 'fundamental', 'sentiment', 'news', 'pattern') NOT NULL,
                factor_name VARCHAR(100) NOT NULL,
                influence_score DECIMAL(5,2) NOT NULL,
                description TEXT,
                confidence DECIMAL(5,2),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_prediction_id (prediction_id),
                INDEX idx_factor_type (factor_type)
            );
            """,
            # ã‚³ãƒ³ãƒ†ã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
            """
            CREATE TABLE IF NOT EXISTS prediction_contests (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                contest_name VARCHAR(100) NOT NULL,
                symbol VARCHAR(10) NOT NULL,
                contest_start_date DATE NOT NULL,
                prediction_deadline DATETIME NOT NULL,
                target_date DATE NOT NULL,
                actual_price DECIMAL(12,4),
                status ENUM('active', 'closed', 'completed') DEFAULT 'active',
                prize_description TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_contest_status (status),
                INDEX idx_target_date (target_date)
            );
            """,
            # ãƒ†ãƒ¼ãƒã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
            """
            CREATE TABLE IF NOT EXISTS theme_insights (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                theme_name VARCHAR(50) NOT NULL,
                theme_category ENUM('technology', 'energy', 'finance', 'healthcare', 'consumer', 'industrial', 'materials') NOT NULL,
                insight_date DATE NOT NULL,
                title VARCHAR(200) NOT NULL,
                summary TEXT NOT NULL,
                key_metrics JSON,
                related_symbols JSON,
                trend_direction ENUM('bullish', 'bearish', 'neutral') DEFAULT 'neutral',
                impact_score DECIMAL(3,1),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_theme_date (theme_name, insight_date),
                INDEX idx_category (theme_category),
                INDEX idx_trend (trend_direction)
            );
            """,
            # ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
            """
            CREATE TABLE IF NOT EXISTS user_watchlists (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                user_id VARCHAR(100) NOT NULL,
                symbol VARCHAR(10) NOT NULL,
                added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                alert_threshold_up DECIMAL(5,2),
                alert_threshold_down DECIMAL(5,2),
                notes TEXT,
                priority ENUM('high', 'medium', 'low') DEFAULT 'medium',
                UNIQUE KEY unique_user_symbol (user_id, symbol),
                INDEX idx_user_id (user_id)
            );
            """
        ]
        
        for sql in tables_sql:
            await conn.execute(text(sql))
            await conn.commit()
        
        logger.info("âœ… Enhanced tables created successfully")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Error creating tables: {e}")
        return False
    finally:
        await conn.close()

async def generate_user_profiles():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    conn = await get_cloud_sql_connection()
    
    try:
        sample_users = [
            {
                "user_id": "demo_conservative_001",
                "username": "SafeInvestor",
                "email": "safe@example.com",
                "investment_style": "conservative",
                "risk_tolerance": "low",
                "investment_experience": "beginner",
                "preferred_sectors": '["finance", "consumer"]',
                "investment_goals": "é•·æœŸçš„ãªè³‡ç”£ä¿å…¨ã¨å®‰å®šã—ãŸãƒªã‚¿ãƒ¼ãƒ³ã‚’ç›®æŒ‡ã—ã¾ã™",
                "total_portfolio_value": 500000.0
            },
            {
                "user_id": "demo_aggressive_002", 
                "username": "TechGrowth",
                "email": "growth@example.com",
                "investment_style": "growth",
                "risk_tolerance": "high",
                "investment_experience": "advanced",
                "preferred_sectors": '["technology", "healthcare"]',
                "investment_goals": "æŠ€è¡“æ ªã‚’ä¸­å¿ƒã¨ã—ãŸç©æ¥µçš„ãªæˆé•·æŠ•è³‡",
                "total_portfolio_value": 1200000.0
            },
            {
                "user_id": "demo_balanced_003",
                "username": "BalancedTrader", 
                "email": "balanced@example.com",
                "investment_style": "moderate",
                "risk_tolerance": "medium",
                "investment_experience": "intermediate",
                "preferred_sectors": '["technology", "finance", "energy"]',
                "investment_goals": "ãƒªã‚¹ã‚¯ã¨ãƒªã‚¿ãƒ¼ãƒ³ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã£ãŸåˆ†æ•£æŠ•è³‡",
                "total_portfolio_value": 800000.0
            }
        ]
        
        created_count = 0
        for user_data in sample_users:
            try:
                # æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒã‚§ãƒƒã‚¯
                result = await conn.execute(text(
                    "SELECT id FROM user_profiles WHERE user_id = :user_id"
                ), {"user_id": user_data["user_id"]})
                
                if result.fetchone():
                    logger.info(f"User {user_data['user_id']} already exists")
                    continue
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
                await conn.execute(text("""
                    INSERT INTO user_profiles 
                    (user_id, username, email, investment_style, risk_tolerance, 
                     investment_experience, preferred_sectors, investment_goals, total_portfolio_value)
                    VALUES (:user_id, :username, :email, :investment_style, :risk_tolerance,
                            :investment_experience, :preferred_sectors, :investment_goals, :total_portfolio_value)
                """), user_data)
                
                created_count += 1
                logger.info(f"Created user profile: {user_data['username']}")
                
            except IntegrityError:
                logger.info(f"User {user_data['user_id']} already exists (skipping)")
                continue
        
        await conn.commit()
        logger.info(f"âœ… Created {created_count} user profiles")
        return created_count
        
    except Exception as e:
        logger.error(f"âŒ Error creating user profiles: {e}")
        logger.error(traceback.format_exc())
        return 0
    finally:
        await conn.close()

async def generate_ai_decision_factors():
    """AIåˆ¤æ–­æ ¹æ‹ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    conn = await get_cloud_sql_connection()
    
    try:
        # æœ€æ–°ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæœ€å¤§50ä»¶ï¼‰
        result = await conn.execute(text("""
            SELECT id, symbol FROM stock_predictions 
            ORDER BY created_at DESC 
            LIMIT 50
        """))
        predictions = result.fetchall()
        
        if not predictions:
            logger.warning("No predictions found for decision factors")
            return 0
        
        factor_templates = [
            {
                "factor_type": "technical",
                "factor_name": "RSIåç™ºã‚·ã‚°ãƒŠãƒ«",
                "description": "RSIæŒ‡æ¨™ãŒ30ã‚’ä¸‹å›ã£ãŸå¾Œã€åç™ºä¸Šæ˜‡ã‚’ç¤ºã—ã¦ã„ã‚‹",
                "base_influence": 0.85,
                "base_confidence": 0.78
            },
            {
                "factor_type": "fundamental", 
                "factor_name": "æ¥­ç¸¾äºˆæƒ³ä¸Šæ–¹ä¿®æ­£",
                "description": "æ¬¡å››åŠæœŸã®EPSäºˆæƒ³ãŒ15%ä¸Šæ–¹ä¿®æ­£ã•ã‚ŒãŸ",
                "base_influence": 0.92,
                "base_confidence": 0.88
            },
            {
                "factor_type": "sentiment",
                "factor_name": "æŠ•è³‡å®¶å¿ƒç†æ”¹å–„",
                "description": "ã‚¢ãƒŠãƒªã‚¹ãƒˆã®å¼·æ°—ã‚³ãƒ¡ãƒ³ãƒˆãŒå¢—åŠ ã€æ©Ÿé–¢æŠ•è³‡å®¶ã®è²·ã„å¢—ã—è¦³æ¸¬",
                "base_influence": 0.73,
                "base_confidence": 0.65
            },
            {
                "factor_type": "news",
                "factor_name": "æ–°è£½å“ç™ºè¡¨å½±éŸ¿",
                "description": "é©æ–°çš„ãªæ–°è£½å“ã®ç™ºè¡¨ã«ã‚ˆã‚Šå¸‚å ´æœŸå¾…ãŒé«˜ã¾ã£ã¦ã„ã‚‹",
                "base_influence": 0.89,
                "base_confidence": 0.82
            },
            {
                "factor_type": "pattern",
                "factor_name": "ä¸Šæ˜‡ä¸‰è§’å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³",
                "description": "ãƒãƒ£ãƒ¼ãƒˆä¸Šã§ä¸Šæ˜‡ä¸‰è§’å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å½¢æˆã€ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆé–“è¿‘",
                "base_influence": 0.76,
                "base_confidence": 0.71
            }
        ]
        
        created_count = 0
        for prediction in predictions:
            # å„äºˆæ¸¬ã«2-4å€‹ã®åˆ¤æ–­æ ¹æ‹ ã‚’ç”Ÿæˆ
            num_factors = random.randint(2, 4)
            selected_factors = random.sample(factor_templates, num_factors)
            
            for factor_template in selected_factors:
                # ã‚¹ã‚³ã‚¢ã«ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’è¿½åŠ 
                influence_score = factor_template["base_influence"] + random.uniform(-0.1, 0.1)
                confidence = factor_template["base_confidence"] + random.uniform(-0.1, 0.1)
                
                await conn.execute(text("""
                    INSERT INTO ai_decision_factors 
                    (prediction_id, factor_type, factor_name, description, influence_score, confidence)
                    VALUES (:prediction_id, :factor_type, :factor_name, :description, :influence_score, :confidence)
                """), {
                    "prediction_id": prediction.id,
                    "factor_type": factor_template["factor_type"],
                    "factor_name": factor_template["factor_name"],
                    "description": factor_template["description"],
                    "influence_score": max(0.1, min(1.0, influence_score)),
                    "confidence": max(0.1, min(1.0, confidence))
                })
                created_count += 1
        
        await conn.commit()
        logger.info(f"âœ… Created {created_count} AI decision factors")
        return created_count
        
    except Exception as e:
        logger.error(f"âŒ Error creating AI decision factors: {e}")
        logger.error(traceback.format_exc())
        return 0
    finally:
        await conn.close()

async def generate_prediction_contests():
    """äºˆæ¸¬ã‚³ãƒ³ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    conn = await get_cloud_sql_connection()
    
    try:
        popular_symbols = ["AAPL", "GOOGL", "MSFT", "TSLA", "NVDA", "AMZN", "META"]
        
        created_count = 0
        for i, symbol in enumerate(popular_symbols[:3]):
            contest_date = date.today() + timedelta(days=i*7)
            
            # æ—¢å­˜ã‚³ãƒ³ãƒ†ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
            result = await conn.execute(text("""
                SELECT id FROM prediction_contests 
                WHERE symbol = :symbol AND contest_start_date = :contest_start_date
            """), {"symbol": symbol, "contest_start_date": contest_date})
            
            if result.fetchone():
                logger.info(f"Contest for {symbol} on {contest_date} already exists")
                continue
            
            await conn.execute(text("""
                INSERT INTO prediction_contests 
                (contest_name, symbol, contest_start_date, prediction_deadline, target_date, status, prize_description)
                VALUES (:contest_name, :symbol, :contest_start_date, :prediction_deadline, :target_date, :status, :prize_description)
            """), {
                "contest_name": f"Weekly {symbol} Price Challenge",
                "symbol": symbol,
                "contest_start_date": contest_date,
                "prediction_deadline": datetime.combine(contest_date + timedelta(days=5), datetime.min.time().replace(hour=23, minute=59)),
                "target_date": contest_date + timedelta(days=7),
                "status": "active",
                "prize_description": "Top 3 winners get digital badges and recognition"
            })
            created_count += 1
            logger.info(f"Created contest: Weekly {symbol} Challenge")
        
        await conn.commit()
        logger.info(f"âœ… Created {created_count} prediction contests")
        return created_count
        
    except Exception as e:
        logger.error(f"âŒ Error creating prediction contests: {e}")
        logger.error(traceback.format_exc())
        return 0
    finally:
        await conn.close()

async def generate_theme_insights():
    """ãƒ†ãƒ¼ãƒã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    conn = await get_cloud_sql_connection()
    
    try:
        insights_data = [
            {
                "theme_name": "AI Revolution",
                "theme_category": "technology", 
                "title": "AIä¼æ¥­ã®ç¬¬3å››åŠæœŸæ±ºç®—åˆ†æï¼šæˆé•·ç¶™ç¶šã®éµ",
                "summary": "ç”ŸæˆAIãƒ–ãƒ¼ãƒ ãŒç¶šãä¸­ã€ä¸»è¦AIä¼æ¥­ã®æ±ºç®—ç™ºè¡¨ãŒç›¸æ¬¡ã„ã§ã„ã¾ã™ã€‚NVIDIAã€Microsoftã€Googleãªã©ã®æ¥­ç¸¾ã‹ã‚‰è¦‹ãˆã‚‹ä»Šå¾Œã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¨æŠ•è³‡æ©Ÿä¼šã‚’åˆ†æã—ã¾ã™ã€‚",
                "key_metrics": '{"sector_growth": "35.2%", "market_cap_increase": "$2.1T", "pe_ratio_average": 45.3}',
                "related_symbols": '["NVDA", "MSFT", "GOOGL", "AMZN"]',
                "trend_direction": "bullish",
                "impact_score": 9.2
            },
            {
                "theme_name": "Green Energy Transition",
                "theme_category": "energy",
                "title": "å†ç”Ÿã‚¨ãƒãƒ«ã‚®ãƒ¼æ”¿ç­–ã¨é–¢é€£æ ªã¸ã®å½±éŸ¿",
                "summary": "å„å›½ã®è„±ç‚­ç´ æ”¿ç­–å¼·åŒ–ã«ã‚ˆã‚Šã€å¤ªé™½å…‰ã€é¢¨åŠ›ç™ºé›»é–¢é€£ä¼æ¥­ã«æ³¨ç›®ãŒé›†ã¾ã£ã¦ã„ã¾ã™ã€‚æ”¿ç­–å‹•å‘ã¨æ¥­ç•Œã®æˆé•·è¦‹é€šã—ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚", 
                "key_metrics": '{"policy_support": "89%", "capacity_growth": "28.5%", "cost_reduction": "15.2%"}',
                "related_symbols": '["NEE", "ENPH", "SEDG", "FSLR"]',
                "trend_direction": "bullish",
                "impact_score": 8.7
            },
            {
                "theme_name": "Healthcare Innovation",
                "theme_category": "healthcare",
                "title": "ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯æ–°è–¬æ‰¿èªãƒ©ãƒƒã‚·ãƒ¥ã®æŠ•è³‡ãƒãƒ£ãƒ³ã‚¹",
                "summary": "2024å¹´ã¯æ–°è–¬æ‰¿èªãŒæ´»ç™ºåŒ–ã—ã¦ãŠã‚Šã€ç‰¹ã«ãŒã‚“æ²»ç™‚è–¬ã‚„å¸Œå°‘ç–¾æ‚£æ²»ç™‚è–¬ã®åˆ†é‡ã§ç”»æœŸçš„ãªæ‰¿èªãŒç›¸æ¬¡ã„ã§ã„ã¾ã™ã€‚é–¢é€£ä¼æ¥­ã®æ¥­ç¸¾å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚",
                "key_metrics": '{"new_approvals": 47, "market_size": "$850B", "r_and_d_increase": "12.3%"}',
                "related_symbols": '["JNJ", "PFE", "MRNA", "GILD"]',
                "trend_direction": "neutral", 
                "impact_score": 7.9
            }
        ]
        
        created_count = 0
        for insight_data in insights_data:
            insight_data["insight_date"] = date.today() - timedelta(days=random.randint(0, 30))
            
            # æ—¢å­˜ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯
            result = await conn.execute(text("""
                SELECT id FROM theme_insights 
                WHERE theme_name = :theme_name AND insight_date = :insight_date
            """), {
                "theme_name": insight_data["theme_name"],
                "insight_date": insight_data["insight_date"]
            })
            
            if result.fetchone():
                logger.info(f"Insight for {insight_data['theme_name']} already exists")
                continue
            
            await conn.execute(text("""
                INSERT INTO theme_insights 
                (theme_name, theme_category, insight_date, title, summary, key_metrics, related_symbols, trend_direction, impact_score)
                VALUES (:theme_name, :theme_category, :insight_date, :title, :summary, :key_metrics, :related_symbols, :trend_direction, :impact_score)
            """), insight_data)
            created_count += 1
            logger.info(f"Created insight: {insight_data['title']}")
        
        await conn.commit()
        logger.info(f"âœ… Created {created_count} theme insights")
        return created_count
        
    except Exception as e:
        logger.error(f"âŒ Error creating theme insights: {e}")
        logger.error(traceback.format_exc())
        return 0
    finally:
        await conn.close()

async def generate_user_watchlists():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    conn = await get_cloud_sql_connection()
    
    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—
        result = await conn.execute(text("SELECT user_id FROM user_profiles"))
        users = result.fetchall()
        
        if not users:
            logger.warning("No users found for watchlists")
            return 0
        
        popular_symbols = ["AAPL", "GOOGL", "MSFT", "TSLA", "NVDA", "AMZN", "META", "JPM", "V", "JNJ"]
        
        created_count = 0
        for user in users:
            # ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆç”Ÿæˆ (3-6éŠ˜æŸ„)
            watchlist_symbols = random.sample(popular_symbols, random.randint(3, 6))
            
            for symbol in watchlist_symbols:
                try:
                    await conn.execute(text("""
                        INSERT INTO user_watchlists 
                        (user_id, symbol, alert_threshold_up, alert_threshold_down, notes, priority)
                        VALUES (:user_id, :symbol, :alert_threshold_up, :alert_threshold_down, :notes, :priority)
                    """), {
                        "user_id": user.user_id,
                        "symbol": symbol,
                        "alert_threshold_up": random.uniform(5, 15),
                        "alert_threshold_down": random.uniform(-15, -5),
                        "notes": f"{symbol}ã®é•·æœŸæŠ•è³‡å€™è£œã¨ã—ã¦ç›£è¦–ä¸­",
                        "priority": random.choice(["high", "medium", "low"])
                    })
                    created_count += 1
                except IntegrityError:
                    # é‡è¤‡ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue
        
        await conn.commit()
        logger.info(f"âœ… Created {created_count} watchlist items")
        return created_count
        
    except Exception as e:
        logger.error(f"âŒ Error creating watchlists: {e}")
        logger.error(traceback.format_exc())
        return 0
    finally:
        await conn.close()

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ Enhanced Data Generator Starting...")
    logger.info("=" * 60)
    
    try:
        # 1. ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        logger.info("1. Creating enhanced tables...")
        await create_enhanced_tables()
        
        # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        logger.info("\n2. Generating user profiles...")
        user_count = await generate_user_profiles()
        
        # 3. AIåˆ¤æ–­æ ¹æ‹ ç”Ÿæˆ
        logger.info("\n3. Generating AI decision factors...")
        factor_count = await generate_ai_decision_factors()
        
        # 4. äºˆæ¸¬ã‚³ãƒ³ãƒ†ã‚¹ãƒˆç”Ÿæˆ
        logger.info("\n4. Generating prediction contests...")
        contest_count = await generate_prediction_contests()
        
        # 5. ãƒ†ãƒ¼ãƒã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
        logger.info("\n5. Generating theme insights...")
        insight_count = await generate_theme_insights()
        
        # 6. ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆç”Ÿæˆ
        logger.info("\n6. Generating user watchlists...")
        watchlist_count = await generate_user_watchlists()
        
        # çµæœã‚µãƒãƒªãƒ¼
        logger.info("\n" + "=" * 60)
        logger.info("âœ… Enhanced data generation completed!")
        logger.info(f"ğŸ“Š Generated:")
        logger.info(f"   - User profiles: {user_count}")
        logger.info(f"   - AI decision factors: {factor_count}")
        logger.info(f"   - Prediction contests: {contest_count}")
        logger.info(f"   - Theme insights: {insight_count}")
        logger.info(f"   - Watchlist items: {watchlist_count}")
        logger.info("=" * 60)
        
        return 0
        
    except Exception as e:
        logger.error(f"\nâŒ Error during enhanced data generation: {e}")
        logger.error(traceback.format_exc())
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())