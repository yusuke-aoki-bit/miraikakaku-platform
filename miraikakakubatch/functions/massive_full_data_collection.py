#!/usr/bin/env python3
"""
å¤§è¦æ¨¡å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ 
9,512éŠ˜æŸ„ã™ã¹ã¦ã‚’å¯¾è±¡ã¨ã—ãŸåŒ…æ‹¬çš„ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿åé›†
"""

import yfinance as yf
import pymysql
import logging
import time
from datetime import datetime, timedelta
from typing import List, Dict, Tuple
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MassiveFullDataCollection:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
        }
        self.stats = {
            "total_targets": 0,
            "processed": 0,
            "successful": 0,
            "failed": 0,
            "skipped": 0,
            "by_market": {}
        }
        self.lock = threading.Lock()

    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def get_all_symbols_without_price_data(self) -> List[Tuple]:
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã™ã¹ã¦ã®éŠ˜æŸ„ã‚’å–å¾—ï¼ˆã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®‰å…¨ç‰ˆï¼‰"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # 1. ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ä¸€è¦§ã‚’å–å¾—
                cursor.execute("SELECT DISTINCT symbol FROM stock_price_history")
                existing_symbols = {row[0] for row in cursor.fetchall()}
                logger.info(f"ğŸ“Š ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¿æœ‰éŠ˜æŸ„: {len(existing_symbols):,}éŠ˜æŸ„")
                
                # 2. å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                cursor.execute("""
                    SELECT 
                        symbol,
                        name,
                        exchange,
                        country,
                        CASE 
                            WHEN exchange LIKE '%NYSE%' THEN 'US_NYSE'
                            WHEN exchange LIKE '%NASDAQ%' THEN 'US_NASDAQ'
                            WHEN exchange LIKE '%Market%' AND exchange LIKE '%Domestic%' THEN 'JP_MARKET'
                            WHEN exchange LIKE '%ETF%' OR name LIKE '%ETF%' THEN 'ETF'
                            WHEN country IN ('UK', 'DE', 'FR', 'CH') THEN 'EUROPE'
                            WHEN country = 'KR' THEN 'KOREA'
                            WHEN country = 'AU' THEN 'AUSTRALIA'
                            ELSE 'OTHER'
                        END as market_category
                    FROM stock_master
                    WHERE is_active = 1
                    ORDER BY RAND()
                """)
                
                all_symbols = cursor.fetchall()
                
                # 3. Pythonå´ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„éŠ˜æŸ„ã®ã¿ï¼‰
                results = []
                for row in all_symbols:
                    symbol = row[0]
                    if symbol not in existing_symbols:
                        results.append(row)
                
                logger.info(f"ğŸ“Š ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãªã—éŠ˜æŸ„: {len(results):,}éŠ˜æŸ„ç™ºè¦‹")
                
                # å¸‚å ´åˆ¥çµ±è¨ˆ
                market_counts = {}
                for row in results:
                    market = row[4]
                    market_counts[market] = market_counts.get(market, 0) + 1
                
                logger.info("ğŸŒ å¸‚å ´åˆ¥å†…è¨³:")
                for market, count in sorted(market_counts.items()):
                    logger.info(f"  {market}: {count:,}éŠ˜æŸ„")
                
                return results
                
        finally:
            connection.close()

    def prepare_symbol_for_yfinance(self, symbol: str, exchange: str, country: str) -> str:
        """Yahoo Financeç”¨ã®ã‚·ãƒ³ãƒœãƒ«æº–å‚™"""
        original_symbol = symbol
        
        # æ—¥æœ¬å¸‚å ´
        if exchange and 'Market' in exchange and 'Domestic' in exchange:
            if len(symbol) == 4 and symbol.isdigit():
                return symbol + '.T'
        
        # éŸ“å›½å¸‚å ´
        elif country == 'KR':
            if not symbol.endswith('.KS'):
                return symbol + '.KS'
        
        # è‹±å›½å¸‚å ´
        elif country == 'UK':
            if not symbol.endswith('.L'):
                return symbol + '.L'
        
        # ãƒ‰ã‚¤ãƒ„å¸‚å ´
        elif country == 'DE':
            if not symbol.endswith('.DE'):
                return symbol + '.DE'
        
        # ãƒ•ãƒ©ãƒ³ã‚¹å¸‚å ´
        elif country == 'FR':
            if not symbol.endswith('.PA'):
                return symbol + '.PA'
        
        # ã‚¹ã‚¤ã‚¹å¸‚å ´
        elif country == 'CH':
            if not symbol.endswith('.SW'):
                return symbol + '.SW'
        
        # ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢å¸‚å ´
        elif country == 'AU':
            if not symbol.endswith('.AX'):
                return symbol + '.AX'
        
        return original_symbol

    def fetch_single_symbol_data(self, symbol_data: Tuple) -> Dict:
        """å˜ä¸€éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        symbol, name, exchange, country, market_category = symbol_data
        
        # Yahoo Financeç”¨ã‚·ãƒ³ãƒœãƒ«æº–å‚™
        yf_symbol = self.prepare_symbol_for_yfinance(symbol, exchange, country)
        
        result = {
            'original_symbol': symbol,
            'yf_symbol': yf_symbol,
            'name': name[:100] if name else symbol,
            'market_category': market_category,
            'success': False,
            'error': None,
            'price_data': None
        }
        
        try:
            ticker = yf.Ticker(yf_symbol)
            hist = ticker.history(period="5d")
            
            if hist.empty:
                result['error'] = 'No price data available'
                return result
            
            # æœ€æ–°ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            latest_data = hist.iloc[-1]
            latest_date = hist.index[-1].strftime('%Y-%m-%d')
            
            result['price_data'] = {
                'date': latest_date,
                'open': float(latest_data['Open']),
                'high': float(latest_data['High']),
                'low': float(latest_data['Low']),
                'close': float(latest_data['Close']),
                'volume': int(latest_data['Volume'])
            }
            
            result['success'] = True
            return result
            
        except Exception as e:
            result['error'] = str(e)[:100]
            return result

    def save_price_data(self, result: Dict) -> bool:
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        if not result['success'] or not result['price_data']:
            return False
        
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                price = result['price_data']
                cursor.execute("""
                    INSERT INTO stock_price_history 
                    (symbol, date, open_price, high_price, low_price, close_price, volume, 
                     data_source, created_at, updated_at, is_valid, data_quality_score)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), 1, 0.95)
                    ON DUPLICATE KEY UPDATE
                    close_price = VALUES(close_price),
                    volume = VALUES(volume),
                    updated_at = NOW()
                """, (
                    result['original_symbol'],
                    price['date'],
                    price['open'],
                    price['high'],
                    price['low'],
                    price['close'],
                    price['volume'],
                    f"Massive Collection - {result['market_category']}"
                ))
                
            connection.commit()
            return True
            
        except Exception as e:
            logger.error(f"DBä¿å­˜ã‚¨ãƒ©ãƒ¼ {result['original_symbol']}: {e}")
            return False
        finally:
            connection.close()

    def process_symbol_batch(self, symbol_batch: List[Tuple], batch_id: int):
        """éŠ˜æŸ„ãƒãƒƒãƒå‡¦ç†"""
        logger.info(f"ğŸ”„ ãƒãƒƒãƒ {batch_id} é–‹å§‹: {len(symbol_batch)}éŠ˜æŸ„")
        
        batch_stats = {"successful": 0, "failed": 0, "by_market": {}}
        
        for symbol_data in symbol_batch:
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
            result = self.fetch_single_symbol_data(symbol_data)
            
            # çµ±è¨ˆæ›´æ–°
            with self.lock:
                self.stats["processed"] += 1
                
                if result['success']:
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                    if self.save_price_data(result):
                        self.stats["successful"] += 1
                        batch_stats["successful"] += 1
                        
                        # å¸‚å ´åˆ¥çµ±è¨ˆ
                        market = result['market_category']
                        self.stats["by_market"][market] = self.stats["by_market"].get(market, 0) + 1
                        batch_stats["by_market"][market] = batch_stats["by_market"].get(market, 0) + 1
                        
                        if self.stats["successful"] % 100 == 0:
                            logger.info(f"âœ… é€²æ—: {self.stats['successful']:,}éŠ˜æŸ„æˆåŠŸ / {self.stats['processed']:,}å‡¦ç†æ¸ˆã¿")
                    else:
                        self.stats["failed"] += 1
                        batch_stats["failed"] += 1
                else:
                    self.stats["failed"] += 1
                    batch_stats["failed"] += 1
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
            time.sleep(0.1)
        
        logger.info(f"âœ… ãƒãƒƒãƒ {batch_id} å®Œäº†: æˆåŠŸ{batch_stats['successful']}, å¤±æ•—{batch_stats['failed']}")

    def run_massive_collection(self, max_workers: int = 4, batch_size: int = 100):
        """å¤§è¦æ¨¡å…¨éŠ˜æŸ„åé›†å®Ÿè¡Œ"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ å¤§è¦æ¨¡å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # å¯¾è±¡éŠ˜æŸ„å–å¾—
        target_symbols = self.get_all_symbols_without_price_data()
        
        if not target_symbols:
            logger.info("âœ… ã™ã¹ã¦ã®éŠ˜æŸ„ã«ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã™")
            return
        
        self.stats["total_targets"] = len(target_symbols)
        logger.info(f"ğŸ“Š å¯¾è±¡éŠ˜æŸ„: {len(target_symbols):,}éŠ˜æŸ„")
        
        # ãƒãƒƒãƒã«åˆ†å‰²
        batches = []
        for i in range(0, len(target_symbols), batch_size):
            batch = target_symbols[i:i + batch_size]
            batches.append(batch)
        
        logger.info(f"ğŸ”„ {len(batches)}ãƒãƒƒãƒã§ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œï¼ˆæœ€å¤§{max_workers}ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰")
        
        # ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            
            for batch_id, batch in enumerate(batches, 1):
                future = executor.submit(self.process_symbol_batch, batch, batch_id)
                futures.append(future)
                time.sleep(0.5)  # ãƒãƒƒãƒé–“ã®é–“éš”
            
            # ã™ã¹ã¦ã®ãƒãƒƒãƒå®Œäº†ã‚’å¾…æ©Ÿ
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 80)
        logger.info("ğŸ“Š å¤§è¦æ¨¡å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info("=" * 80)
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.0f}ç§’ ({duration/60:.1f}åˆ†)")
        logger.info(f"ğŸ¯ å¯¾è±¡éŠ˜æŸ„: {self.stats['total_targets']:,}éŠ˜æŸ„")
        logger.info(f"ğŸ“Š å‡¦ç†æ¸ˆã¿: {self.stats['processed']:,}éŠ˜æŸ„")
        logger.info(f"âœ… æˆåŠŸ: {self.stats['successful']:,}éŠ˜æŸ„")
        logger.info(f"âŒ å¤±æ•—: {self.stats['failed']:,}éŠ˜æŸ„")
        
        if self.stats['processed'] > 0:
            success_rate = (self.stats['successful'] / self.stats['processed']) * 100
            logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
        
        logger.info("ğŸŒ å¸‚å ´åˆ¥æˆåŠŸæ•°:")
        for market, count in sorted(self.stats['by_market'].items()):
            logger.info(f"  {market}: {count:,}éŠ˜æŸ„")
        
        # å‡¦ç†é€Ÿåº¦
        if duration > 0:
            speed = self.stats['processed'] / duration
            logger.info(f"âš¡ å‡¦ç†é€Ÿåº¦: {speed:.1f}éŠ˜æŸ„/ç§’")
        
        logger.info("=" * 80)
        
        return self.stats

if __name__ == "__main__":
    collector = MassiveFullDataCollection()
    
    try:
        # å¤§è¦æ¨¡åé›†å®Ÿè¡Œï¼ˆ4ã‚¹ãƒ¬ãƒƒãƒ‰ã€100éŠ˜æŸ„/ãƒãƒƒãƒï¼‰
        results = collector.run_massive_collection(max_workers=4, batch_size=100)
        
        # æœ€çµ‚çŠ¶æ³ç¢ºèª
        logger.info("\nğŸ” åé›†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ç¢ºèªä¸­...")
        connection = pymysql.connect(**collector.db_config)
        try:
            with connection.cursor() as cursor:
                cursor.execute('SELECT COUNT(DISTINCT symbol) FROM stock_price_history')
                final_count = cursor.fetchone()[0]
                logger.info(f"ğŸ“Š æœ€çµ‚ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¿æœ‰éŠ˜æŸ„æ•°: {final_count:,}éŠ˜æŸ„")
        finally:
            connection.close()
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢")
        logger.info(f"â¸ï¸ ä¸­æ–­æ™‚ç‚¹: {collector.stats['successful']:,}éŠ˜æŸ„æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()