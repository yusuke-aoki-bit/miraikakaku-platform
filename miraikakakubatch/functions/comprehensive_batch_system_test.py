#!/usr/bin/env python3
"""
çµ±åˆãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ  - ãƒ†ã‚¹ãƒˆç‰ˆ
ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹éŠ˜æŸ„ã®ã¿ã‚’ä½¿ç”¨
"""

import yfinance as yf
import pymysql
import logging
import time
from datetime import datetime, timedelta
from typing import List, Dict
import threading
from concurrent.futures import ThreadPoolExecutor
import pandas as pd
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ComprehensiveBatchSystemTest:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
        }
        self.stats = {
            "data_collection": {
                "processed": 0,
                "successful": 0,
                "failed": 0
            },
            "prediction": {
                "lstm_predictions": 0,
                "vertexai_predictions": 0,
                "lstm_success": 0,
                "vertexai_success": 0,
                "total_symbols": 0
            }
        }
        self.lock = threading.Lock()

    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def get_test_symbols(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹éŠ˜æŸ„ãƒªã‚¹ãƒˆ"""
        return {
            "us_stocks": [
                ("AAPL", "Apple Inc."),
                ("MSFT", "Microsoft Corporation"), 
                ("GOOGL", "Alphabet Inc."),
                ("AMZN", "Amazon.com Inc."),
                ("NVDA", "NVIDIA Corporation")
            ],
            "jp_stocks": [
                ("7203", "Toyota Motor Corp", "7203.T"),
                ("6758", "Sony Group Corp", "6758.T"),
                ("9984", "SoftBank Group Corp", "9984.T"),
                ("6861", "Keyence Corp", "6861.T"),
                ("4519", "Chugai Pharmaceutical", "4519.T")
            ],
            "etfs": [
                ("SPY", "SPDR S&P 500 ETF"),
                ("QQQ", "Invesco QQQ Trust"),
                ("VTI", "Vanguard Total Stock Market ETF")
            ],
            "fx_pairs": [
                "USDJPY=X", "EURJPY=X", "GBPJPY=X"
            ]
        }

    def collect_test_data(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åé›†"""
        logger.info("ğŸš€ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
        test_symbols = self.get_test_symbols()
        
        # 1. ç±³å›½æ ª
        logger.info("ğŸ‡ºğŸ‡¸ ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿åé›†")
        for symbol, name in test_symbols["us_stocks"]:
            success = self.collect_single_stock_data(symbol, name, "US_TEST")
            self.stats["data_collection"]["processed"] += 1
            if success:
                logger.info(f"âœ… {symbol} ({name}): åé›†æˆåŠŸ")
            time.sleep(0.5)
        
        # 2. æ—¥æœ¬æ ª
        logger.info("ğŸ‡¯ğŸ‡µ æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿åé›†")
        for symbol, name, yf_symbol in test_symbols["jp_stocks"]:
            success = self.collect_single_stock_data(symbol, name, "JP_TEST", yf_symbol)
            self.stats["data_collection"]["processed"] += 1
            if success:
                logger.info(f"âœ… {yf_symbol} ({name}): åé›†æˆåŠŸ")
            time.sleep(0.5)
        
        # 3. ETF
        logger.info("ğŸ“Š ETFãƒ‡ãƒ¼ã‚¿åé›†")
        for symbol, name in test_symbols["etfs"]:
            success = self.collect_single_stock_data(symbol, name, "ETF_TEST")
            self.stats["data_collection"]["processed"] += 1
            if success:
                logger.info(f"âœ… {symbol} ({name}): åé›†æˆåŠŸ")
            time.sleep(0.5)
        
        # 4. ç‚ºæ›¿
        logger.info("ğŸ’± ç‚ºæ›¿ãƒ‡ãƒ¼ã‚¿åé›†")
        for fx_symbol in test_symbols["fx_pairs"]:
            success = self.collect_single_fx_data(fx_symbol)
            if success:
                logger.info(f"âœ… {fx_symbol}: åé›†æˆåŠŸ")
            time.sleep(0.5)

    def collect_single_stock_data(self, symbol, name, market_type, yf_symbol=None):
        """å˜ä¸€éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿åé›†"""
        if not yf_symbol:
            yf_symbol = symbol
            
        try:
            ticker = yf.Ticker(yf_symbol)
            hist = ticker.history(period="5d")
            
            if hist.empty:
                self.stats["data_collection"]["failed"] += 1
                return False
            
            latest_data = hist.iloc[-1]
            latest_date = hist.index[-1].strftime('%Y-%m-%d')
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            connection = self.get_connection()
            try:
                with connection.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO stock_price_history 
                        (symbol, date, open_price, high_price, low_price, close_price, volume, 
                         data_source, created_at, updated_at, is_valid, data_quality_score)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), 1, 0.95)
                        ON DUPLICATE KEY UPDATE
                        close_price = VALUES(close_price),
                        volume = VALUES(volume),
                        updated_at = NOW()
                    """, (
                        symbol, latest_date,
                        float(latest_data['Open']),
                        float(latest_data['High']),
                        float(latest_data['Low']),
                        float(latest_data['Close']),
                        int(latest_data['Volume']),
                        f"Test Batch - {market_type}"
                    ))
                    
                connection.commit()
                self.stats["data_collection"]["successful"] += 1
                return True
                
            finally:
                connection.close()
                
        except Exception as e:
            logger.error(f"âŒ {yf_symbol}ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats["data_collection"]["failed"] += 1
            return False

    def collect_single_fx_data(self, fx_symbol):
        """å˜ä¸€ç‚ºæ›¿ãƒ‡ãƒ¼ã‚¿åé›†"""
        try:
            ticker = yf.Ticker(fx_symbol)
            hist = ticker.history(period="5d")
            
            if hist.empty:
                return False
            
            latest_data = hist.iloc[-1]
            logger.info(f"ğŸ’± {fx_symbol}: {latest_data['Close']:.4f}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ {fx_symbol}ç‚ºæ›¿ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def run_test_predictions(self):
        """ãƒ†ã‚¹ãƒˆäºˆæ¸¬å®Ÿè¡Œ"""
        logger.info("ğŸ¤– ãƒ†ã‚¹ãƒˆäºˆæ¸¬ãƒãƒƒãƒé–‹å§‹")
        
        # ãƒ†ã‚¹ãƒˆå¯¾è±¡éŠ˜æŸ„ï¼ˆåé›†æ¸ˆã¿éŠ˜æŸ„ã‹ã‚‰é¸æŠï¼‰
        test_symbols = ["AAPL", "MSFT", "GOOGL", "7203", "6758"]
        self.stats["prediction"]["total_symbols"] = len(test_symbols)
        
        for symbol in test_symbols:
            logger.info(f"ğŸ” {symbol}ã®äºˆæ¸¬é–‹å§‹")
            
            # LSTMäºˆæ¸¬
            lstm_results = self.run_test_lstm_prediction(symbol)
            
            # VertexAIäºˆæ¸¬
            vertexai_results = self.run_test_vertexai_prediction(symbol)
            
            # çµæœä¿å­˜
            self.save_test_prediction_results(symbol, lstm_results, vertexai_results)
            
            logger.info(f"âœ… {symbol}äºˆæ¸¬å®Œäº†: LSTMä¿¡é ¼åº¦{lstm_results['confidence']}, VertexAIä¿¡é ¼åº¦{vertexai_results['confidence']}")
            
            time.sleep(1)

    def run_test_lstm_prediction(self, symbol):
        """ãƒ†ã‚¹ãƒˆç”¨LSTMäºˆæ¸¬"""
        # ç°¡æ˜“ç‰ˆ - å®Ÿéš›ã®å®Ÿè£…ã§ã¯æœ¬æ ¼çš„ãªLSTMãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        predictions = {
            "model_type": "lstm_test_v2",
            "confidence": round(0.75 + np.random.random() * 0.1, 2),
            "predictions_count": 0
        }
        
        # éå»30æ—¥é–“ã®äºˆæ¸¬ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«çŸ­ç¸®ï¼‰
        for days_ago in range(30, 0, -1):
            pred_date = datetime.now() - timedelta(days=days_ago)
            predictions["predictions_count"] += 1
        
        # æœªæ¥30æ—¥é–“ã®äºˆæ¸¬ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«çŸ­ç¸®ï¼‰
        for days_ahead in range(1, 31):
            pred_date = datetime.now() + timedelta(days=days_ahead)
            predictions["predictions_count"] += 1
        
        with self.lock:
            self.stats["prediction"]["lstm_predictions"] += predictions["predictions_count"]
            self.stats["prediction"]["lstm_success"] += 1
        
        return predictions

    def run_test_vertexai_prediction(self, symbol):
        """ãƒ†ã‚¹ãƒˆç”¨VertexAIäºˆæ¸¬"""
        predictions = {
            "model_type": "vertexai_test_v2",
            "confidence": round(0.80 + np.random.random() * 0.1, 2),
            "predictions_count": 0
        }
        
        # éå»30æ—¥é–“ã®äºˆæ¸¬
        for days_ago in range(30, 0, -1):
            predictions["predictions_count"] += 1
        
        # æœªæ¥30æ—¥é–“ã®äºˆæ¸¬
        for days_ahead in range(1, 31):
            predictions["predictions_count"] += 1
        
        with self.lock:
            self.stats["prediction"]["vertexai_predictions"] += predictions["predictions_count"]
            self.stats["prediction"]["vertexai_success"] += 1
        
        return predictions

    def save_test_prediction_results(self, symbol, lstm_results, vertexai_results):
        """ãƒ†ã‚¹ãƒˆç”¨äºˆæ¸¬çµæœä¿å­˜"""
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # LSTMçµæœä¿å­˜ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
                for i in range(5):  # ãƒ†ã‚¹ãƒˆç”¨ã«5ä»¶ã®ã¿
                    pred_date = datetime.now() + timedelta(days=i+1)
                    cursor.execute("""
                        INSERT INTO stock_predictions 
                        (symbol, prediction_date, predicted_price, predicted_change_percent,
                         confidence_score, model_type, model_version, prediction_horizon,
                         created_at, is_active)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), 1)
                    """, (
                        symbol, pred_date,
                        100.0 + np.random.normal(0, 5),  # ä»®ã®ä¾¡æ ¼
                        np.random.normal(0, 2),  # ä»®ã®å¤‰åŒ–ç‡
                        lstm_results["confidence"],
                        lstm_results["model_type"],
                        "v2.0.test", 1
                    ))
                
                # VertexAIçµæœä¿å­˜ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
                for i in range(5):
                    pred_date = datetime.now() + timedelta(days=i+1)
                    cursor.execute("""
                        INSERT INTO stock_predictions 
                        (symbol, prediction_date, predicted_price, predicted_change_percent,
                         confidence_score, model_type, model_version, prediction_horizon,
                         created_at, is_active)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), 1)
                    """, (
                        symbol, pred_date,
                        100.0 + np.random.normal(0, 3),
                        np.random.normal(0, 1.5),
                        vertexai_results["confidence"],
                        vertexai_results["model_type"],
                        "v2.0.test", 1
                    ))
                
                connection.commit()
                
        finally:
            connection.close()

    def run_comprehensive_test(self):
        """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ çµ±åˆãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆé–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿åé›†ãƒ†ã‚¹ãƒˆ
            self.collect_test_data()
            
            logger.info("â¸ï¸  ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†ã€äºˆæ¸¬ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
            time.sleep(2)
            
            # 2. äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
            self.run_test_predictions()
            
        except Exception as e:
            logger.error(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 70)
        logger.info("ğŸ“Š çµ±åˆãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’")
        logger.info("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åé›†:")
        logger.info(f"  ğŸ¯ å‡¦ç†: {self.stats['data_collection']['processed']}ä»¶")
        logger.info(f"  âœ… æˆåŠŸ: {self.stats['data_collection']['successful']}ä»¶")
        logger.info(f"  âŒ å¤±æ•—: {self.stats['data_collection']['failed']}ä»¶")
        logger.info("ğŸ¤– äºˆæ¸¬:")
        logger.info(f"  ğŸ“Š å¯¾è±¡éŠ˜æŸ„: {self.stats['prediction']['total_symbols']}éŠ˜æŸ„")
        logger.info(f"  ğŸ§  LSTMäºˆæ¸¬: {self.stats['prediction']['lstm_predictions']}ä»¶")
        logger.info(f"  ğŸ¯ VertexAIäºˆæ¸¬: {self.stats['prediction']['vertexai_predictions']}ä»¶")
        logger.info(f"  âœ… LSTMæˆåŠŸ: {self.stats['prediction']['lstm_success']}éŠ˜æŸ„")
        logger.info(f"  âœ… VertexAIæˆåŠŸ: {self.stats['prediction']['vertexai_success']}éŠ˜æŸ„")
        logger.info("=" * 70)

if __name__ == "__main__":
    batch_system = ComprehensiveBatchSystemTest()
    
    try:
        batch_system.run_comprehensive_test()
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢")
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()