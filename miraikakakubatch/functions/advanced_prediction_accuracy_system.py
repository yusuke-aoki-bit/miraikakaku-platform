#!/usr/bin/env python3
"""
é«˜åº¦ãªäºˆæ¸¬ç²¾åº¦è©•ä¾¡ãƒ»æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ 
ç”Ÿæˆã•ã‚ŒãŸäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦ã‚’è©•ä¾¡ã—ã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹
"""

import pymysql
import numpy as np
import pandas as pd
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import json

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AdvancedPredictionAccuracySystem:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
            "charset": "utf8mb4"
        }
        
    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def evaluate_prediction_accuracy(self, days_back: int = 30) -> Dict:
        """éå»ã®äºˆæ¸¬ç²¾åº¦ã‚’è©•ä¾¡"""
        logger.info(f"ğŸ§® éå»{days_back}æ—¥é–“ã®äºˆæ¸¬ç²¾åº¦è©•ä¾¡é–‹å§‹")
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # äºˆæ¸¬ã¨å®Ÿç¸¾ä¾¡æ ¼ã‚’çµåˆã—ã¦å–å¾—
                cursor.execute("""
                    SELECT 
                        sp.symbol,
                        sp.model_type,
                        sp.model_version,
                        sp.prediction_date,
                        sp.predicted_price,
                        sp.predicted_change_percent,
                        sp.confidence_score,
                        sp.prediction_horizon,
                        sph.close_price as actual_price,
                        sph.date as actual_date
                    FROM stock_predictions sp
                    JOIN stock_price_history sph ON sp.symbol = sph.symbol
                    WHERE sp.prediction_date >= %s
                    AND DATE(sph.date) = DATE(DATE_ADD(sp.prediction_date, INTERVAL sp.prediction_horizon DAY))
                    AND sp.predicted_price IS NOT NULL
                    AND sph.close_price IS NOT NULL
                    ORDER BY sp.prediction_date DESC
                    LIMIT 10000
                """, (datetime.now() - timedelta(days=days_back),))
                
                predictions = cursor.fetchall()
                
                if not predictions:
                    logger.warning("âš ï¸ è©•ä¾¡å¯èƒ½ãªäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãªã—")
                    return {}
                
                logger.info(f"ğŸ“Š è©•ä¾¡å¯¾è±¡äºˆæ¸¬æ•°: {len(predictions)}")
                
                # ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                accuracy_results = self.calculate_accuracy_metrics(predictions)
                
                # ãƒ¢ãƒ‡ãƒ«åˆ¥ç²¾åº¦
                model_accuracy = self.calculate_model_accuracy(predictions)
                
                # éŠ˜æŸ„åˆ¥ç²¾åº¦
                symbol_accuracy = self.calculate_symbol_accuracy(predictions)
                
                # ä¿¡é ¼åº¦åˆ¥ç²¾åº¦
                confidence_accuracy = self.calculate_confidence_accuracy(predictions)
                
                return {
                    'overall': accuracy_results,
                    'by_model': model_accuracy,
                    'by_symbol': symbol_accuracy,
                    'by_confidence': confidence_accuracy,
                    'evaluation_count': len(predictions)
                }
                
        except Exception as e:
            logger.error(f"âŒ äºˆæ¸¬ç²¾åº¦è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
        finally:
            connection.close()

    def calculate_accuracy_metrics(self, predictions: List[Tuple]) -> Dict:
        """äºˆæ¸¬ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
        mae_values = []  # Mean Absolute Error
        mse_values = []  # Mean Squared Error
        mape_values = []  # Mean Absolute Percentage Error
        directional_accuracy = []  # æ–¹å‘æ€§ç²¾åº¦
        
        for pred in predictions:
            predicted_price = pred[4]
            actual_price = pred[8]
            predicted_change_pct = pred[5]
            
            if predicted_price and actual_price and actual_price > 0:
                # MAE, MSEè¨ˆç®—
                absolute_error = abs(predicted_price - actual_price)
                squared_error = (predicted_price - actual_price) ** 2
                
                mae_values.append(absolute_error)
                mse_values.append(squared_error)
                
                # MAPEè¨ˆç®—
                percentage_error = abs((predicted_price - actual_price) / actual_price) * 100
                mape_values.append(percentage_error)
                
                # æ–¹å‘æ€§ç²¾åº¦ï¼ˆä¾¡æ ¼ä¸Šæ˜‡/ä¸‹é™ã®äºˆæ¸¬ãŒæ­£ã—ã„ã‹ï¼‰
                if predicted_change_pct is not None:
                    predicted_direction = 1 if predicted_change_pct > 0 else -1
                    # å®Ÿéš›ã®å¤‰å‹•ã‚’æ¨å®šï¼ˆç¾åœ¨ä¾¡æ ¼ã‹ã‚‰é€†ç®—ï¼‰
                    estimated_previous_price = actual_price / (1 + predicted_change_pct / 100)
                    actual_direction = 1 if actual_price > estimated_previous_price else -1
                    
                    directional_accuracy.append(1 if predicted_direction == actual_direction else 0)
        
        return {
            'mae': np.mean(mae_values) if mae_values else 0,
            'mse': np.mean(mse_values) if mse_values else 0,
            'rmse': np.sqrt(np.mean(mse_values)) if mse_values else 0,
            'mape': np.mean(mape_values) if mape_values else 0,
            'directional_accuracy': np.mean(directional_accuracy) if directional_accuracy else 0,
            'sample_count': len(predictions)
        }

    def calculate_model_accuracy(self, predictions: List[Tuple]) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«åˆ¥ç²¾åº¦ã‚’è¨ˆç®—"""
        model_results = {}
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        models = {}
        for pred in predictions:
            model_key = f"{pred[1]}_{pred[2]}"  # model_type_model_version
            if model_key not in models:
                models[model_key] = []
            models[model_key].append(pred)
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦è¨ˆç®—
        for model_key, model_preds in models.items():
            if len(model_preds) >= 5:  # æœ€ä½5ã¤ã®äºˆæ¸¬ãŒã‚ã‚‹å ´åˆã®ã¿è©•ä¾¡
                model_results[model_key] = self.calculate_accuracy_metrics(model_preds)
        
        return model_results

    def calculate_symbol_accuracy(self, predictions: List[Tuple]) -> Dict:
        """éŠ˜æŸ„åˆ¥ç²¾åº¦ã‚’è¨ˆç®—"""
        symbol_results = {}
        
        # éŠ˜æŸ„åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        symbols = {}
        for pred in predictions:
            symbol = pred[0]
            if symbol not in symbols:
                symbols[symbol] = []
            symbols[symbol].append(pred)
        
        # å„éŠ˜æŸ„ã®ç²¾åº¦è¨ˆç®—ï¼ˆäºˆæ¸¬æ•°ãŒå¤šã„ä¸Šä½20éŠ˜æŸ„ï¼‰
        symbol_counts = [(symbol, len(preds)) for symbol, preds in symbols.items()]
        symbol_counts.sort(key=lambda x: x[1], reverse=True)
        
        for symbol, count in symbol_counts[:20]:
            if count >= 3:
                symbol_results[symbol] = self.calculate_accuracy_metrics(symbols[symbol])
        
        return symbol_results

    def calculate_confidence_accuracy(self, predictions: List[Tuple]) -> Dict:
        """ä¿¡é ¼åº¦åŒºé–“åˆ¥ç²¾åº¦ã‚’è¨ˆç®—"""
        confidence_ranges = {
            'high': (0.8, 1.0),
            'medium': (0.6, 0.8),
            'low': (0.0, 0.6)
        }
        
        confidence_results = {}
        
        for range_name, (min_conf, max_conf) in confidence_ranges.items():
            range_preds = [
                pred for pred in predictions 
                if pred[6] and min_conf <= pred[6] < max_conf  # confidence_score
            ]
            
            if range_preds:
                confidence_results[range_name] = self.calculate_accuracy_metrics(range_preds)
        
        return confidence_results

    def update_model_performance_table(self, accuracy_results: Dict):
        """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°"""
        logger.info("ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°é–‹å§‹")
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # å…¨ä½“æ€§èƒ½ã‚’è¨˜éŒ²
                overall_results = accuracy_results.get('overall', {})
                if overall_results:
                    cursor.execute("""
                        INSERT INTO model_performance 
                        (model_type, model_version, mae, mse, rmse, accuracy, 
                         evaluation_start_date, evaluation_end_date, symbols_count, 
                         is_active, created_at, updated_at)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                    """, (
                        'ensemble_evaluation',
                        'v4.0',
                        overall_results.get('mae', 0),
                        overall_results.get('mse', 0),
                        overall_results.get('rmse', 0),
                        overall_results.get('directional_accuracy', 0),
                        datetime.now() - timedelta(days=30),
                        datetime.now(),
                        accuracy_results.get('evaluation_count', 0),
                        1
                    ))
                
                # ãƒ¢ãƒ‡ãƒ«åˆ¥æ€§èƒ½ã‚’è¨˜éŒ²
                model_results = accuracy_results.get('by_model', {})
                for model_key, metrics in model_results.items():
                    model_parts = model_key.split('_', 1)
                    model_type = model_parts[0] if model_parts else 'unknown'
                    model_version = model_parts[1] if len(model_parts) > 1 else 'unknown'
                    
                    cursor.execute("""
                        INSERT INTO model_performance 
                        (model_type, model_version, mae, mse, rmse, accuracy, 
                         evaluation_start_date, evaluation_end_date, symbols_count, 
                         is_active, created_at, updated_at)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                        ON DUPLICATE KEY UPDATE
                        mae = VALUES(mae),
                        mse = VALUES(mse),
                        rmse = VALUES(rmse),
                        accuracy = VALUES(accuracy),
                        updated_at = NOW()
                    """, (
                        model_type,
                        model_version,
                        metrics.get('mae', 0),
                        metrics.get('mse', 0),
                        metrics.get('rmse', 0),
                        metrics.get('directional_accuracy', 0),
                        datetime.now() - timedelta(days=30),
                        datetime.now(),
                        metrics.get('sample_count', 0),
                        1
                    ))
                
                connection.commit()
                logger.info("âœ… ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°å®Œäº†")
                
        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            connection.close()

    def log_ai_inference_activity(self, accuracy_results: Dict):
        """AIæ¨è«–ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        logger.info("ğŸ“ AIæ¨è«–ãƒ­ã‚°è¨˜éŒ²é–‹å§‹")
        connection = self.get_connection()
        
        try:
            with connection.cursor() as cursor:
                # æ¨è«–ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
                log_entries = []
                
                model_results = accuracy_results.get('by_model', {})
                
                for model_key, metrics in model_results.items():
                    model_parts = model_key.split('_', 1)
                    model_name = model_parts[0] if model_parts else 'unknown'
                    model_version = model_parts[1] if len(model_parts) > 1 else 'unknown'
                    
                    log_entry = {
                        'request_id': f"accuracy_eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{model_name}",
                        'model_name': model_name,
                        'model_version': model_version,
                        'input_data': json.dumps({'evaluation_type': 'accuracy_assessment'}),
                        'output_data': json.dumps({
                            'mae': metrics.get('mae', 0),
                            'mse': metrics.get('mse', 0),
                            'directional_accuracy': metrics.get('directional_accuracy', 0),
                            'sample_count': metrics.get('sample_count', 0)
                        }),
                        'inference_time_ms': int(metrics.get('sample_count', 0) * 10),  # æ¨å®šå‡¦ç†æ™‚é–“
                        'confidence_score': metrics.get('directional_accuracy', 0),
                        'is_successful': 1,
                        'endpoint': '/api/prediction/evaluate',
                        'user_id': 'system',
                        'session_id': f"eval_session_{datetime.now().strftime('%Y%m%d')}"
                    }
                    log_entries.append(log_entry)
                
                # ãƒãƒƒãƒæŒ¿å…¥
                if log_entries:
                    insert_query = """
                        INSERT INTO ai_inference_log 
                        (request_id, model_name, model_version, input_data, output_data,
                         inference_time_ms, confidence_score, is_successful, endpoint,
                         user_id, session_id, created_at)
                        VALUES (%(request_id)s, %(model_name)s, %(model_version)s, %(input_data)s,
                                %(output_data)s, %(inference_time_ms)s, %(confidence_score)s,
                                %(is_successful)s, %(endpoint)s, %(user_id)s, %(session_id)s, NOW())
                    """
                    
                    cursor.executemany(insert_query, log_entries)
                    connection.commit()
                    
                    logger.info(f"âœ… AIæ¨è«–ãƒ­ã‚° {len(log_entries)}ä»¶è¨˜éŒ²å®Œäº†")
                
        except Exception as e:
            logger.error(f"âŒ AIæ¨è«–ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            connection.close()

    def generate_comprehensive_accuracy_report(self):
        """åŒ…æ‹¬çš„ãªç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        logger.info("ğŸ“Š åŒ…æ‹¬çš„ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
        
        # äºˆæ¸¬ç²¾åº¦è©•ä¾¡å®Ÿè¡Œ
        accuracy_results = self.evaluate_prediction_accuracy(days_back=30)
        
        if not accuracy_results:
            logger.warning("âš ï¸ ç²¾åº¦è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãªã—")
            return
        
        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°
        self.update_model_performance_table(accuracy_results)
        
        # AIæ¨è«–ãƒ­ã‚°è¨˜éŒ²
        self.log_ai_inference_activity(accuracy_results)
        
        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        self.print_accuracy_report(accuracy_results)

    def print_accuracy_report(self, results: Dict):
        """ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
        logger.info("=" * 80)
        logger.info("ğŸ“Š é«˜åº¦äºˆæ¸¬ç²¾åº¦è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info("=" * 80)
        
        # å…¨ä½“ç²¾åº¦
        overall = results.get('overall', {})
        if overall:
            logger.info("ã€å…¨ä½“ç²¾åº¦ã€‘")
            logger.info(f"  MAE (å¹³å‡çµ¶å¯¾èª¤å·®): {overall.get('mae', 0):.2f}")
            logger.info(f"  RMSE (å¹³å‡å¹³æ–¹æ ¹èª¤å·®): {overall.get('rmse', 0):.2f}")
            logger.info(f"  MAPE (å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®): {overall.get('mape', 0):.2f}%")
            logger.info(f"  æ–¹å‘æ€§ç²¾åº¦: {overall.get('directional_accuracy', 0):.1%}")
            logger.info(f"  è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {overall.get('sample_count', 0):,}")
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ç²¾åº¦ï¼ˆä¸Šä½5ä½ï¼‰
        model_results = results.get('by_model', {})
        if model_results:
            logger.info("\nã€ãƒ¢ãƒ‡ãƒ«åˆ¥ç²¾åº¦ (ä¸Šä½5ä½)ã€‘")
            sorted_models = sorted(
                model_results.items(), 
                key=lambda x: x[1].get('directional_accuracy', 0), 
                reverse=True
            )[:5]
            
            for model, metrics in sorted_models:
                logger.info(f"  {model}:")
                logger.info(f"    æ–¹å‘æ€§ç²¾åº¦: {metrics.get('directional_accuracy', 0):.1%}")
                logger.info(f"    MAE: {metrics.get('mae', 0):.2f}")
                logger.info(f"    ã‚µãƒ³ãƒ—ãƒ«æ•°: {metrics.get('sample_count', 0)}")
        
        # ä¿¡é ¼åº¦åˆ¥ç²¾åº¦
        confidence_results = results.get('by_confidence', {})
        if confidence_results:
            logger.info("\nã€ä¿¡é ¼åº¦åˆ¥ç²¾åº¦ã€‘")
            for range_name, metrics in confidence_results.items():
                logger.info(f"  {range_name}ä¿¡é ¼åº¦:")
                logger.info(f"    æ–¹å‘æ€§ç²¾åº¦: {metrics.get('directional_accuracy', 0):.1%}")
                logger.info(f"    MAE: {metrics.get('mae', 0):.2f}")
                logger.info(f"    ã‚µãƒ³ãƒ—ãƒ«æ•°: {metrics.get('sample_count', 0)}")
        
        logger.info("=" * 80)

def main():
    system = AdvancedPredictionAccuracySystem()
    system.generate_comprehensive_accuracy_report()

if __name__ == "__main__":
    main()