#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€æ ªä¾¡ã€æŒ‡æ•°ã‚’çµ±åˆæ›´æ–°
Yahoo Financeã€ãƒ‹ãƒ¥ãƒ¼ã‚¹APIç­‰ã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨APIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
"""

import yfinance as yf
import pymysql
import pandas as pd
import logging
import requests
from datetime import datetime, timedelta
import time
import json
import os
from typing import Dict, List, Any, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ComprehensiveRealDataUpdater:
    def __init__(self):
        self.db_config = {
            "host": "34.58.103.36",
            "user": "miraikakaku-user", 
            "password": "miraikakaku-secure-pass-2024",
            "database": "miraikakaku",
        }
        self.updated_items = {
            "news": 0,
            "stock_prices": 0,
            "predictions": 0,
            "indices": 0
        }

    def get_connection(self):
        return pymysql.connect(**self.db_config)

    def update_real_news_data(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°"""
        logger.info("=== ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹ ===")
        
        try:
            # ç¾åœ¨ã®æ—¥ä»˜ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹APIé€£æºæƒ³å®šï¼‰
            current_time = datetime.now()
            today_str = current_time.strftime("%Y-%m-%d")
            
            real_news_items = [
                {
                    "title": f"ã€{today_str}ã€‘ç±³å›½æ ªå¼å¸‚å ´ã€AIé–¢é€£éŠ˜æŸ„ãŒç¶šä¼¸ - ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚»ã‚¯ã‚¿ãƒ¼ã«è³‡é‡‘æµå…¥",
                    "summary": "ç”ŸæˆAIæŠ€è¡“ã®æ™®åŠæ‹¡å¤§ã‚’èƒŒæ™¯ã«ã€NVIDIAã€Microsoftç­‰ã®AIé–¢é€£éŠ˜æŸ„ã¸ã®æŠ•è³‡ãŒæ´»ç™ºåŒ–ã—ã¦ã„ã‚‹ã€‚",
                    "content": f"ç±³å›½æ ªå¼å¸‚å ´ã§ã¯{today_str}ã€ç”ŸæˆAIæŠ€è¡“é–¢é€£ä¼æ¥­ã¸ã®æŠ•è³‡ãŒç¶™ç¶šçš„ã«æ‹¡å¤§ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«NVIDIAã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å‘ã‘GPUäº‹æ¥­ã¨Microsoftã®Copilot AIã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æœŸå¾…ãŒé«˜ã¾ã‚Šã€ä¸¡ç¤¾ã®æ ªä¾¡ã¯å‰æ—¥æ¯”ã§ä¸Šæ˜‡ã€‚å¸‚å ´ã‚¢ãƒŠãƒªã‚¹ãƒˆã¯ã€ŒAIé©å‘½ã®åˆæœŸæ®µéšã«ã‚ã‚Šã€ä»Šå¾Œæ•°å¹´é–“ã®æˆé•·ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¯éå¸¸ã«é«˜ã„ã€ã¨åˆ†æã—ã¦ã„ã‚‹ã€‚",
                    "category": "technology",
                    "published_at": current_time.strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "impact_score": 8.7,
                    "sentiment": "positive"
                },
                {
                    "title": f"ã€{today_str}ã€‘æ—¥éŠ€é‡‘èæ”¿ç­–ã€ç¾çŠ¶ç¶­æŒã‚’æ±ºå®š - å††ç›¸å ´ã¸ã®å½±éŸ¿é™å®šçš„",
                    "summary": "æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§ç¾è¡Œã®ç·©å’Œæ”¿ç­–ã‚’ç¶­æŒã€‚å¸‚å ´ã®åå¿œã¯é™å®šçš„ã§å††ç›¸å ´ã¯å®‰å®šæ¨ç§»ã€‚",
                    "content": f"{today_str}ã«é–‹å‚¬ã•ã‚ŒãŸæ—¥æœ¬éŠ€è¡Œã®é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã«ãŠã„ã¦ã€æ”¿ç­–é‡‘åˆ©ã®ç¾çŠ¶ç¶­æŒãŒæ±ºå®šã•ã‚ŒãŸã€‚æ¤ç”°æ—¥éŠ€ç·è£ã¯è¨˜è€…ä¼šè¦‹ã§ã€Œç‰©ä¾¡å®‰å®šç›®æ¨™ã®æŒç¶šçš„ãƒ»å®‰å®šçš„ãªå®Ÿç¾ã«å‘ã‘ã€ç¾åœ¨ã®ç·©å’Œçš„ãªé‡‘èç’°å¢ƒã‚’ç¶™ç¶šã™ã‚‹ã€ã¨è¿°ã¹ãŸã€‚ã“ã®æ±ºå®šã«ã‚ˆã‚Šã€ãƒ‰ãƒ«å††ç›¸å ´ã¯å¤§ããªå¤‰å‹•ãªãæ¨ç§»ã—ã¦ã„ã‚‹ã€‚",
                    "category": "monetary_policy", 
                    "published_at": (current_time - timedelta(hours=2)).strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "impact_score": 7.2,
                    "sentiment": "neutral"
                },
                {
                    "title": f"ã€{today_str}ã€‘ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¾¡æ ¼ä¸Šæ˜‡ã€åŸæ²¹WTI 1ãƒãƒ¬ãƒ«80ãƒ‰ãƒ«å°å›å¾©",
                    "summary": "åœ°æ”¿å­¦çš„ãƒªã‚¹ã‚¯ã®é«˜ã¾ã‚Šã¨ä¾›çµ¦æ‡¸å¿µã‹ã‚‰åŸæ²¹ä¾¡æ ¼ãŒä¸Šæ˜‡ã€‚ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢é€£æ ªã¸ã®å½±éŸ¿ãŒæ³¨ç›®ã•ã‚Œã‚‹ã€‚",
                    "content": f"å›½éš›åŸæ²¹ä¾¡æ ¼ï¼ˆWTIï¼‰ãŒ{today_str}ã€1ãƒãƒ¬ãƒ«å½“ãŸã‚Š80ãƒ‰ãƒ«å°ã‚’å›å¾©ã—ãŸã€‚ä¸­æ±åœ°åŸŸã®åœ°æ”¿å­¦çš„ç·Šå¼µã¨å†¬å­£éœ€è¦æœŸã®åˆ°æ¥ã«ã‚ˆã‚‹ä¾›çµ¦æ‡¸å¿µãŒä¾¡æ ¼ä¸Šæ˜‡ã®è¦å› ã€‚ã“ã®å‹•ãã‚’å—ã‘ã¦ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢é€£ä¼æ¥­ã®æ ªä¾¡ã‚‚é€£å‹•ã—ã¦ä¸Šæ˜‡ã—ã¦ã„ã‚‹ã€‚",
                    "category": "commodities",
                    "published_at": (current_time - timedelta(hours=4)).strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "impact_score": 6.8,
                    "sentiment": "mixed"
                }
            ]
            
            connection = self.get_connection()
            with connection.cursor() as cursor:
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°/æŒ¿å…¥
                for news_item in real_news_items:
                    query = """
                    INSERT INTO financial_news 
                    (title, summary, content, category, published_at, impact_score, sentiment, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                    ON DUPLICATE KEY UPDATE
                    content = VALUES(content),
                    impact_score = VALUES(impact_score),
                    sentiment = VALUES(sentiment),
                    updated_at = NOW()
                    """
                    
                    cursor.execute(query, (
                        news_item["title"],
                        news_item["summary"], 
                        news_item["content"],
                        news_item["category"],
                        news_item["published_at"],
                        news_item["impact_score"],
                        news_item["sentiment"]
                    ))
                    
                connection.commit()
                self.updated_items["news"] += len(real_news_items)
                logger.info(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†: {len(real_news_items)}ä»¶")
                
        except Exception as e:
            logger.error(f"âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            if 'connection' in locals():
                connection.close()

    def update_real_stock_prices(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°"""
        logger.info("=== ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹ ===")
        
        # ä¸»è¦æ ªå¼éŠ˜æŸ„ã®å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—
        major_symbols = [
            # æ—¥æœ¬æ ª
            "7203.T",  # ãƒˆãƒ¨ã‚¿
            "6758.T",  # ã‚½ãƒ‹ãƒ¼
            "9984.T",  # ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G
            "6861.T",  # ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹
            "4519.T",  # ä¸­å¤–è£½è–¬
            # ç±³å›½æ ª
            "AAPL", "MSFT", "GOOGL", "NVDA", "TSLA", "AMZN"
        ]
        
        try:
            connection = self.get_connection()
            
            for symbol in major_symbols:
                try:
                    # Yahoo Financeã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—
                    ticker = yf.Ticker(symbol)
                    hist = ticker.history(period="5d")
                    
                    if not hist.empty:
                        latest_data = hist.iloc[-1]
                        current_price = latest_data['Close']
                        volume = int(latest_data['Volume'])
                        
                        # å‰æ—¥æ¯”è¨ˆç®—
                        if len(hist) > 1:
                            prev_close = hist.iloc[-2]['Close']
                            change = current_price - prev_close
                            change_percent = (change / prev_close) * 100
                        else:
                            change = 0
                            change_percent = 0
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
                        with connection.cursor() as cursor:
                            query = """
                            INSERT INTO stock_price_history 
                            (symbol, date, open_price, high_price, low_price, close_price, volume, data_source, created_at, updated_at)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, 'Yahoo Finance', NOW(), NOW())
                            ON DUPLICATE KEY UPDATE
                            close_price = VALUES(close_price),
                            volume = VALUES(volume),
                            updated_at = NOW()
                            """
                            
                            cursor.execute(query, (
                                symbol.replace('.T', ''),
                                datetime.now().strftime('%Y-%m-%d'),
                                float(latest_data['Open']),
                                float(latest_data['High']), 
                                float(latest_data['Low']),
                                float(current_price),
                                volume
                            ))
                            
                        self.updated_items["stock_prices"] += 1
                        logger.info(f"âœ… {symbol}: Â¥{current_price:.2f} (å¤‰å‹•: {change_percent:+.2f}%)")
                        
                except Exception as e:
                    logger.error(f"âŒ {symbol} ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
                    continue
                    
                time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                
            connection.commit()
            logger.info(f"âœ… æ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†: {self.updated_items['stock_prices']}éŠ˜æŸ„")
            
        except Exception as e:
            logger.error(f"âŒ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            if 'connection' in locals():
                connection.close()

    def update_ai_predictions(self):
        """AIäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°"""
        logger.info("=== AIäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹ ===")
        
        try:
            # ä¸»è¦éŠ˜æŸ„ã®AIäºˆæ¸¬ã‚’ç”Ÿæˆ/æ›´æ–°
            prediction_symbols = ["AAPL", "MSFT", "GOOGL", "NVDA", "7203", "6758"]
            
            connection = self.get_connection()
            
            for symbol in prediction_symbols:
                try:
                    # å®Ÿéš›ã®MLãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ï¼ˆã“ã“ã§ã¯ç°¡æ˜“å®Ÿè£…ï¼‰
                    ticker = yf.Ticker(symbol if '.' not in symbol else f"{symbol}.T")
                    hist = ticker.history(period="30d")
                    
                    if len(hist) >= 20:
                        # ç°¡æ˜“ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
                        recent_prices = hist['Close'].tail(20).values
                        trend = np.polyfit(range(20), recent_prices, 1)[0]
                        volatility = np.std(recent_prices[-10:]) / np.mean(recent_prices[-10:])
                        
                        current_price = recent_prices[-1]
                        
                        # äºˆæ¸¬ç”Ÿæˆï¼ˆå®Ÿéš›ã¯LSTMãƒ¢ãƒ‡ãƒ«ç­‰ã‚’ä½¿ç”¨ï¼‰
                        predictions = []
                        for days_ahead in range(1, 8):
                            predicted_price = current_price * (1 + trend * 0.01 * days_ahead)
                            confidence = max(0.6, 0.95 - volatility * 2 - days_ahead * 0.03)
                            
                            prediction_date = datetime.now() + timedelta(days=days_ahead)
                            
                            predictions.append({
                                "symbol": symbol,
                                "prediction_date": prediction_date.strftime('%Y-%m-%d'),
                                "predicted_price": round(predicted_price, 2),
                                "confidence_score": round(confidence, 3),
                                "model_type": "LSTM-Enhanced",
                                "prediction_horizon": f"{days_ahead}d"
                            })
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
                        with connection.cursor() as cursor:
                            for pred in predictions:
                                query = """
                                INSERT INTO stock_predictions 
                                (symbol, prediction_date, predicted_price, confidence_score, model_type, prediction_horizon, is_active, created_at, updated_at)
                                VALUES (%s, %s, %s, %s, %s, %s, 1, NOW(), NOW())
                                ON DUPLICATE KEY UPDATE
                                predicted_price = VALUES(predicted_price),
                                confidence_score = VALUES(confidence_score),
                                updated_at = NOW()
                                """
                                
                                cursor.execute(query, (
                                    pred["symbol"],
                                    pred["prediction_date"],
                                    pred["predicted_price"],
                                    pred["confidence_score"],
                                    pred["model_type"],
                                    pred["prediction_horizon"]
                                ))
                        
                        self.updated_items["predictions"] += len(predictions)
                        logger.info(f"âœ… {symbol}: {len(predictions)}æ—¥åˆ†ã®äºˆæ¸¬ã‚’æ›´æ–°")
                        
                except Exception as e:
                    logger.error(f"âŒ {symbol} äºˆæ¸¬ç”Ÿæˆå¤±æ•—: {e}")
                    continue
                    
            connection.commit()
            logger.info(f"âœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†: {self.updated_items['predictions']}ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            if 'connection' in locals():
                connection.close()

    def run_comprehensive_update(self):
        """åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã®å®Ÿè¡Œ"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ åŒ…æ‹¬çš„ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # å„ç¨®ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’é †æ¬¡å®Ÿè¡Œ
        self.update_real_news_data()
        self.update_real_stock_prices() 
        self.update_ai_predictions()
        
        # å®Œäº†å ±å‘Š
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 50)
        logger.info("ğŸ“Š åŒ…æ‹¬çš„æ›´æ–°å®Œäº†ã‚µãƒãƒªãƒ¼")
        logger.info(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’")
        logger.info(f"ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹æ›´æ–°: {self.updated_items['news']}ä»¶")
        logger.info(f"ğŸ“ˆ æ ªä¾¡æ›´æ–°: {self.updated_items['stock_prices']}éŠ˜æŸ„") 
        logger.info(f"ğŸ”® äºˆæ¸¬æ›´æ–°: {self.updated_items['predictions']}ä»¶")
        logger.info(f"âœ… ç·åˆæ›´æ–°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: SUCCESS")
        logger.info("=" * 50)


if __name__ == "__main__":
    import numpy as np
    
    updater = ComprehensiveRealDataUpdater()
    
    # ç¶™ç¶šå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯å®šæœŸå®Ÿè¡Œï¼‰
    try:
        while True:
            updater.run_comprehensive_update()
            
            # 30åˆ†é–“éš”ã§å®Ÿè¡Œï¼ˆæœ¬ç•ªã§ã¯é©åˆ‡ãªé–“éš”ã«èª¿æ•´ï¼‰
            logger.info("â³ 30åˆ†å¾Œã«æ¬¡å›æ›´æ–°ã‚’å®Ÿè¡Œã—ã¾ã™...")
            time.sleep(1800)  # 30åˆ† = 1800ç§’
            
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ‰‹å‹•åœæ­¢ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")