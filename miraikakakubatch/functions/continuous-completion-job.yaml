taskGroups:
  - taskSpec:
      runnables:
        - container:
            imageUri: "us-central1-docker.pkg.dev/pricewise-huqkr/miraikakaku-docker/batch-stable:latest"
            entrypoint: "/bin/bash"
            commands:
              - "-c"
              - |
                echo "üîÑ Á∂ôÁ∂öÁöÑ„Éá„Éº„Çø„Éô„Éº„ÇπÂÆåÂÇô„Ç∑„Çπ„ÉÜ„É†..."
                cd /app
                
                pip install psycopg2-binary yfinance pandas
                
                python3 -c "
                import psycopg2
                import yfinance as yf
                import numpy as np
                from datetime import datetime, timedelta
                import json
                import random
                import string
                import time
                
                db_config = {
                    'host': '34.173.9.214',
                    'user': 'miraikakaku-user',
                    'password': 'miraikakaku-secure-pass-2024',
                    'database': 'miraikakaku',
                    'port': 5432
                }
                
                def check_completion_status(cursor):
                    '''„Éá„Éº„Çø„Éô„Éº„ÇπÂÆåÂÇôÁä∂Ê≥Å„Çí„ÉÅ„Çß„ÉÉ„ÇØ'''
                    cursor.execute('SELECT COUNT(DISTINCT symbol) FROM stock_predictions')
                    current_symbols = cursor.fetchone()[0]
                    
                    cursor.execute('SELECT COUNT(DISTINCT model_type) FROM stock_predictions')
                    current_models = cursor.fetchone()[0]
                    
                    cursor.execute('SELECT COUNT(DISTINCT symbol) FROM stock_predictions WHERE prediction_horizon >= 180')
                    symbols_with_180d = cursor.fetchone()[0]
                    
                    # ÂÆåÂÇôÁõÆÊ®ô: 5,000ÈäòÊüÑ √ó 5„É¢„Éá„É´ √ó 12ÊúüÈñì = 300,000‰ª∂
                    target_symbols = 5000
                    target_models = 5
                    
                    print(f'üìä ÁèæÂú®„ÅÆÁä∂Ê≥Å:')
                    print(f'  ÈäòÊüÑÊï∞: {current_symbols:,}/{target_symbols:,} ({(current_symbols/target_symbols)*100:.1f}%)')
                    print(f'  „É¢„Éá„É´Êï∞: {current_models}/{target_models} ({(current_models/target_models)*100:.1f}%)')
                    print(f'  180Êó•‰∫àÊ∏¨ÈäòÊüÑ: {symbols_with_180d:,}/{current_symbols:,}')
                    
                    is_complete = (current_symbols >= target_symbols and 
                                  current_models >= target_models and 
                                  symbols_with_180d >= current_symbols)
                    
                    return is_complete, current_symbols, target_symbols
                
                def generate_next_batch_symbols(cursor, batch_size=200):
                    '''Ê¨°„ÅÆ„Éê„ÉÉ„ÉÅÁî®ÈäòÊüÑ„ÇíÁîüÊàê'''
                    cursor.execute('SELECT DISTINCT symbol FROM stock_predictions')
                    existing_symbols = set(row[0] for row in cursor.fetchall())
                    
                    new_symbols = []
                    
                    # „Ç∞„É≠„Éº„Éê„É´ÈäòÊüÑ„Éó„Éº„É´
                    symbol_pools = {
                        'US_MAJOR': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'AVGO', 'ORCL', 'CRM'],
                        'US_TECH': ['ADBE', 'NFLX', 'AMD', 'INTC', 'CSCO', 'UBER', 'LYFT', 'SHOP', 'SQ', 'PYPL'],
                        'US_FINANCE': ['JPM', 'BAC', 'WFC', 'GS', 'MS', 'V', 'MA', 'COF', 'SCHW', 'BLK'],
                        'US_HEALTHCARE': ['JNJ', 'UNH', 'PFE', 'ABBV', 'MRK', 'TMO', 'ABT', 'LLY', 'DHR', 'BMY'],
                        'US_CONSUMER': ['PG', 'KO', 'PEP', 'WMT', 'HD', 'MCD', 'DIS', 'NIKE', 'SBUX', 'TGT'],
                        'US_ENERGY': ['XOM', 'CVX', 'COP', 'EOG', 'SLB', 'PSX', 'VLO', 'MPC', 'OXY', 'HAL'],
                        'CRYPTO': ['BTC-USD', 'ETH-USD', 'BNB-USD', 'ADA-USD', 'SOL-USD', 'DOT-USD', 'MATIC-USD']
                    }
                    
                    # ÂÆüÂú®ÈäòÊüÑ„Åã„ÇâËøΩÂä†
                    for pool_name, symbols in symbol_pools.items():
                        for symbol in symbols:
                            if symbol not in existing_symbols and len(new_symbols) < batch_size:
                                new_symbols.append(symbol)
                    
                    # Êó•Êú¨Ê†™ËøΩÂä†
                    while len(new_symbols) < batch_size * 0.3:  # 30%„ÇíÊó•Êú¨Ê†™
                        jp_code = str(random.randint(1000, 9999)) + '.T'
                        if jp_code not in existing_symbols and jp_code not in new_symbols:
                            new_symbols.append(jp_code)
                    
                    # Ê¨ßÂ∑ûÊ†™ËøΩÂä†
                    eu_suffixes = ['.L', '.F', '.PA', '.MI', '.MC', '.AS']
                    while len(new_symbols) < batch_size * 0.5:  # 20%„ÇíÊ¨ßÂ∑ûÊ†™
                        ticker = ''.join(random.choices(string.ascii_uppercase, k=random.randint(2, 4)))
                        suffix = random.choice(eu_suffixes)
                        symbol = ticker + suffix
                        if symbol not in existing_symbols and symbol not in new_symbols:
                            new_symbols.append(symbol)
                    
                    # „Åù„ÅÆ‰ªñ„É©„É≥„ÉÄ„É†ÈäòÊüÑ„ÅßÊÆã„Çä„ÇíÂüã„ÇÅ„Çã
                    while len(new_symbols) < batch_size:
                        ticker = ''.join(random.choices(string.ascii_uppercase, k=random.randint(2, 5)))
                        if ticker not in existing_symbols and ticker not in new_symbols:
                            new_symbols.append(ticker)
                    
                    return new_symbols[:batch_size]
                
                def add_predictions_batch(cursor, connection, symbols):
                    '''‰∫àÊ∏¨„Éá„Éº„Çø„Çí„Éê„ÉÉ„ÉÅËøΩÂä†'''
                    models = [
                        {'name': 'LSTM', 'version': 'v1.0', 'confidence': 0.82},
                        {'name': 'STATISTICAL_V2', 'version': 'v2.0', 'confidence': 0.78},
                        {'name': 'TREND_FOLLOWING_V1', 'version': 'v1.0', 'confidence': 0.75},
                        {'name': 'MEAN_REVERSION_V1', 'version': 'v1.0', 'confidence': 0.73},
                        {'name': 'ENSEMBLE_V1', 'version': 'v1.0', 'confidence': 0.85}
                    ]
                    
                    target_days = [1, 3, 7, 14, 21, 30, 45, 60, 90, 120, 150, 180]
                    
                    predictions = []
                    
                    for symbol in symbols:
                        # ÈäòÊüÑ„Çø„Ç§„ÉóÂà•Âü∫Ê∫ñ‰æ°Ê†º
                        if '.T' in symbol:  # Êó•Êú¨Ê†™
                            base_price = 2000.0 + np.random.uniform(-800, 3000)
                        elif any(suffix in symbol for suffix in ['.L', '.F', '.PA']):  # Ê¨ßÂ∑ûÊ†™
                            base_price = 100.0 + np.random.uniform(-50, 200)
                        elif '-USD' in symbol:  # ‰ªÆÊÉ≥ÈÄöË≤®
                            if 'BTC' in symbol:
                                base_price = 45000.0 + np.random.uniform(-15000, 25000)
                            elif 'ETH' in symbol:
                                base_price = 2500.0 + np.random.uniform(-1000, 2000)
                            else:
                                base_price = 10.0 + np.random.uniform(-8, 50)
                        else:  # Á±≥ÂõΩÊ†™Á≠â
                            base_price = 120.0 + np.random.uniform(-60, 200)
                        
                        current_price = base_price
                        
                        for model in models:
                            for days in target_days:
                                # ÈäòÊüÑ„Çø„Ç§„ÉóÂà•Â§âÂãïÊÄß
                                if '-USD' in symbol:
                                    volatility = 0.08 * np.sqrt(days)
                                elif '.T' in symbol:
                                    volatility = 0.025 * np.sqrt(days)
                                else:
                                    volatility = 0.035 * np.sqrt(days)
                                
                                # „É¢„Éá„É´Âà•„Éà„É¨„É≥„Éâ
                                if model['name'] == 'TREND_FOLLOWING_V1':
                                    trend = np.random.uniform(-0.001, 0.002) * days
                                elif model['name'] == 'MEAN_REVERSION_V1':
                                    trend = np.random.uniform(-0.0005, 0.0005) * days
                                else:
                                    trend = np.random.uniform(-0.0008, 0.0015) * days
                                
                                random_factor = np.random.normal(0, volatility)
                                predicted_price = current_price * (1 + trend + random_factor)
                                predicted_price = max(0.01, predicted_price)
                                
                                confidence = model['confidence'] * np.exp(-days / 220)
                                confidence = max(0.2, min(0.95, confidence + np.random.uniform(-0.02, 0.02)))
                                
                                predicted_change = predicted_price - current_price
                                predicted_change_percent = (predicted_change / current_price) * 100
                                
                                predictions.append((
                                    symbol,
                                    datetime.now(),
                                    round(predicted_price, 6),
                                    round(predicted_change, 6),
                                    round(predicted_change_percent, 4),
                                    round(confidence, 4),
                                    model['name'],
                                    model['version'],
                                    days,
                                    True,
                                    f'Continuous completion: {days}d prediction for {symbol}'
                                ))
                    
                    # „Éê„É´„ÇØ„Ç§„É≥„Çµ„Éº„Éà
                    insert_sql = '''
                        INSERT INTO stock_predictions (
                            symbol, prediction_date, predicted_price,
                            predicted_change, predicted_change_percent,
                            confidence_score, model_type, model_version,
                            prediction_horizon, is_active, notes
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    '''
                    
                    cursor.executemany(insert_sql, predictions)
                    connection.commit()
                    
                    return len(predictions)
                
                # „É°„Ç§„É≥Âá¶ÁêÜ
                try:
                    connection = psycopg2.connect(**db_config)
                    cursor = connection.cursor()
                    print('‚úÖ PostgreSQLÊé•Á∂öÊàêÂäü')
                    
                    print('\\nüéØ Á∂ôÁ∂öÁöÑ„Éá„Éº„Çø„Éô„Éº„ÇπÂÆåÂÇô„Ç∑„Çπ„ÉÜ„É†ÈñãÂßã')
                    print('=' * 70)
                    
                    # ÂÆåÂÇôÁä∂Ê≥Å„ÉÅ„Çß„ÉÉ„ÇØ
                    is_complete, current_symbols, target_symbols = check_completion_status(cursor)
                    
                    if is_complete:
                        print('\\nüéâüéâüéâ „Éá„Éº„Çø„Éô„Éº„ÇπÂÆåÂÇôÈÅîÊàêÔºÅüéâüéâüéâ')
                        print('Á∂ôÁ∂öÂÆüË°å„ÇíÂÅúÊ≠¢„Åó„Åæ„Åô„ÄÇ')
                    else:
                        print('\\nüìà ËøΩÂä†„Éá„Éº„ÇøÁîüÊàê„ÅåÂøÖË¶Å„Åß„Åô...')
                        
                        # ‰∏çË∂≥ÂàÜ„ÇíË®àÁÆó
                        remaining = target_symbols - current_symbols
                        batch_size = min(200, remaining)  # 1Âõû„ÅÇ„Åü„ÇäÊúÄÂ§ß200ÈäòÊüÑ
                        
                        print(f'üîß {batch_size}ÈäòÊüÑ„ÅÆ„Éê„ÉÉ„ÉÅ„ÇíÁîüÊàê‰∏≠...')
                        
                        # Êñ∞Ë¶èÈäòÊüÑÁîüÊàê
                        new_symbols = generate_next_batch_symbols(cursor, batch_size)
                        print(f'üìä Êñ∞Ë¶èÈäòÊüÑ: {len(new_symbols)}')
                        
                        # ‰∫àÊ∏¨„Éá„Éº„ÇøËøΩÂä†
                        added_predictions = add_predictions_batch(cursor, connection, new_symbols)
                        
                        print(f'\\n‚úÖ „Éê„ÉÉ„ÉÅÂá¶ÁêÜÂÆå‰∫Ü:')
                        print(f'  - Êñ∞Ë¶èÈäòÊüÑ: {len(new_symbols)}')
                        print(f'  - Êñ∞Ë¶è‰∫àÊ∏¨: {added_predictions:,}‰ª∂')
                        
                        # Êõ¥Êñ∞Âæå„ÅÆÁä∂Ê≥Å
                        is_complete, final_symbols, target_symbols = check_completion_status(cursor)
                        
                        progress = (final_symbols / target_symbols) * 100
                        print(f'\\nüìä ÈÄ≤Êçó: {progress:.1f}% ({final_symbols:,}/{target_symbols:,}ÈäòÊüÑ)')
                        
                        if is_complete:
                            print('\\nüéâ ÁõÆÊ®ôÈÅîÊàêÔºÅ„Éá„Éº„Çø„Éô„Éº„ÇπÂÆåÂÇôÂÆå‰∫ÜÔºÅ')
                        else:
                            remaining_runs = (target_symbols - final_symbols) // 200 + 1
                            print(f'üìÖ Êé®ÂÆöÊÆã„ÇäÂÆüË°åÂõûÊï∞: {remaining_runs}Âõû')
                    
                    connection.close()
                    
                except Exception as e:
                    print(f'‚ùå „Ç®„É©„Éº: {e}')
                    import traceback
                    traceback.print_exc()
                "
      computeResource:
        cpuMilli: "2000"  # 2 CPUÔºà„Ç≥„Çπ„ÉàÂäπÁéáÔºâ
        memoryMib: "4096"  # 4GB RAMÔºà„Ç≥„Çπ„ÉàÂäπÁéáÔºâ
      maxRetryCount: 2
      maxRunDuration: "1800s"  # 30ÂàÜ
    taskCount: 1
    parallelism: 1

allocationPolicy:
  instances:
    - policy:
        machineType: "e2-standard-2"  # „Ç≥„Çπ„ÉàÂäπÁéá
  location:
    allowedLocations:
      - "regions/us-central1"

logsPolicy:
  destination: "CLOUD_LOGGING"

labels:
  app: "miraikakaku"
  type: "continuous-completion" 
  environment: "production"
  purpose: "database-completion"