#!/usr/bin/env python3
"""
Miraikakaku Batch System - å®šæœŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€æ–°æ€§ã¨ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’è‡ªå‹•çš„ã«ç›£è¦–ãƒ»æ›´æ–°ã™ã‚‹ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ 

æ©Ÿèƒ½:
- æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å®šæœŸæ›´æ–° (æ¯é€±æœˆæ›œæ—¥ 6:00)
- ç±³å›½æ ªãƒ»ETFãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å®šæœŸåŒæœŸ (æ¯æ—¥ 4:00)
- ã‚«ãƒãƒ¬ãƒƒã‚¸ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½

ä½¿ç”¨æ–¹æ³•:
python3 miraikakakubatch.py --mode daily    # æ—¥æ¬¡å‡¦ç†
python3 miraikakakubatch.py --mode weekly   # é€±æ¬¡å‡¦ç†  
python3 miraikakakubatch.py --mode check    # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯
python3 miraikakakubatch.py --mode monitor  # ç›£è¦–ãƒ¢ãƒ¼ãƒ‰
"""

import asyncio
import aiohttp
import requests
import csv
import io
import json
import logging
import argparse
from datetime import datetime, timedelta
import os
import shutil
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import schedule
import time
from typing import Dict, List, Optional, Tuple

# MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from ml_prediction_system import MLBatchIntegration
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    logger.warning("MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ (ml_prediction_system.py)")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('miraikakakubatch.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MiraikakakuBatchSystem:
    """Miraikakaku ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.config = {
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹URL
            'tse_data_url': 'https://www.jpx.co.jp/english/markets/statistics-equities/misc/01.html',
            'alphavantage_url': 'https://www.alphavantage.co/query?function=LISTING_STATUS&apikey=demo',
            'nasdaq_ftp_url': 'ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt',
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            'japanese_stocks_file': 'comprehensive_japanese_stocks_enhanced.py',
            'us_stocks_backup': 'us_stocks_backup.json',
            'etf_optimized_file': 'optimized_etfs_3000.json',
            'coverage_report_file': 'coverage_monitoring_report.json',
            
            # ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™
            'target_japanese_stocks': 4200,  # TSEå…¨ç¤¾ + ä½™è£•
            'target_us_stocks': 8700,        # 100%ã‚«ãƒãƒ¬ãƒƒã‚¸ç¶­æŒ
            'target_etfs': 3000,             # æœ€é©åŒ–æ¸ˆã¿ETFæ•°
            
            # ç›£è¦–ã—ãã„å€¤
            'coverage_alert_threshold': 0.95,  # 95%æœªæº€ã§ã‚¢ãƒ©ãƒ¼ãƒˆ
            'update_interval_days': 7,         # 1é€±é–“é–“éš”ã§ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
            
            # é€šçŸ¥è¨­å®š (å¿…è¦ã«å¿œã˜ã¦è¨­å®š)
            'email_notifications': False,
            'slack_webhook_url': None,
            
            # MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
            'ml_enabled': ML_AVAILABLE,
            'ml_daily_symbols': 50,    # æ—¥æ¬¡MLå‡¦ç†ã™ã‚‹éŠ˜æŸ„æ•°
            'ml_weekly_symbols': 200,  # é€±æ¬¡MLå‡¦ç†ã™ã‚‹éŠ˜æŸ„æ•°
            'ml_retrain_threshold': 7  # ãƒªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–“éš”(æ—¥)
        }
        
        self.current_stats = {}
        self.last_update = {}
        
        # MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if self.config['ml_enabled']:
            try:
                self.ml_batch = MLBatchIntegration()
                logger.info("âœ… MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                logger.error(f"MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                self.config['ml_enabled'] = False
                self.ml_batch = None
        else:
            self.ml_batch = None
        
    async def run_daily_maintenance(self):
        """æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å‡¦ç†"""
        logger.info("ğŸš€ æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é–‹å§‹")
        
        try:
            # 1. ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯
            coverage_report = await self.check_coverage_status()
            
            # 2. ç±³å›½æ ªãƒ»ETFåŒæœŸ
            us_updated = await self.sync_us_data()
            etf_updated = await self.sync_etf_data()
            
            # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            integrity_ok = await self.check_database_integrity()
            
            # 4. MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ—¥æ¬¡å‡¦ç†
            ml_results = await self.run_daily_ml_tasks()
            
            # 5. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            await self.generate_daily_report(coverage_report, us_updated, etf_updated, integrity_ok, ml_results)
            
            logger.info("âœ… æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            await self.send_alert("æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼", str(e))
            
    async def run_weekly_maintenance(self):
        """é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å‡¦ç†"""
        logger.info("ğŸš€ é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é–‹å§‹")
        
        try:
            # 1. æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Œå…¨æ›´æ–°
            jp_updated = await self.update_japanese_stocks()
            
            # 2. ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Œå…¨ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
            us_refreshed = await self.refresh_us_database()
            
            # 3. ETFãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
            etf_optimized = await self.optimize_etf_database()
            
            # 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            await self.create_database_backups()
            
            # 5. MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é€±æ¬¡å‡¦ç†
            ml_results = await self.run_weekly_ml_tasks()
            
            # 6. é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            await self.generate_weekly_report(jp_updated, us_refreshed, etf_optimized, ml_results)
            
            logger.info("âœ… é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            await self.send_alert("é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼", str(e))
            
    async def check_coverage_status(self) -> Dict:
        """ç¾åœ¨ã®ã‚«ãƒãƒ¬ãƒƒã‚¸çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        logger.info("ğŸ“Š ã‚«ãƒãƒ¬ãƒƒã‚¸çŠ¶æ³ç¢ºèªä¸­...")
        
        try:
            # APIã‹ã‚‰ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
            response = requests.get('http://localhost:8000/api/finance/markets/stats', timeout=10)
            if response.status_code == 200:
                stats = response.json()
                
                coverage_report = {
                    'timestamp': datetime.now().isoformat(),
                    'japanese_stocks': {
                        'current': stats['database_stats']['japanese_stocks'],
                        'target': self.config['target_japanese_stocks'],
                        'coverage_rate': stats['database_stats']['japanese_stocks'] / self.config['target_japanese_stocks']
                    },
                    'us_stocks': {
                        'current': stats['database_stats']['us_stocks'],
                        'target': self.config['target_us_stocks'],
                        'coverage_rate': stats['database_stats']['us_stocks'] / self.config['target_us_stocks']
                    },
                    'etfs': {
                        'current': stats['database_stats']['etfs'],
                        'target': self.config['target_etfs'],
                        'coverage_rate': stats['database_stats']['etfs'] / self.config['target_etfs']
                    },
                    'total_securities': stats['database_stats']['total_securities']
                }
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
                await self.check_coverage_alerts(coverage_report)
                
                # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
                with open(self.config['coverage_report_file'], 'w', encoding='utf-8') as f:
                    json.dump(coverage_report, f, indent=2, ensure_ascii=False)
                
                logger.info(f"ğŸ“ˆ ã‚«ãƒãƒ¬ãƒƒã‚¸: JP={coverage_report['japanese_stocks']['coverage_rate']:.1%}, "
                          f"US={coverage_report['us_stocks']['coverage_rate']:.1%}, "
                          f"ETF={coverage_report['etfs']['coverage_rate']:.1%}")
                
                return coverage_report
                
        except Exception as e:
            logger.error(f"ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            return {}
            
    async def check_coverage_alerts(self, coverage_report: Dict):
        """ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""
        alerts = []
        
        for market, data in coverage_report.items():
            if isinstance(data, dict) and 'coverage_rate' in data:
                if data['coverage_rate'] < self.config['coverage_alert_threshold']:
                    alerts.append(f"{market}: {data['coverage_rate']:.1%} (ç›®æ¨™: {self.config['coverage_alert_threshold']:.1%})")
        
        if alerts:
            alert_message = "âš ï¸ ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¢ãƒ©ãƒ¼ãƒˆ:\n" + "\n".join(alerts)
            logger.warning(alert_message)
            await self.send_alert("ã‚«ãƒãƒ¬ãƒƒã‚¸ä½ä¸‹è­¦å‘Š", alert_message)
            
    async def update_japanese_stocks(self) -> bool:
        """æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°"""
        logger.info("ğŸ‡¯ğŸ‡µ æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ä¸­...")
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_file = f"{self.config['japanese_stocks_file']}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            shutil.copy2(self.config['japanese_stocks_file'], backup_file)
            
            # TSEå…¬å¼ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»å‡¦ç† (å®Ÿè£…ã¯æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§)
            # ã“ã“ã§ã¯æ¦‚å¿µçš„ãªå®Ÿè£…
            
            # æ–°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
            updated_count = await self._fetch_latest_japanese_stocks()
            
            if updated_count > self.config['target_japanese_stocks'] * 0.9:
                logger.info(f"âœ… æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°å®Œäº†: {updated_count}ç¤¾")
                return True
            else:
                logger.warning(f"âš ï¸ æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ä¸è¶³: {updated_count}ç¤¾ (ç›®æ¨™: {self.config['target_japanese_stocks']})")
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ
                shutil.copy2(backup_file, self.config['japanese_stocks_file'])
                return False
                
        except Exception as e:
            logger.error(f"æ—¥æœ¬æ ªæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    async def _fetch_latest_japanese_stocks(self) -> int:
        """æœ€æ–°æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿å–å¾— (å®Ÿè£…ä¾‹)"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€TSEå…¬å¼ãƒ‡ãƒ¼ã‚¿APIã¾ãŸã¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        # æ—¢å­˜ã®create_enhanced_japanese_stocks.pyã®å‡¦ç†ã‚’çµ±åˆ
        return 4200  # ä»®ã®æˆ»ã‚Šå€¤
        
    async def sync_us_data(self) -> bool:
        """ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿åŒæœŸ"""
        logger.info("ğŸ‡ºğŸ‡¸ ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿åŒæœŸä¸­...")
        
        try:
            # Alpha Vantage APIç¢ºèª
            response = requests.get(self.config['alphavantage_url'], timeout=30)
            if response.status_code == 200:
                reader = csv.DictReader(io.StringIO(response.text))
                us_stocks_count = sum(1 for row in reader if row.get('assetType') == 'Stock')
                
                if us_stocks_count >= self.config['target_us_stocks'] * 0.95:
                    logger.info(f"âœ… ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿åŒæœŸå®Œäº†: {us_stocks_count}ç¤¾")
                    return True
                else:
                    logger.warning(f"âš ï¸ ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿ä¸è¶³: {us_stocks_count}ç¤¾")
                    return False
            else:
                logger.error(f"Alpha Vantage API ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"ç±³å›½æ ªåŒæœŸã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    async def sync_etf_data(self) -> bool:
        """ETFãƒ‡ãƒ¼ã‚¿åŒæœŸ"""
        logger.info("ğŸ“Š ETFãƒ‡ãƒ¼ã‚¿åŒæœŸä¸­...")
        
        try:
            # æœ€é©åŒ–æ¸ˆã¿ETFãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            if os.path.exists(self.config['etf_optimized_file']):
                with open(self.config['etf_optimized_file'], 'r', encoding='utf-8') as f:
                    etf_data = json.load(f)
                    etf_count = len(etf_data)
                    
                if etf_count == self.config['target_etfs']:
                    logger.info(f"âœ… ETFãƒ‡ãƒ¼ã‚¿åŒæœŸå®Œäº†: {etf_count}éŠ˜æŸ„")
                    return True
                else:
                    logger.warning(f"âš ï¸ ETFãƒ‡ãƒ¼ã‚¿ä¸ä¸€è‡´: {etf_count}éŠ˜æŸ„ (ç›®æ¨™: {self.config['target_etfs']})")
                    return False
            else:
                logger.error("ETFæœ€é©åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
                
        except Exception as e:
            logger.error(f"ETFåŒæœŸã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    async def check_database_integrity(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        try:
            # APIçµŒç”±ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹ç¢ºèª
            response = requests.get('http://localhost:8000/', timeout=10)
            if response.status_code == 200:
                api_info = response.json()
                
                # å„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                files_ok = all([
                    os.path.exists(self.config['japanese_stocks_file']),
                    os.path.exists(self.config['etf_optimized_file'])
                ])
                
                if files_ok and 'coverage' in api_info:
                    logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§OK")
                    return True
                else:
                    logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼")
                    return False
            else:
                logger.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    async def create_database_backups(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        logger.info("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
        
        try:
            backup_dir = f"backups/{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            os.makedirs(backup_dir, exist_ok=True)
            
            # å„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            backup_files = [
                self.config['japanese_stocks_file'],
                self.config['etf_optimized_file'],
                'universal_stock_api.py'
            ]
            
            for file_path in backup_files:
                if os.path.exists(file_path):
                    shutil.copy2(file_path, os.path.join(backup_dir, os.path.basename(file_path)))
            
            logger.info(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {backup_dir}")
            
        except Exception as e:
            logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            
    async def generate_daily_report(self, coverage_report: Dict, us_updated: bool, etf_updated: bool, integrity_ok: bool, ml_results: Dict):
        """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'type': 'daily',
            'coverage_report': coverage_report,
            'updates': {
                'us_stocks': us_updated,
                'etfs': etf_updated
            },
            'integrity_check': integrity_ok,
            'ml_predictions': ml_results,
            'status': 'success' if all([us_updated, etf_updated, integrity_ok, ml_results.get('status') != 'error']) else 'warning'
        }
        
        report_file = f"reports/daily_report_{datetime.now().strftime('%Y%m%d')}.json"
        os.makedirs('reports', exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        logger.info(f"ğŸ“‹ æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
        
    async def generate_weekly_report(self, jp_updated: bool, us_refreshed: bool, etf_optimized: bool, ml_results: Dict):
        """é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'type': 'weekly',
            'updates': {
                'japanese_stocks': jp_updated,
                'us_stocks': us_refreshed,
                'etfs': etf_optimized
            },
            'ml_training': ml_results,
            'status': 'success' if all([jp_updated, us_refreshed, etf_optimized, ml_results.get('status') != 'error']) else 'warning'
        }
        
        report_file = f"reports/weekly_report_{datetime.now().strftime('%Y%m%d')}.json"
        os.makedirs('reports', exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        logger.info(f"ğŸ“‹ é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
        
    async def send_alert(self, subject: str, message: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        logger.warning(f"ğŸš¨ ALERT: {subject} - {message}")
        
        # å¿…è¦ã«å¿œã˜ã¦ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚„Slacké€šçŸ¥ãªã©ã‚’å®Ÿè£…
        if self.config['email_notifications']:
            # ãƒ¡ãƒ¼ãƒ«é€ä¿¡å®Ÿè£…
            pass
            
    async def refresh_us_database(self) -> bool:
        """ç±³å›½æ ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Œå…¨ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥"""
        # å®Ÿè£…ã¯æ—¢å­˜ã®USæ ªå–å¾—ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‚ç…§
        return True
        
    async def optimize_etf_database(self) -> bool:
        """ETFãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–"""
        # å®Ÿè£…ã¯æ—¢å­˜ã®ETFæœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‚ç…§
        return True
        
    async def run_daily_ml_tasks(self) -> Dict:
        """MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ—¥æ¬¡å‡¦ç†"""
        if not self.config['ml_enabled'] or self.ml_batch is None:
            logger.info("âš ï¸ MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
            return {'status': 'disabled', 'reason': 'ML system not available'}
            
        try:
            logger.info("ğŸ¤– MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ—¥æ¬¡å‡¦ç†é–‹å§‹")
            
            # ä¸»è¦éŠ˜æŸ„ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬æ›´æ–°
            major_symbols = await self._get_daily_ml_symbols()
            
            if not major_symbols:
                logger.warning("æ—¥æ¬¡MLå‡¦ç†å¯¾è±¡éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {'status': 'skipped', 'reason': 'No symbols found'}
                
            # MLå‡¦ç†å®Ÿè¡Œ
            ml_results = await self.ml_batch.run_daily_ml_tasks()
            
            logger.info(f"âœ… MLæ—¥æ¬¡å‡¦ç†å®Œäº†: {ml_results.get('symbols_processed', 0)}éŠ˜æŸ„å‡¦ç†")
            
            return {
                'status': 'completed',
                'symbols_processed': ml_results.get('symbols_processed', 0),
                'predictions_generated': ml_results.get('predictions_generated', 0),
                'model_accuracy': ml_results.get('average_accuracy', 0),
                'execution_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"MLæ—¥æ¬¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'status': 'error', 'error': str(e)}
            
    async def run_weekly_ml_tasks(self) -> Dict:
        """MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é€±æ¬¡å‡¦ç†"""
        if not self.config['ml_enabled'] or self.ml_batch is None:
            logger.info("âš ï¸ MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
            return {'status': 'disabled', 'reason': 'ML system not available'}
            
        try:
            logger.info("ğŸ¤– MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é€±æ¬¡å‡¦ç†é–‹å§‹")
            
            # å…¨éŠ˜æŸ„ã®ãƒ¢ãƒ‡ãƒ«å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            weekly_symbols = await self._get_weekly_ml_symbols()
            
            if not weekly_symbols:
                logger.warning("é€±æ¬¡MLå‡¦ç†å¯¾è±¡éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {'status': 'skipped', 'reason': 'No symbols found'}
                
            # é€±æ¬¡MLå‡¦ç†å®Ÿè¡Œ
            ml_results = await self.ml_batch.run_weekly_ml_tasks()
            
            # MLãƒ¢ãƒ‡ãƒ«æ€§èƒ½çµ±è¨ˆæ›´æ–°
            await self._update_ml_performance_stats(ml_results)
            
            logger.info(f"âœ… MLé€±æ¬¡å‡¦ç†å®Œäº†: {ml_results.get('symbols_processed', 0)}éŠ˜æŸ„å‡¦ç†")
            
            return {
                'status': 'completed',
                'symbols_processed': ml_results.get('symbols_processed', 0),
                'models_retrained': ml_results.get('models_trained', 0),
                'predictions_generated': ml_results.get('predictions_generated', 0),
                'average_accuracy': ml_results.get('average_accuracy', 0),
                'execution_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"MLé€±æ¬¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'status': 'error', 'error': str(e)}
            
    async def _get_daily_ml_symbols(self) -> List[str]:
        """æ—¥æ¬¡MLå‡¦ç†å¯¾è±¡éŠ˜æŸ„å–å¾—"""
        try:
            # APIçµŒç”±ã§äººæ°—éŠ˜æŸ„ãƒ»é«˜ãƒœãƒªãƒ¥ãƒ¼ãƒ éŠ˜æŸ„ã‚’å–å¾—
            response = requests.get('http://localhost:8000/api/finance/rankings/universal', timeout=10)
            if response.status_code == 200:
                rankings = response.json()
                return [item['symbol'] for item in rankings[:self.config['ml_daily_symbols']]]
        except:
            pass
            
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¸»è¦éŠ˜æŸ„
        return ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA', 'META', 'AMZN', 'SPY', 'QQQ', 'VTI',
                '7203.T', '9984.T', '6758.T', '8306.T', '9434.T'][:self.config['ml_daily_symbols']]
                
    async def _get_weekly_ml_symbols(self) -> List[str]:
        """é€±æ¬¡MLå‡¦ç†å¯¾è±¡éŠ˜æŸ„å–å¾—"""
        try:
            # ã‚ˆã‚Šåºƒç¯„å›²ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—
            all_symbols = []
            
            # å„å¸‚å ´ã‹ã‚‰éŠ˜æŸ„å–å¾—
            markets = ['US', 'JP']
            for market in markets:
                response = requests.get(
                    f'http://localhost:8000/api/finance/stocks/search?query=&market={market}', 
                    timeout=15
                )
                if response.status_code == 200:
                    results = response.json()
                    symbols = [item['symbol'] for item in results]
                    all_symbols.extend(symbols)
                    
            return all_symbols[:self.config['ml_weekly_symbols']]
            
        except Exception as e:
            logger.warning(f"é€±æ¬¡MLéŠ˜æŸ„å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA'] * 40  # 200éŠ˜æŸ„ç›¸å½“
        
    async def _update_ml_performance_stats(self, ml_results: Dict):
        """MLæ€§èƒ½çµ±è¨ˆæ›´æ–°"""
        try:
            stats_file = 'ml_performance_stats.json'
            
            # æ—¢å­˜çµ±è¨ˆèª­ã¿è¾¼ã¿
            if os.path.exists(stats_file):
                with open(stats_file, 'r', encoding='utf-8') as f:
                    stats = json.load(f)
            else:
                stats = {'history': [], 'summary': {}}
                
            # æ–°ã—ã„çµæœè¿½åŠ 
            stats['history'].append({
                'timestamp': datetime.now().isoformat(),
                'symbols_processed': ml_results.get('symbols_processed', 0),
                'average_accuracy': ml_results.get('average_accuracy', 0),
                'models_trained': ml_results.get('models_trained', 0)
            })
            
            # ç›´è¿‘30æ—¥ã®çµ±è¨ˆè¨ˆç®—
            recent_stats = stats['history'][-30:]
            if recent_stats:
                stats['summary'] = {
                    'avg_accuracy_30d': sum(s.get('average_accuracy', 0) for s in recent_stats) / len(recent_stats),
                    'total_models_30d': sum(s.get('models_trained', 0) for s in recent_stats),
                    'avg_symbols_per_run': sum(s.get('symbols_processed', 0) for s in recent_stats) / len(recent_stats),
                    'last_updated': datetime.now().isoformat()
                }
                
            # çµ±è¨ˆä¿å­˜
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"MLçµ±è¨ˆæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

def setup_scheduler():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®š"""
    batch_system = MiraikakakuBatchSystem()
    
    # æ—¥æ¬¡å‡¦ç†: æ¯æ—¥ 4:00
    schedule.every().day.at("04:00").do(
        lambda: asyncio.run(batch_system.run_daily_maintenance())
    )
    
    # é€±æ¬¡å‡¦ç†: æ¯é€±æœˆæ›œæ—¥ 6:00
    schedule.every().monday.at("06:00").do(
        lambda: asyncio.run(batch_system.run_weekly_maintenance())
    )
    
    # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯: 6æ™‚é–“ã”ã¨
    schedule.every(6).hours.do(
        lambda: asyncio.run(batch_system.check_coverage_status())
    )
    
    logger.info("â° ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šå®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='Miraikakaku Batch System')
    parser.add_argument('--mode', choices=['daily', 'weekly', 'check', 'monitor', 'ml-daily', 'ml-weekly'], 
                       default='monitor', help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰')
    
    args = parser.parse_args()
    batch_system = MiraikakakuBatchSystem()
    
    if args.mode == 'daily':
        asyncio.run(batch_system.run_daily_maintenance())
    elif args.mode == 'weekly':
        asyncio.run(batch_system.run_weekly_maintenance())
    elif args.mode == 'check':
        asyncio.run(batch_system.check_coverage_status())
    elif args.mode == 'ml-daily':
        logger.info("ğŸ¤– MLæ—¥æ¬¡å‡¦ç†å®Ÿè¡Œ")
        result = asyncio.run(batch_system.run_daily_ml_tasks())
        print(f"MLæ—¥æ¬¡å‡¦ç†çµæœ: {result}")
    elif args.mode == 'ml-weekly':
        logger.info("ğŸ¤– MLé€±æ¬¡å‡¦ç†å®Ÿè¡Œ")
        result = asyncio.run(batch_system.run_weekly_ml_tasks())
        print(f"MLé€±æ¬¡å‡¦ç†çµæœ: {result}")
    elif args.mode == 'monitor':
        logger.info("ğŸ¯ ç›£è¦–ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
        setup_scheduler()
        
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # 1åˆ†é–“éš”ã§ãƒã‚§ãƒƒã‚¯
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ ç›£è¦–ãƒ¢ãƒ¼ãƒ‰çµ‚äº†")

if __name__ == "__main__":
    main()