#!/usr/bin/env python3
"""
Continuous LSTM & VertexAI Scheduler
ç¶™ç¶šçš„LSTM & VertexAIå®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ãªå……è¶³ã‚’ç›®æŒ‡ã™
"""

import time
import threading
import subprocess
import logging
import psycopg2
from datetime import datetime, timedelta

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ContinuousLSTMScheduler:
    """ç¶™ç¶šçš„LSTM & VertexAIå®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"""

    def __init__(self, interval_hours: int = 2):
        self.interval_hours = interval_hours
        self.running = False
        self.scheduler_thread = None
        self.cycle_count = 0

    def check_data_coverage(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª"""
        try:
            conn = psycopg2.connect(
                host='34.173.9.214',
                user='postgres',
                password='os.getenv('DB_PASSWORD', '')',
                database='miraikakaku'
            )
            cursor = conn.cursor()

            # éŠ˜æŸ„æ•°ç¢ºèª
            cursor.execute('SELECT COUNT(*) FROM stock_master WHERE is_active = true')
            total_symbols = cursor.fetchone()[0]

            # æœªæ¥äºˆæ¸¬ã‚«ãƒãƒ¬ãƒƒã‚¸
            cursor.execute('''
                SELECT COUNT(DISTINCT symbol) FROM stock_predictions
                WHERE prediction_date >= CURRENT_DATE
                AND model_type LIKE '%LSTM_VERTEXAI%'
            ''')
            future_covered = cursor.fetchone()[0]

            # éå»äºˆæ¸¬ã‚«ãƒãƒ¬ãƒƒã‚¸
            cursor.execute('''
                SELECT COUNT(DISTINCT symbol) FROM stock_predictions
                WHERE actual_price IS NOT NULL
                AND model_type LIKE '%HISTORICAL%LSTM%'
            ''')
            historical_covered = cursor.fetchone()[0]

            # æœ€æ–°äºˆæ¸¬æ•°
            cursor.execute('''
                SELECT COUNT(*) FROM stock_predictions
                WHERE created_at >= NOW() - INTERVAL '2 hours'
                AND model_type LIKE '%LSTM_VERTEXAI%'
            ''')
            recent_predictions = cursor.fetchone()[0]

            conn.close()

            future_coverage = (future_covered / total_symbols * 100) if total_symbols > 0 else 0
            historical_coverage = (historical_covered / total_symbols * 100) if total_symbols > 0 else 0

            logger.info(f"ğŸ“Š Data Coverage Report:")
            logger.info(f"  ğŸ¯ Total active symbols: {total_symbols}")
            logger.info(f"  ğŸ”® Future predictions: {future_covered} symbols ({future_coverage:.1f}%)")
            logger.info(f"  ğŸ“œ Historical predictions: {historical_covered} symbols ({historical_coverage:.1f}%)")
            logger.info(f"  â° Recent predictions (2h): {recent_predictions}")

            return {
                'total_symbols': total_symbols,
                'future_coverage': future_coverage,
                'historical_coverage': historical_coverage,
                'recent_predictions': recent_predictions
            }

        except Exception as e:
            logger.error(f"âŒ Data coverage check failed: {e}")
            return None

    def run_lstm_system(self):
        """LSTM & VertexAIã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ"""
        try:
            logger.info("ğŸš€ Starting LSTM & VertexAI execution...")
            result = subprocess.run(
                ['python3', 'direct_lstm_vertexai_system.py'],
                capture_output=True,
                text=True,
                timeout=3600  # 1æ™‚é–“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )

            if result.returncode == 0:
                logger.info("âœ… LSTM & VertexAI execution completed successfully")
                return True
            else:
                logger.error(f"âŒ LSTM execution failed: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            logger.warning("â° LSTM execution timeout (1 hour) - continuing...")
            return True  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯æ­£å¸¸ã¨ã¿ãªã™ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ï¼‰
        except Exception as e:
            logger.error(f"âŒ LSTM execution error: {e}")
            return False

    def start(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹"""
        if self.running:
            logger.warning("Scheduler is already running")
            return

        self.running = True
        self.scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self.scheduler_thread.start()
        logger.info(f"âœ… Continuous LSTM & VertexAI scheduler started (interval: {self.interval_hours}h)")

    def stop(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢"""
        self.running = False
        if self.scheduler_thread:
            self.scheduler_thread.join()
        logger.info("ğŸ›‘ Continuous LSTM scheduler stopped")

    def _run_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        while self.running:
            try:
                self.cycle_count += 1
                logger.info(f"ğŸ”„ ã‚µã‚¤ã‚¯ãƒ« {self.cycle_count}: LSTM & VertexAIç¶™ç¶šå®Ÿè¡Œ")
                logger.info("="*60)

                # ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
                coverage = self.check_data_coverage()

                # LSTM & VertexAIå®Ÿè¡Œåˆ¤å®š
                should_run = True
                if coverage:
                    # ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ90%ä»¥ä¸Šã‹ã¤æœ€è¿‘ã®äºˆæ¸¬ãŒååˆ†ãªå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    if (coverage['future_coverage'] >= 90 and
                        coverage['historical_coverage'] >= 90 and
                        coverage['recent_predictions'] >= 500):
                        should_run = False
                        logger.info("âœ… Data coverage sufficient, skipping this cycle")

                if should_run:
                    # LSTM & VertexAIå®Ÿè¡Œ
                    success = self.run_lstm_system()

                    if success:
                        logger.info(f"âœ… ã‚µã‚¤ã‚¯ãƒ« {self.cycle_count} å®Œäº†")
                    else:
                        logger.warning(f"âš ï¸ ã‚µã‚¤ã‚¯ãƒ« {self.cycle_count} éƒ¨åˆ†çš„æˆåŠŸ")

                    # å®Ÿè¡Œå¾Œã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
                    post_coverage = self.check_data_coverage()
                    if post_coverage and coverage:
                        improvement = post_coverage['recent_predictions']
                        logger.info(f"ğŸ“ˆ äºˆæ¸¬ç”Ÿæˆæ•°: {improvement}ä»¶")

                # æ¬¡å›å®Ÿè¡Œã¾ã§å¾…æ©Ÿ
                sleep_seconds = self.interval_hours * 3600
                logger.info(f"â° æ¬¡å›ã‚µã‚¤ã‚¯ãƒ« {self.cycle_count + 1} ã¾ã§ {self.interval_hours}æ™‚é–“å¾…æ©Ÿ")
                logger.info("="*60)

                for i in range(sleep_seconds):
                    if not self.running:
                        break
                    time.sleep(1)

                    # é€²æ—è¡¨ç¤ºï¼ˆ10åˆ†æ¯ï¼‰
                    if i % 600 == 0 and i > 0:
                        remaining_hours = (sleep_seconds - i) / 3600
                        logger.info(f"â³ æ®‹ã‚Šæ™‚é–“: {remaining_hours:.1f}æ™‚é–“")

            except Exception as e:
                logger.error(f"âŒ Scheduler error in cycle {self.cycle_count}: {e}")
                time.sleep(300)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯5åˆ†å¾…æ©Ÿ

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    scheduler = ContinuousLSTMScheduler(interval_hours=2)  # 2æ™‚é–“é–“éš”

    try:
        logger.info("ğŸš€ğŸ¤– Continuous LSTM & VertexAI Scheduler Starting")
        logger.info("ğŸ’¡ ç›®æ¨™: éŠ˜æŸ„ãƒ»ä¾¡æ ¼ãƒ»éå»äºˆæ¸¬ãƒ»æœªæ¥äºˆæ¸¬ã®å®Œå…¨å……è¶³")
        logger.info("ğŸ§  ä½¿ç”¨æŠ€è¡“: LSTM + VertexAI + TensorFlow 2.20.0")

        scheduler.start()

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        while True:
            time.sleep(10)

    except KeyboardInterrupt:
        logger.info("Shutting down continuous LSTM scheduler...")
        scheduler.stop()

if __name__ == "__main__":
    main()