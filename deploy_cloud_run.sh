#!/bin/bash
#
# Cloud Runå®Œå…¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# GCP Batchã‹ã‚‰ã®ç§»è¡Œã‚’è‡ªå‹•åŒ–
#

set -e

PROJECT_ID="pricewise-huqkr"
REGION="us-central1"
SERVICE_ACCOUNT="cloud-run-sa@${PROJECT_ID}.iam.gserviceaccount.com"

echo "ğŸš€ Cloud Runãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆé–‹å§‹"
echo "================================"

# 1. ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ
echo "ğŸ“Œ Step 1: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®š"
gcloud iam service-accounts create cloud-run-sa \
    --display-name="Cloud Run Service Account" 2>/dev/null || echo "ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ—¢å­˜"

# å¿…è¦ãªæ¨©é™ã‚’ä»˜ä¸
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/cloudsql.client" --quiet

gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/secretmanager.secretAccessor" --quiet

# 2. Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
echo "ğŸ“Œ Step 2: Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰"

# Data Collector
echo "ğŸ”¨ Building data-collector image..."
docker build -t gcr.io/${PROJECT_ID}/data-collector:latest \
    -f Dockerfile.data-collector .

# Prediction Generator
echo "ğŸ”¨ Building prediction-generator image..."
docker build -t gcr.io/${PROJECT_ID}/prediction-generator:latest \
    -f Dockerfile.prediction-generator .

# 3. ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’GCRã«ãƒ—ãƒƒã‚·ãƒ¥
echo "ğŸ“Œ Step 3: GCRã¸ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ—ãƒƒã‚·ãƒ¥"

docker push gcr.io/${PROJECT_ID}/data-collector:latest
docker push gcr.io/${PROJECT_ID}/prediction-generator:latest

# 4. Cloud Runã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ—ãƒ­ã‚¤
echo "ğŸ“Œ Step 4: Cloud Runã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ—ãƒ­ã‚¤"

# Data Collector Service
echo "ğŸš€ Deploying data-collector service..."
gcloud run deploy miraikakaku-data-collector \
    --image=gcr.io/${PROJECT_ID}/data-collector:latest \
    --platform=managed \
    --region=${REGION} \
    --memory=2Gi \
    --cpu=1 \
    --timeout=600 \
    --min-instances=0 \
    --max-instances=10 \
    --concurrency=100 \
    --service-account=${SERVICE_ACCOUNT} \
    --set-env-vars="DATABASE_HOST=34.173.9.214,DATABASE_USER=postgres,DATABASE_NAME=miraikakaku" \
    --set-secrets="DATABASE_PASSWORD=projects/${PROJECT_ID}/secrets/db-password:latest" \
    --allow-unauthenticated

# Prediction Generator Service
echo "ğŸš€ Deploying prediction-generator service..."
gcloud run deploy miraikakaku-prediction-generator \
    --image=gcr.io/${PROJECT_ID}/prediction-generator:latest \
    --platform=managed \
    --region=${REGION} \
    --memory=4Gi \
    --cpu=2 \
    --timeout=900 \
    --min-instances=1 \
    --max-instances=5 \
    --concurrency=50 \
    --service-account=${SERVICE_ACCOUNT} \
    --set-env-vars="DATABASE_HOST=34.173.9.214,DATABASE_USER=postgres,DATABASE_NAME=miraikakaku" \
    --set-secrets="DATABASE_PASSWORD=projects/${PROJECT_ID}/secrets/db-password:latest" \
    --allow-unauthenticated

# 5. Cloud Schedulerã‚¸ãƒ§ãƒ–è¨­å®š
echo "ğŸ“Œ Step 5: Cloud Schedulerã‚¸ãƒ§ãƒ–è¨­å®š"

# ã‚µãƒ¼ãƒ“ã‚¹URLã‚’å–å¾—
DATA_COLLECTOR_URL=$(gcloud run services describe miraikakaku-data-collector \
    --region=${REGION} --format="value(status.url)")
PREDICTION_GENERATOR_URL=$(gcloud run services describe miraikakaku-prediction-generator \
    --region=${REGION} --format="value(status.url)")

# Hourly Data Collection
echo "â° Setting up hourly data collection..."
gcloud scheduler jobs create http hourly-data-collection \
    --location=${REGION} \
    --schedule="0 * * * *" \
    --uri="${DATA_COLLECTOR_URL}/collect" \
    --http-method=POST \
    --headers="Content-Type=application/json" \
    --message-body='{"mode":"standard","symbols_limit":500,"days_back":7}' \
    --time-zone="Asia/Tokyo" 2>/dev/null || \
    gcloud scheduler jobs update http hourly-data-collection \
        --location=${REGION} \
        --schedule="0 * * * *" \
        --uri="${DATA_COLLECTOR_URL}/collect"

# Daily Predictions
echo "â° Setting up daily predictions..."
gcloud scheduler jobs create http daily-predictions \
    --location=${REGION} \
    --schedule="0 6 * * *" \
    --uri="${PREDICTION_GENERATOR_URL}/predict" \
    --http-method=POST \
    --headers="Content-Type=application/json" \
    --message-body='{"mode":"priority","prediction_days":[1,3,7,14,30]}' \
    --time-zone="Asia/Tokyo" 2>/dev/null || \
    gcloud scheduler jobs update http daily-predictions \
        --location=${REGION} \
        --schedule="0 6 * * *" \
        --uri="${PREDICTION_GENERATOR_URL}/predict"

# Priority Collection (3x daily on weekdays)
echo "â° Setting up priority collection..."
gcloud scheduler jobs create http priority-collection \
    --location=${REGION} \
    --schedule="0 9,15,21 * * 1-5" \
    --uri="${DATA_COLLECTOR_URL}/collect" \
    --http-method=POST \
    --headers="Content-Type=application/json" \
    --message-body='{"mode":"priority","symbols_limit":100,"days_back":1}' \
    --time-zone="Asia/Tokyo" 2>/dev/null || \
    gcloud scheduler jobs update http priority-collection \
        --location=${REGION} \
        --schedule="0 9,15,21 * * 1-5" \
        --uri="${DATA_COLLECTOR_URL}/collect"

# Weekly Full Collection
echo "â° Setting up weekly full collection..."
gcloud scheduler jobs create http weekly-full-collection \
    --location=${REGION} \
    --schedule="0 2 * * 0" \
    --uri="${DATA_COLLECTOR_URL}/collect" \
    --http-method=POST \
    --headers="Content-Type=application/json" \
    --message-body='{"mode":"full","symbols_limit":2000,"days_back":30}' \
    --time-zone="Asia/Tokyo" 2>/dev/null || \
    gcloud scheduler jobs update http weekly-full-collection \
        --location=${REGION} \
        --schedule="0 2 * * 0" \
        --uri="${DATA_COLLECTOR_URL}/collect"

# Health Check (every 15 minutes)
echo "â° Setting up health monitoring..."
gcloud scheduler jobs create http health-check \
    --location=${REGION} \
    --schedule="*/15 * * * *" \
    --uri="${DATA_COLLECTOR_URL}/health" \
    --http-method=GET \
    --time-zone="Asia/Tokyo" 2>/dev/null || \
    gcloud scheduler jobs update http health-check \
        --location=${REGION} \
        --schedule="*/15 * * * *" \
        --uri="${DATA_COLLECTOR_URL}/health"

# 6. ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
echo "ğŸ“Œ Step 6: ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š"

# Uptime Checks
gcloud monitoring uptime-checks create data-collector-uptime \
    --display-name="Data Collector Health Check" \
    --resource-type=uptime-url \
    --monitored-resource="{'host': '${DATA_COLLECTOR_URL#https://}'}" \
    --http-check="{'path': '/health', 'port': 443, 'use_ssl': true}" \
    --period=5m 2>/dev/null || echo "Uptime checkæ—¢å­˜"

gcloud monitoring uptime-checks create prediction-generator-uptime \
    --display-name="Prediction Generator Health Check" \
    --resource-type=uptime-url \
    --monitored-resource="{'host': '${PREDICTION_GENERATOR_URL#https://}'}" \
    --http-check="{'path': '/health', 'port': 443, 'use_ssl': true}" \
    --period=5m 2>/dev/null || echo "Uptime checkæ—¢å­˜"

# 7. æœ€çµ‚ç¢ºèª
echo "ğŸ“Œ Step 7: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç¢ºèª"
echo "================================"

echo "âœ… Data Collector URL: ${DATA_COLLECTOR_URL}"
echo "âœ… Prediction Generator URL: ${PREDICTION_GENERATOR_URL}"

# ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
echo ""
echo "ğŸ“Š ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹:"
gcloud run services list --platform=managed --region=${REGION} \
    --filter="metadata.name:miraikakaku" --format="table(metadata.name,status.url,status.conditions[0].message)"

echo ""
echo "â° ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚¸ãƒ§ãƒ–:"
gcloud scheduler jobs list --location=${REGION} \
    --format="table(name,schedule,state)"

echo ""
echo "ğŸ‰ Cloud Runãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå®Œäº†!"
echo "================================"
echo ""
echo "ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:"
echo "1. ã‚µãƒ¼ãƒ“ã‚¹URLã§ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç¢ºèª"
echo "2. Cloud Schedulerã‚¸ãƒ§ãƒ–ã®æ‰‹å‹•å®Ÿè¡Œã§ãƒ†ã‚¹ãƒˆ"
echo "3. Cloud Monitoringã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–"
echo "4. å¤ã„GCP Batchã‚¸ãƒ§ãƒ–ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ"