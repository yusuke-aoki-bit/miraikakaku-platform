# MiraiKakaku Auto-Scaling Configuration
# Production-ready scaling configuration for all services

apiVersion: v1
kind: ConfigMap
metadata:
  name: miraikakaku-scaling-config
  namespace: miraikakaku-prod
data:
  # API Service Scaling Configuration
  api-scaling.yaml: |
    service: miraikakaku-api
    platform: cloud-run
    scaling:
      min_instances: 2
      max_instances: 100
      concurrency: 80
      cpu_utilization_target: 70
      memory_utilization_target: 80

    custom_metrics:
      - name: request_latency_p95
        target_value: 2000  # 2 seconds
        weight: 0.3
      - name: database_connection_pool_usage
        target_value: 70    # 70%
        weight: 0.2
      - name: error_rate_percentage
        target_value: 1     # 1%
        weight: 0.2
      - name: queue_depth
        target_value: 50    # messages
        weight: 0.3

    business_metrics:
      - name: active_users_per_minute
        scaling_factor: 1.5  # 1.5 instances per 1000 active users
      - name: prediction_requests_per_minute
        scaling_factor: 2.0  # 2 instances per 100 requests

    scaling_policies:
      scale_up:
        threshold_breach_duration: 60s
        cooldown_period: 300s
        step_size: 2
      scale_down:
        threshold_breach_duration: 300s
        cooldown_period: 600s
        step_size: 1

  # Batch Service Scaling Configuration
  batch-scaling.yaml: |
    service: miraikakaku-batch
    platform: cloud-run-jobs
    scaling:
      parallelism: 10
      task_count: 100
      task_timeout: 3600s
      max_retries: 3

    scheduling:
      data_collection:
        cron: "0 */4 * * *"  # Every 4 hours
        scaling:
          min_instances: 1
          max_instances: 20
      prediction_generation:
        cron: "30 6,18 * * *"  # 6:30 AM and 6:30 PM daily
        scaling:
          min_instances: 2
          max_instances: 50
      data_analysis:
        cron: "0 2 * * *"     # 2:00 AM daily
        scaling:
          min_instances: 1
          max_instances: 10

    resource_scaling:
      cpu_based:
        target_utilization: 80
        scale_up_threshold: 85
        scale_down_threshold: 50
      memory_based:
        target_utilization: 75
        scale_up_threshold: 80
        scale_down_threshold: 40

  # Frontend Service Scaling Configuration
  frontend-scaling.yaml: |
    service: miraikakaku-frontend
    platform: cloud-run
    scaling:
      min_instances: 1
      max_instances: 50
      concurrency: 1000
      cpu_utilization_target: 60
      memory_utilization_target: 70

    cdn_configuration:
      enabled: true
      cache_control: "public, max-age=3600"
      static_assets_ttl: 86400  # 24 hours

    edge_locations:
      - asia-northeast1  # Tokyo
      - asia-southeast1  # Singapore
      - us-central1      # Iowa
      - europe-west1     # Belgium

    performance_budgets:
      first_contentful_paint: 1500ms
      largest_contentful_paint: 2500ms
      cumulative_layout_shift: 0.1

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: scaling-thresholds
  namespace: miraikakaku-prod
data:
  # Critical Alert Thresholds
  critical_thresholds.yaml: |
    system_alerts:
      high_cpu_usage:
        threshold: 90
        duration: 180s
        action: immediate_scale_up
      high_memory_usage:
        threshold: 85
        duration: 120s
        action: immediate_scale_up
      high_error_rate:
        threshold: 5    # 5%
        duration: 60s
        action: circuit_breaker
      database_connection_exhaustion:
        threshold: 95   # 95% of pool
        duration: 30s
        action: emergency_scale_up

    performance_alerts:
      slow_response_time:
        threshold: 5000ms  # 5 seconds
        duration: 180s
        action: gradual_scale_up
      high_latency_p99:
        threshold: 3000ms
        duration: 300s
        action: investigation_required
      cache_miss_rate:
        threshold: 30    # 30%
        duration: 600s
        action: cache_warming

    business_alerts:
      user_session_spike:
        threshold_multiplier: 2.0  # 2x normal traffic
        baseline_period: 1h
        action: predictive_scale_up
      peak_trading_hours:
        time_ranges:
          - "09:00-16:00 JST"  # Tokyo market hours
          - "09:30-16:00 EST"  # NYSE hours
        scaling_multiplier: 1.5
      earnings_announcement_periods:
        scaling_multiplier: 3.0
        pre_scale_duration: 30min

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scaling-controller
  namespace: miraikakaku-prod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: scaling-controller
  template:
    metadata:
      labels:
        app: scaling-controller
    spec:
      containers:
      - name: scaling-controller
        image: gcr.io/miraikakaku/scaling-controller:latest
        ports:
        - containerPort: 8080
        env:
        - name: GCP_PROJECT_ID
          value: "miraikakaku-prod"
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-credentials
              key: url
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: postgres-credentials
              key: url
        - name: PROMETHEUS_URL
          value: "http://prometheus:9090"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: scaling-config
          mountPath: /config
          readOnly: true
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: scaling-config
        configMap:
          name: miraikakaku-scaling-config
      serviceAccountName: scaling-controller
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000