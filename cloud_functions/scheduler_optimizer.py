#!/usr/bin/env python3
"""
Cloud Scheduleræœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
Cloud Scheduler Optimization System

è‡ªå‹•ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ç®¡ç†ã®å®Œå…¨è‡ªå‹•åŒ–
"""

import json
import logging
from typing import Dict, List, Any
from datetime import datetime, timedelta
import subprocess
import os

logger = logging.getLogger(__name__)

class SchedulerOptimizer:
    """Cloud Scheduleræœ€é©åŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.project_id = "pricewise-huqkr"
        self.region = "us-central1"
        self.time_zone = "Asia/Tokyo"

    def create_scheduler_jobs(self) -> List[Dict[str, Any]]:
        """æœ€é©åŒ–ã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ"""

        scheduler_configs = [
            {
                'name': 'daily-stock-data-update',
                'description': 'æ¯æ—¥ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆé«˜å„ªå…ˆåº¦ï¼‰',
                'schedule': '0 9 * * 1-5',  # å¹³æ—¥9:00 JST
                'target_uri': 'https://stock-data-updater-zbaru5v7za-uc.a.run.app/update',
                'http_method': 'POST',
                'timeout': '1800s',  # 30åˆ†
                'retry_count': 3,
                'max_backoff': '300s'
            },
            {
                'name': 'hourly-prediction-update',
                'description': '1æ™‚é–“ã”ã¨ã®AIäºˆæ¸¬æ›´æ–°',
                'schedule': '0 */1 * * *',  # æ¯æ™‚0åˆ†
                'target_uri': 'https://lstm-predictions-v3-zbaru5v7za-uc.a.run.app/predict',
                'http_method': 'POST',
                'timeout': '900s',  # 15åˆ†
                'retry_count': 2,
                'max_backoff': '120s'
            },
            {
                'name': 'weekly-system-maintenance',
                'description': 'é€±æ¬¡ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹',
                'schedule': '0 2 * * 0',  # æ—¥æ›œæ—¥2:00 JST
                'target_uri': 'https://miraikakaku-api-zbaru5v7za-uc.a.run.app/maintenance',
                'http_method': 'POST',
                'timeout': '1800s',  # 30åˆ†ï¼ˆCloud Schedulerã®æœ€å¤§åˆ¶é™ï¼‰
                'retry_count': 1,
                'max_backoff': '600s'
            },
            {
                'name': 'health-check-monitor',
                'description': '15åˆ†é–“éš”ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯',
                'schedule': '*/15 * * * *',  # 15åˆ†ã”ã¨
                'target_uri': 'https://miraikakaku-api-zbaru5v7za-uc.a.run.app/health',
                'http_method': 'GET',
                'timeout': '60s',
                'retry_count': 2,
                'max_backoff': '30s'
            }
        ]

        results = []
        for config in scheduler_configs:
            try:
                result = self.create_single_scheduler_job(config)
                results.append({
                    'name': config['name'],
                    'status': 'success' if result else 'failed',
                    'config': config
                })
                logger.info(f"Scheduler job created: {config['name']}")
            except Exception as e:
                results.append({
                    'name': config['name'],
                    'status': 'error',
                    'error': str(e),
                    'config': config
                })
                logger.error(f"Failed to create scheduler job {config['name']}: {e}")

        return results

    def create_single_scheduler_job(self, config: Dict[str, Any]) -> bool:
        """å˜ä¸€ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ"""

        # gcloud ã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰
        cmd = [
            'gcloud', 'scheduler', 'jobs', 'create', 'http',
            config['name'],
            f"--location={self.region}",
            f"--schedule={config['schedule']}",
            f"--uri={config['target_uri']}",
            f"--http-method={config['http_method']}",
            f"--time-zone={self.time_zone}",
            f"--attempt-deadline={config['timeout']}",
            f"--max-retry-attempts={config['retry_count']}",
            f"--max-backoff={config['max_backoff']}",
            f"--description={config['description']}",
            '--quiet'
        ]

        # POST ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã€ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒœãƒ‡ã‚£ã‚’è¿½åŠ 
        if config['http_method'] == 'POST':
            cmd.extend([
                '--headers=Content-Type=application/json',
                '--message-body={"source":"cloud_scheduler","automated":true}'
            ])

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode == 0:
                logger.info(f"Successfully created scheduler job: {config['name']}")
                return True
            else:
                logger.error(f"gcloud command failed: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            logger.error(f"Timeout creating scheduler job: {config['name']}")
            return False
        except Exception as e:
            logger.error(f"Exception creating scheduler job {config['name']}: {e}")
            return False

    def get_scheduler_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çŠ¶æ³ã‚’å–å¾—"""
        try:
            cmd = [
                'gcloud', 'scheduler', 'jobs', 'list',
                f'--location={self.region}',
                '--format=json'
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                jobs = json.loads(result.stdout) if result.stdout else []
                return {
                    'status': 'success',
                    'total_jobs': len(jobs),
                    'jobs': jobs,
                    'timestamp': datetime.now().isoformat()
                }
            else:
                return {
                    'status': 'error',
                    'message': result.stderr,
                    'timestamp': datetime.now().isoformat()
                }

        except Exception as e:
            return {
                'status': 'error',
                'message': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def optimize_existing_jobs(self) -> List[Dict[str, Any]]:
        """æ—¢å­˜ã‚¸ãƒ§ãƒ–ã®æœ€é©åŒ–"""
        status = self.get_scheduler_status()

        if status['status'] != 'success':
            return [{'error': 'Failed to fetch existing jobs', 'details': status}]

        optimizations = []

        for job in status.get('jobs', []):
            job_name = job.get('name', '').split('/')[-1]

            # æœ€é©åŒ–ææ¡ˆã‚’ç”Ÿæˆ
            suggestions = self.analyze_job_performance(job)
            if suggestions:
                optimizations.append({
                    'job_name': job_name,
                    'current_config': job,
                    'suggestions': suggestions,
                    'priority': self.calculate_optimization_priority(suggestions)
                })

        return sorted(optimizations, key=lambda x: x['priority'], reverse=True)

    def analyze_job_performance(self, job: Dict[str, Any]) -> List[str]:
        """ã‚¸ãƒ§ãƒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æ"""
        suggestions = []

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«é »åº¦ã®ãƒã‚§ãƒƒã‚¯
        schedule = job.get('schedule', '')
        if 'health-check' in job.get('name', '').lower():
            if '*/15' not in schedule:
                suggestions.append('ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯é–“éš”ã‚’15åˆ†ã«æœ€é©åŒ–æ¨å¥¨')

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®ãƒã‚§ãƒƒã‚¯
        timeout = job.get('attemptDeadline', '')
        if 'prediction' in job.get('name', '').lower():
            if '900s' not in timeout:
                suggestions.append('äºˆæ¸¬ã‚¸ãƒ§ãƒ–ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’15åˆ†ã«è¨­å®šæ¨å¥¨')

        # ãƒªãƒˆãƒ©ã‚¤è¨­å®šã®ãƒã‚§ãƒƒã‚¯
        retry_config = job.get('retryConfig', {})
        max_attempts = retry_config.get('maxRetryAttempts', 0)

        if 'update' in job.get('name', '').lower() and max_attempts < 3:
            suggestions.append('ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¸ãƒ§ãƒ–ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’3å›ã«å¢—åŠ æ¨å¥¨')

        return suggestions

    def calculate_optimization_priority(self, suggestions: List[str]) -> int:
        """æœ€é©åŒ–å„ªå…ˆåº¦ã‚’è¨ˆç®—"""
        priority_keywords = {
            'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ': 5,
            'ãƒªãƒˆãƒ©ã‚¤': 4,
            'ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯': 3,
            'é–“éš”': 2,
            'è¨­å®š': 1
        }

        total_priority = 0
        for suggestion in suggestions:
            for keyword, value in priority_keywords.items():
                if keyword in suggestion:
                    total_priority += value

        return total_priority

def setup_production_scheduler():
    """æœ¬ç•ªç’°å¢ƒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    scheduler = SchedulerOptimizer()

    print("ğŸš€ Starting Cloud Scheduler Optimization Setup")
    print("=" * 50)

    # 1. ç¾åœ¨ã®çŠ¶æ³ç¢ºèª
    print("\nğŸ“Š Current Scheduler Status:")
    status = scheduler.get_scheduler_status()
    print(json.dumps(status, indent=2, default=str))

    # 2. æ–°ã—ã„ã‚¸ãƒ§ãƒ–ä½œæˆ
    print("\nğŸ”§ Creating Optimized Scheduler Jobs:")
    results = scheduler.create_scheduler_jobs()

    for result in results:
        status_icon = "âœ…" if result['status'] == 'success' else "âŒ"
        print(f"{status_icon} {result['name']}: {result['status']}")

    # 3. æœ€é©åŒ–ææ¡ˆ
    print("\nğŸ’¡ Optimization Suggestions:")
    optimizations = scheduler.optimize_existing_jobs()

    for opt in optimizations[:3]:  # Top 3 suggestions
        print(f"ğŸ¯ {opt['job_name']} (Priority: {opt['priority']})")
        for suggestion in opt['suggestions']:
            print(f"   â€¢ {suggestion}")

    print("\nâœ… Cloud Scheduler Optimization Complete!")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    setup_production_scheduler()