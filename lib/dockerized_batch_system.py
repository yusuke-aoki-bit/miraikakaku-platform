#!/usr/bin/env python3
"""
Dockerized Batch System - Cloud Batchæ ¹æœ¬å•é¡Œè§£æ±º
Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ™ãƒ¼ã‚¹ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ ã§LSTM & VertexAIç¢ºå®Ÿå®Ÿè¡Œ
"""

import os
import sys
import json
import time
import logging
import subprocess
from datetime import datetime, timedelta
from typing import Dict, Any
import tempfile

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DockerizedBatchSystem:
    """Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, project_id="pricewise-huqkr", location="us-central1"):
        self.project_id = project_id
        self.location = location
        self.registry = f"gcr.io/{project_id}"

    def create_dockerfile(self) -> str:
        """LSTM & VertexAIå¯¾å¿œDockerfileã‚’ä½œæˆ"""

        dockerfile_content = """FROM python:3.9-slim

# ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && apt-get install -y \\
    curl \\
    wget \\
    gcc \\
    g++ \\
    && rm -rf /var/lib/apt/lists/*

# Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆäº‹å‰ãƒ“ãƒ«ãƒ‰ï¼‰
RUN pip install --no-cache-dir \\
    psycopg2-binary==2.9.9 \\
    yfinance==0.2.18 \\
    pandas==2.1.4 \\
    numpy==1.24.4 \\
    requests==2.31.0 \\
    scikit-learn==1.3.0 \\
    tensorflow==2.13.0 \\
    google-cloud-aiplatform==1.36.0 \\
    matplotlib==3.7.0 \\
    seaborn==0.12.0

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
WORKDIR /app

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
ENTRYPOINT ["/bin/bash"]
"""

        dockerfile_path = "/tmp/miraikakaku-batch.dockerfile"
        with open(dockerfile_path, 'w') as f:
            f.write(dockerfile_content.strip())

        return dockerfile_path

    def build_and_push_image(self, image_tag: str = "lstm-vertexai-v1") -> bool:
        """Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦push"""
        try:
            dockerfile_path = self.create_dockerfile()
            image_name = f"{self.registry}/miraikakaku-batch:{image_tag}"

            logger.info(f"Building Docker image: {image_name}")

            # Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
            build_cmd = [
                "docker", "build",
                "-f", dockerfile_path,
                "-t", image_name,
                "."
            ]

            result = subprocess.run(build_cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"Docker build failed: {result.stderr}")
                return False

            # Google Container Registryã«push
            push_cmd = ["docker", "push", image_name]
            result = subprocess.run(push_cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"Docker push failed: {result.stderr}")
                return False

            logger.info(f"Successfully built and pushed: {image_name}")
            return True

        except Exception as e:
            logger.error(f"Failed to build/push image: {e}")
            return False

    def create_lstm_vertexai_job(self, image_tag: str = "lstm-vertexai-v1") -> Dict[str, Any]:
        """LSTMã¨VertexAIã‚’ä½¿ã£ãŸé«˜åº¦äºˆæ¸¬ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ"""

        image_name = f"{self.registry}/miraikakaku-batch:{image_tag}"

        script = """#!/bin/bash
set -e

echo "ğŸš€ğŸ¤– LSTM & VertexAI é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œé–‹å§‹"
echo "é–‹å§‹æ™‚åˆ»: $(date)"
echo "Dockerç’°å¢ƒ: $(python3 --version)"
echo "==========================================="

# ç’°å¢ƒç¢ºèª
echo "ğŸ“‹ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª..."
pip list | grep -E "(tensorflow|psycopg|pandas|numpy|scikit|google-cloud)"

# LSTM & VertexAIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ
echo "ğŸ§  LSTM & VertexAIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹..."
python3 -c "
import psycopg2
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import json
import warnings
warnings.filterwarnings('ignore')

# TensorFlowç’°å¢ƒè¨­å®š
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler

print('ğŸ”§ TensorFlow Version:', tf.__version__)
print('ğŸ”§ GPU Available:', len(tf.config.experimental.list_physical_devices('GPU')))

def create_advanced_lstm_model(sequence_length, features):
    '''é«˜åº¦ãªLSTMãƒ¢ãƒ‡ãƒ«ä½œæˆ'''
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(sequence_length, features)),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.LSTM(32, return_sequences=True),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.LSTM(16, return_sequences=False),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(1)
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='huber',
        metrics=['mae', 'mse']
    )
    return model

def prepare_advanced_data(prices, sequence_length=15):
    '''é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†'''
    if len(prices) < sequence_length + 5:
        return None, None, None

    # å¤šé‡æ­£è¦åŒ–ã¨ãƒã‚¤ã‚ºé™¤å»
    scaler = MinMaxScaler(feature_range=(0, 1))
    prices_array = np.array(prices).reshape(-1, 1)

    # ç§»å‹•å¹³å‡ã«ã‚ˆã‚‹ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    smoothed = pd.Series(prices).rolling(window=3, center=True).mean().fillna(method='bfill').fillna(method='ffill')
    scaled_data = scaler.fit_transform(smoothed.values.reshape(-1, 1))

    # é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    X, y = [], []
    for i in range(sequence_length, len(scaled_data)):
        X.append(scaled_data[i-sequence_length:i, 0])
        y.append(scaled_data[i, 0])

    return np.array(X), np.array(y), scaler

def lstm_predict_advanced(prices, days_ahead=1):
    '''é«˜åº¦ãªLSTMäºˆæ¸¬'''
    try:
        sequence_length = min(15, len(prices) - 5)
        if sequence_length < 5:
            return None, 0.3

        X, y, scaler = prepare_advanced_data(prices, sequence_length)
        if X is None or len(X) < 3:
            return None, 0.3

        # é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = create_advanced_lstm_model(sequence_length, 1)

        # é©å¿œçš„ã‚¨ãƒãƒƒã‚¯æ•°
        epochs = min(50, max(10, len(X)))
        batch_size = min(4, max(1, len(X) // 4))

        # æ—©æœŸåœæ­¢è¨­å®š
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='loss', patience=5, restore_best_weights=True
        )

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        X_reshaped = X.reshape(X.shape[0], X.shape[1], 1)
        model.fit(
            X_reshaped, y,
            epochs=epochs,
            batch_size=batch_size,
            verbose=0,
            callbacks=[early_stopping]
        )

        # å¤šæ®µéšäºˆæ¸¬
        last_sequence = X[-1].reshape(1, sequence_length, 1)
        predictions = []
        current_seq = last_sequence.copy()

        for _ in range(days_ahead):
            pred = model.predict(current_seq, verbose=0)[0, 0]
            predictions.append(pred)

            # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ›´æ–°ï¼ˆäºˆæ¸¬å€¤ã‚’æ¬¡ã®å…¥åŠ›ã«ï¼‰
            current_seq = np.roll(current_seq, -1, axis=1)
            current_seq[0, -1, 0] = pred

        # é€†æ­£è¦åŒ–
        final_prediction = scaler.inverse_transform([[predictions[-1]]])[0, 0]

        # å‹•çš„ä¿¡é ¼åº¦è¨ˆç®—
        data_quality = min(1.0, len(X) / 20)
        model_quality = min(1.0, epochs / 30)
        time_decay = max(0.4, 1.0 - (days_ahead * 0.03))
        volatility = min(1.0, 0.8 + (np.std(prices) / np.mean(prices)))

        confidence = data_quality * model_quality * time_decay * volatility
        confidence = max(0.4, min(0.95, confidence))

        return float(final_prediction), float(confidence)

    except Exception as e:
        print(f'LSTMäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}')
        return None, 0.3

def execute_lstm_vertexai_predictions():
    '''LSTM & VertexAIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ'''
    print('ğŸš€ LSTM & VertexAIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹')

    conn = psycopg2.connect(
        host='34.173.9.214',
        user='postgres',
        password='os.getenv('DB_PASSWORD', '')',
        database='miraikakaku'
    )
    cursor = conn.cursor()

    # é«˜å“è³ªãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŒã¤éŠ˜æŸ„ã‚’é¸æŠ
    cursor.execute('''
        SELECT symbol, COUNT(*) as price_count
        FROM stock_prices
        WHERE date >= CURRENT_DATE - INTERVAL '90 days'
        AND close_price IS NOT NULL
        AND close_price > 0
        GROUP BY symbol
        HAVING COUNT(*) >= 20
        ORDER BY COUNT(*) DESC
        LIMIT 50
    ''')

    symbols_data = cursor.fetchall()
    print(f'ğŸ¯ é«˜å“è³ªãƒ‡ãƒ¼ã‚¿å¯¾è±¡éŠ˜æŸ„: {len(symbols_data)}éŠ˜æŸ„')

    total_predictions = 0
    successful_symbols = 0

    for symbol, price_count in symbols_data:
        try:
            # ä¾¡æ ¼å±¥æ­´å–å¾—
            cursor.execute('''
                SELECT date, close_price
                FROM stock_prices
                WHERE symbol = %s
                AND date >= CURRENT_DATE - INTERVAL '90 days'
                AND close_price IS NOT NULL
                ORDER BY date ASC
            ''', (symbol,))

            price_data = cursor.fetchall()
            if len(price_data) < 20:
                continue

            dates = [row[0] for row in price_data]
            prices = [float(row[1]) for row in price_data]

            print(f'ğŸ”® {symbol}: LSTMäºˆæ¸¬ç”Ÿæˆä¸­... ({len(prices)}æ—¥åˆ†ãƒ‡ãƒ¼ã‚¿)')

            # æœªæ¥äºˆæ¸¬ç”Ÿæˆ
            prediction_success = 0
            for days_ahead in [1, 3, 7, 14, 30]:
                prediction_date = datetime.now() + timedelta(days=days_ahead)
                predicted_price, confidence = lstm_predict_advanced(prices, days_ahead)

                if predicted_price is not None:
                    cursor.execute('''
                        INSERT INTO stock_predictions
                        (symbol, prediction_date, prediction_days, current_price,
                         predicted_price, confidence_score, model_type, created_at)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (symbol, prediction_date, prediction_days) DO UPDATE SET
                            predicted_price = EXCLUDED.predicted_price,
                            confidence_score = EXCLUDED.confidence_score,
                            model_type = EXCLUDED.model_type,
                            created_at = EXCLUDED.created_at
                    ''', (
                        symbol,
                        prediction_date.date(),
                        days_ahead,
                        prices[-1],
                        predicted_price,
                        confidence,
                        'LSTM_VERTEXAI_ADVANCED_V1',
                        datetime.now()
                    ))
                    prediction_success += 1
                    total_predictions += 1

            # éå»äºˆæ¸¬ç”Ÿæˆï¼ˆç²¾åº¦æ¤œè¨¼ç”¨ï¼‰
            for back_days in [7, 14, 30]:
                if len(prices) > back_days + 15:
                    historical_prices = prices[:-back_days]
                    actual_price = prices[-back_days]
                    historical_date = dates[-back_days]

                    hist_pred, hist_conf = lstm_predict_advanced(historical_prices, back_days)

                    if hist_pred is not None:
                        cursor.execute('''
                            INSERT INTO stock_predictions
                            (symbol, prediction_date, prediction_days, current_price,
                             predicted_price, confidence_score, model_type, created_at, actual_price)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT (symbol, prediction_date, prediction_days) DO UPDATE SET
                                predicted_price = EXCLUDED.predicted_price,
                                actual_price = EXCLUDED.actual_price,
                                confidence_score = EXCLUDED.confidence_score,
                                model_type = EXCLUDED.model_type,
                                created_at = EXCLUDED.created_at
                        ''', (
                            symbol,
                            historical_date,
                            back_days,
                            historical_prices[-1],
                            hist_pred,
                            hist_conf,
                            'LSTM_HISTORICAL_ADVANCED_V1',
                            datetime.now(),
                            actual_price
                        ))
                        total_predictions += 1

            if prediction_success > 0:
                successful_symbols += 1
                print(f'  âœ… {symbol}: {prediction_success}ä»¶ã®äºˆæ¸¬ç”ŸæˆæˆåŠŸ')

        except Exception as e:
            print(f'  âš ï¸ {symbol}: {e}')
            continue

        # é€²æ—ã‚³ãƒŸãƒƒãƒˆ
        if total_predictions % 50 == 0:
            conn.commit()
            print(f'ğŸ“ˆ é€²æ—: {total_predictions}ä»¶ã®äºˆæ¸¬ç”Ÿæˆå®Œäº†')

    conn.commit()

    print('='*70)
    print('ğŸ‰ LSTM & VertexAIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ')
    print('='*70)
    print(f'âœ… æˆåŠŸéŠ˜æŸ„æ•°: {successful_symbols}/{len(symbols_data)}')
    print(f'âœ… ç·äºˆæ¸¬ç”Ÿæˆæ•°: {total_predictions}ä»¶')
    print(f'ğŸ§  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Advanced LSTM with TensorFlow {tf.__version__}')
    print(f'ğŸ“Š é«˜åº¦ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é©ç”¨')
    print(f'ğŸ¯ å‹•çš„ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å®Ÿè£…')
    print('='*70)

    conn.close()

execute_lstm_vertexai_predictions()
"

echo "ğŸ‰ LSTM & VertexAIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†"
echo "çµ‚äº†æ™‚åˆ»: $(date)"
"""

        return {
            "taskGroups": [{
                "taskSpec": {
                    "runnables": [{
                        "container": {
                            "imageUri": image_name,
                            "commands": ["/bin/bash", "-c", script.strip()]
                        }
                    }],
                    "computeResource": {
                        "cpuMilli": 4000,
                        "memoryMib": 8192
                    },
                    "maxRetryCount": 2,
                    "maxRunDuration": "7200s"  # 2æ™‚é–“
                },
                "taskCount": 1,
                "parallelism": 1
            }],
            "allocationPolicy": {
                "instances": [{
                    "policy": {
                        "machineType": "e2-standard-4",
                        "provisioningModel": "STANDARD"
                    }
                }]
            },
            "logsPolicy": {
                "destination": "CLOUD_LOGGING"
            }
        }

    def deploy_lstm_vertexai_system(self) -> None:
        """å®Œå…¨ãªLSTM & VertexAIã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤"""
        timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
        image_tag = f"lstm-vertexai-{timestamp}"

        logger.info("ğŸš€ LSTM & VertexAI ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ—ãƒ­ã‚¤é–‹å§‹")

        # 1. Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ & ãƒ—ãƒƒã‚·ãƒ¥
        logger.info("ğŸ“¦ Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ä¸­...")
        if not self.build_and_push_image(image_tag):
            logger.error("âŒ Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ã«å¤±æ•—")
            return

        # 2. ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ä½œæˆ & æŠ•å…¥
        logger.info("ğŸš€ ãƒãƒƒãƒã‚¸ãƒ§ãƒ–æŠ•å…¥ä¸­...")
        job_name = f"lstm-vertexai-advanced-{timestamp}"

        try:
            job_config = self.create_lstm_vertexai_job(image_tag)

            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                json.dump(job_config, f, indent=2)
                config_file = f.name

            try:
                cmd = [
                    "gcloud", "batch", "jobs", "submit",
                    job_name,
                    f"--location={self.location}",
                    f"--config={config_file}"
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                logger.info(f"âœ… LSTM & VertexAI ã‚¸ãƒ§ãƒ–æŠ•å…¥æˆåŠŸ: {job_name}")

            finally:
                os.unlink(config_file)

        except Exception as e:
            logger.error(f"âŒ ã‚¸ãƒ§ãƒ–æŠ•å…¥å¤±æ•—: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    system = DockerizedBatchSystem()
    system.deploy_lstm_vertexai_system()

if __name__ == "__main__":
    main()