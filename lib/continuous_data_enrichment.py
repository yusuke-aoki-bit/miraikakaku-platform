#!/usr/bin/env python3
"""
Continuous Data Enrichment Batch Job System
Á∂ôÁ∂öÁöÑ„Éá„Éº„ÇøÂÖÖË∂≥„Éê„ÉÉ„ÉÅ„Ç∏„Éß„Éñ„Ç∑„Çπ„ÉÜ„É†
"""

import os
import sys
import json
import time
import logging
import subprocess
from datetime import datetime, timedelta
from typing import Dict, Any
import tempfile

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ContinuousDataEnrichmentJob:
    """Á∂ôÁ∂öÁöÑ„Éá„Éº„ÇøÂÖÖË∂≥„Ç∏„Éß„Éñ"""

    def __init__(self, project_id="pricewise-huqkr", location="us-central1"):
        self.project_id = project_id
        self.location = location

    def create_comprehensive_job(self) -> Dict[str, Any]:
        """ÂåÖÊã¨ÁöÑ„Éá„Éº„ÇøÂèéÈõÜ„Éª‰∫àÊ∏¨ÁîüÊàê„Ç∏„Éß„Éñ„Çí‰ΩúÊàê"""

        script = """#!/bin/bash
set -e

echo "üöÄ 100%ÂÆåÁíßmiraikakaku„Ç∑„Çπ„ÉÜ„É† - ÂÆåÂÖ®„Éá„Éº„ÇøÂÖÖË∂≥„Éê„ÉÉ„ÉÅ"
echo "ÈñãÂßãÊôÇÂàª: $(date)"
echo "================================"

# 1. „Éë„ÉÉ„Ç±„Éº„Ç∏„Ç§„É≥„Çπ„Éà„Éº„É´
echo "üì¶ ÂøÖË¶Å„Éë„ÉÉ„Ç±„Éº„Ç∏„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´‰∏≠..."
pip install -q psycopg2-binary>=2.9.9 yfinance>=0.2.18 pandas>=2.1.0 numpy>=1.24.0 requests>=2.31.0

# 2. ÈäòÊüÑ„Éû„Çπ„Çø„ÅÆÊõ¥Êñ∞„Å®Êã°Âºµ
echo "üîç ÈäòÊüÑ„Éû„Çπ„Çø„ÅÆÊõ¥Êñ∞‰∏≠..."
python3 -c "
import psycopg2
import yfinance as yf
from datetime import datetime, timedelta
import time

def update_stock_master():
    conn = psycopg2.connect(
        host='34.173.9.214',
        user='postgres',
        password='os.getenv('DB_PASSWORD', '')',
        database='miraikakaku'
    )
    cursor = conn.cursor()

    # ‰∏ªË¶Å„Å™ÈäòÊüÑ„É™„Çπ„Éà
    symbols = [
        # Á±≥ÂõΩÊ†™
        'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA',
        'JPM', 'V', 'JNJ', 'WMT', 'PG', 'UNH', 'HD', 'DIS',
        # Êó•Êú¨Ê†™
        '7203.T', '6758.T', '8306.T', '9984.T', '6861.T', '4063.T',
        '6501.T', '8058.T', '8031.T', '7267.T', '4502.T', '9433.T',
        # ETF
        'SPY', 'QQQ', 'DIA', 'VTI', 'VOO', 'IWM', 'EFA', 'EEM'
    ]

    added = 0
    for symbol in symbols:
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info

            company_name = info.get('longName', info.get('shortName', symbol))
            exchange = info.get('exchange', 'UNKNOWN')

            cursor.execute('''
                INSERT INTO stock_master (symbol, company_name, exchange, is_active)
                VALUES (%s, %s, %s, true)
                ON CONFLICT (symbol) DO UPDATE SET
                    company_name = EXCLUDED.company_name,
                    exchange = EXCLUDED.exchange,
                    is_active = true
            ''', (symbol, company_name, exchange))

            added += 1
            if added % 10 == 0:
                conn.commit()
                print(f'‚úÖ {added}ÈäòÊüÑ„ÇíÊõ¥Êñ∞')

            time.sleep(0.5)  # APIÂà∂ÈôêÂØæÁ≠ñ

        except Exception as e:
            print(f'‚ö†Ô∏è {symbol}„ÅÆ„Ç®„É©„Éº: {e}')
            continue

    conn.commit()
    print(f'‚úÖ ÂêàË®à{added}ÈäòÊüÑ„ÇíÊõ¥Êñ∞ÂÆå‰∫Ü')
    conn.close()

update_stock_master()
"

# 3. ‰æ°Ê†º„Éá„Éº„Çø„ÅÆÂèéÈõÜ
echo "üíπ ‰æ°Ê†º„Éá„Éº„ÇøÂèéÈõÜ‰∏≠..."
python3 -c "
import psycopg2
import yfinance as yf
from datetime import datetime, timedelta
import time

def collect_price_data():
    conn = psycopg2.connect(
        host='34.173.9.214',
        user='postgres',
        password='os.getenv('DB_PASSWORD', '')',
        database='miraikakaku'
    )
    cursor = conn.cursor()

    # „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Å™ÈäòÊüÑ„ÇíÂèñÂæó
    cursor.execute('''
        SELECT symbol FROM stock_master
        WHERE is_active = true
        ORDER BY RANDOM()
        LIMIT 100
    ''')
    symbols = [row[0] for row in cursor.fetchall()]

    prices_added = 0
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)

    for symbol in symbols:
        try:
            ticker = yf.Ticker(symbol)
            hist = ticker.history(start=start_date, end=end_date)

            if hist.empty:
                continue

            for date, row in hist.iterrows():
                cursor.execute('''
                    INSERT INTO stock_prices
                    (symbol, date, open_price, high_price, low_price, close_price, volume)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (symbol, date) DO UPDATE SET
                        open_price = EXCLUDED.open_price,
                        high_price = EXCLUDED.high_price,
                        low_price = EXCLUDED.low_price,
                        close_price = EXCLUDED.close_price,
                        volume = EXCLUDED.volume
                ''', (
                    symbol,
                    date.date(),
                    float(row['Open']),
                    float(row['High']),
                    float(row['Low']),
                    float(row['Close']),
                    int(row['Volume'])
                ))
                prices_added += 1

            if prices_added % 100 == 0:
                conn.commit()
                print(f'‚úÖ {prices_added}‰ª∂„ÅÆ‰æ°Ê†º„Éá„Éº„Çø„Çí‰øùÂ≠ò')

            time.sleep(0.5)  # APIÂà∂ÈôêÂØæÁ≠ñ

        except Exception as e:
            print(f'‚ö†Ô∏è {symbol}„ÅÆ‰æ°Ê†ºÂèñÂæó„Ç®„É©„Éº: {e}')
            continue

    conn.commit()
    print(f'‚úÖ ÂêàË®à{prices_added}‰ª∂„ÅÆ‰æ°Ê†º„Éá„Éº„Çø„ÇíÂèéÈõÜÂÆå‰∫Ü')
    conn.close()

collect_price_data()
"

# 4. ‰∫àÊ∏¨„Éá„Éº„Çø„ÅÆÁîüÊàê
echo "üîÆ ‰∫àÊ∏¨„Éá„Éº„ÇøÁîüÊàê‰∏≠..."
python3 -c "
import psycopg2
import numpy as np
from datetime import datetime, timedelta
import random

def generate_predictions():
    conn = psycopg2.connect(
        host='34.173.9.214',
        user='postgres',
        password='os.getenv('DB_PASSWORD', '')',
        database='miraikakaku'
    )
    cursor = conn.cursor()

    # ÊúÄËøë‰æ°Ê†º„Éá„Éº„Çø„Åå„ÅÇ„ÇãÈäòÊüÑ„ÇíÂèñÂæó
    cursor.execute('''
        SELECT DISTINCT sp.symbol, sp.close_price
        FROM stock_prices sp
        WHERE sp.date >= CURRENT_DATE - INTERVAL '7 days'
        AND sp.close_price IS NOT NULL
        ORDER BY RANDOM()
        LIMIT 50
    ''')

    symbols_with_price = cursor.fetchall()
    predictions_added = 0

    for symbol, current_price in symbols_with_price:
        try:
            # ÈÅéÂéª„ÅÆ‰æ°Ê†º„Éá„Éº„Çø„ÇíÂèñÂæó
            cursor.execute('''
                SELECT close_price FROM stock_prices
                WHERE symbol = %s AND date >= CURRENT_DATE - INTERVAL '30 days'
                AND close_price IS NOT NULL
                ORDER BY date DESC
                LIMIT 10
            ''', (symbol,))

            prices = [row[0] for row in cursor.fetchall()]

            if len(prices) < 2:
                continue

            # „Ç∑„É≥„Éó„É´„Å™‰∫àÊ∏¨„É≠„Ç∏„ÉÉ„ÇØ
            avg_price = np.mean(prices)
            std_price = np.std(prices) if len(prices) > 1 else avg_price * 0.05
            trend = (prices[0] - prices[-1]) / len(prices) if len(prices) > 1 else 0

            # Ë§áÊï∞Êó•„ÅÆ‰∫àÊ∏¨„ÇíÁîüÊàê
            for days_ahead in [1, 3, 7, 14, 30]:
                prediction_date = datetime.now() + timedelta(days=days_ahead)

                # „Éà„É¨„É≥„Éâ„Å®Â§âÂãï„ÇíËÄÉÊÖÆ„Åó„Åü‰∫àÊ∏¨
                trend_adjustment = trend * days_ahead
                random_variation = random.gauss(0, std_price * 0.1)
                predicted_price = float(avg_price + trend_adjustment + random_variation)

                # ‰æ°Ê†º„ÅåË≤†„Å´„Å™„Çâ„Å™„ÅÑ„Çà„ÅÜ„Å´Ë™øÊï¥
                predicted_price = max(predicted_price, current_price * 0.5)

                # ‰ø°È†ºÂ∫¶„Çπ„Ç≥„Ç¢ÔºàÊó•Êï∞„ÅåÈï∑„ÅÑ„Åª„Å©‰Ωé‰∏ãÔºâ
                confidence = max(0.3, 0.9 - (days_ahead * 0.02))

                cursor.execute('''
                    INSERT INTO stock_predictions
                    (symbol, prediction_date, prediction_days, current_price,
                     predicted_price, confidence_score, model_type, created_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (symbol, prediction_date, prediction_days) DO UPDATE SET
                        predicted_price = EXCLUDED.predicted_price,
                        confidence_score = EXCLUDED.confidence_score,
                        created_at = EXCLUDED.created_at
                ''', (
                    symbol,
                    prediction_date.date(),
                    days_ahead,
                    float(current_price),
                    predicted_price,
                    confidence,
                    'CONTINUOUS_ENRICHMENT_V1',
                    datetime.now()
                ))

                predictions_added += 1

        except Exception as e:
            print(f'‚ö†Ô∏è {symbol}„ÅÆ‰∫àÊ∏¨ÁîüÊàê„Ç®„É©„Éº: {e}')
            continue

        if predictions_added % 50 == 0:
            conn.commit()
            print(f'‚úÖ {predictions_added}‰ª∂„ÅÆ‰∫àÊ∏¨„ÇíÁîüÊàê')

    conn.commit()
    print(f'‚úÖ ÂêàË®à{predictions_added}‰ª∂„ÅÆ‰∫àÊ∏¨„Éá„Éº„Çø„ÇíÁîüÊàêÂÆå‰∫Ü')
    conn.close()

generate_predictions()
"

# 5. „Éá„Éº„ÇøÂÖÖË∂≥Áä∂Ê≥Å„ÅÆÁ¢∫Ë™ç
echo "üìä „Éá„Éº„ÇøÂÖÖË∂≥Áä∂Ê≥ÅÁ¢∫Ë™ç‰∏≠..."
python3 -c "
import psycopg2

conn = psycopg2.connect(
    host='34.173.9.214',
    user='postgres',
    password='os.getenv('DB_PASSWORD', '')',
    database='miraikakaku'
)
cursor = conn.cursor()

# Áµ±Ë®àÊÉÖÂ†±„ÇíÂèñÂæó
cursor.execute('SELECT COUNT(*) FROM stock_master WHERE is_active = true')
active_symbols = cursor.fetchone()[0]

cursor.execute('SELECT COUNT(DISTINCT symbol) FROM stock_prices WHERE date >= CURRENT_DATE - INTERVAL \\'7 days\\'')
symbols_with_recent_prices = cursor.fetchone()[0]

cursor.execute('SELECT COUNT(*) FROM stock_predictions WHERE created_at >= NOW() - INTERVAL \\'1 hour\\'')
recent_predictions = cursor.fetchone()[0]

cursor.execute('SELECT COUNT(DISTINCT symbol) FROM stock_predictions WHERE prediction_date >= CURRENT_DATE')
symbols_with_predictions = cursor.fetchone()[0]

print('='*50)
print('üìà „Éá„Éº„ÇøÂÖÖË∂≥„É¨„Éù„Éº„Éà')
print(f'‚úÖ „Ç¢„ÇØ„ÉÜ„Ç£„ÉñÈäòÊüÑÊï∞: {active_symbols:,}')
print(f'‚úÖ ÊúÄËøë„ÅÆ‰æ°Ê†º„Éá„Éº„Çø„Åå„ÅÇ„ÇãÈäòÊüÑ: {symbols_with_recent_prices:,}')
print(f'‚úÖ ‰∫àÊ∏¨„Éá„Éº„Çø„Åå„ÅÇ„ÇãÈäòÊüÑ: {symbols_with_predictions:,}')
print(f'‚úÖ ‰ªäÂõûÁîüÊàê„Åó„Åü‰∫àÊ∏¨: {recent_predictions:,}')
print('='*50)

conn.close()
"

echo "üéâ „Éá„Éº„ÇøÂÖÖË∂≥„Éê„ÉÉ„ÉÅÂÆå‰∫Ü"
echo "ÁµÇ‰∫ÜÊôÇÂàª: $(date)"
"""

        return {
            "taskGroups": [{
                "taskSpec": {
                    "runnables": [{
                        "script": {
                            "text": script.strip()
                        }
                    }],
                    "computeResource": {
                        "cpuMilli": 2000,
                        "memoryMib": 4096
                    },
                    "maxRetryCount": 2,
                    "maxRunDuration": "3600s"
                },
                "taskCount": 1,
                "parallelism": 1
            }],
            "allocationPolicy": {
                "instances": [{
                    "policy": {
                        "machineType": "e2-standard-2",
                        "provisioningModel": "STANDARD"
                    }
                }]
            },
            "logsPolicy": {
                "destination": "CLOUD_LOGGING"
            }
        }

    def submit_job(self, job_name: str) -> bool:
        """„Ç∏„Éß„Éñ„ÇíÊäïÂÖ•"""
        try:
            logger.info(f"Submitting job: {job_name}")

            job_config = self.create_comprehensive_job()

            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                json.dump(job_config, f, indent=2)
                config_file = f.name

            try:
                cmd = [
                    "gcloud", "batch", "jobs", "submit",
                    job_name,
                    f"--location={self.location}",
                    f"--config={config_file}"
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                logger.info(f"Job submitted successfully: {job_name}")
                return True

            finally:
                os.unlink(config_file)

        except Exception as e:
            logger.error(f"Failed to submit job {job_name}: {e}")
            return False

    def deploy_continuous_jobs(self) -> None:
        """Á∂ôÁ∂öÁöÑ„Å™„Ç∏„Éß„Éñ„Çí„Éá„Éó„É≠„Ç§"""
        timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
        job_name = f"continuous-data-enrichment-{timestamp}"

        if self.submit_job(job_name):
            logger.info(f"‚úÖ Continuous data enrichment job deployed: {job_name}")
        else:
            logger.error(f"‚ùå Failed to deploy job: {job_name}")

def main():
    """„É°„Ç§„É≥Èñ¢Êï∞"""
    deployer = ContinuousDataEnrichmentJob()
    deployer.deploy_continuous_jobs()

if __name__ == "__main__":
    main()