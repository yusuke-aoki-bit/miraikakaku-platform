#!/usr/bin/env python3
"""
Google Cloud ãƒãƒƒãƒå‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç›£è¦– - é‹ç”¨çŠ¶æ³ã®ç·åˆãƒ¬ãƒãƒ¼ãƒˆ
"""

import subprocess
import json
import logging
from datetime import datetime, timedelta

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def get_cloud_run_status():
    """Cloud Run ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³ç¢ºèª"""

    logger.info("ğŸš€ Cloud Run ã‚µãƒ¼ãƒ“ã‚¹ç¢ºèªä¸­...")

    try:
        cmd = ["gcloud", "run", "services", "list", "--format", "json"]
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            services = json.loads(result.stdout)

            batch_services = [
                s
                for s in services
                if "batch" in s.get("metadata", {}).get("name", "").lower()
            ]

            logger.info(f"ğŸ“Š ãƒãƒƒãƒã‚µãƒ¼ãƒ“ã‚¹: {len(batch_services)}å€‹")

            for service in batch_services:
                name = service.get("metadata", {}).get("name", "Unknown")
                region = (
                    service.get("metadata", {})
                    .get("labels", {})
                    .get("cloud.googleapis.com/location", "Unknown")
                )
                url = service.get("status", {}).get("url", "No URL")

                # ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³ç¢ºèª
                try:
                    test_cmd = [
                        "curl",
                        "-s",
                        "-o",
                        "/dev/null",
                        "-w",
                        "%{http_code}",
                        url,
                        "-m",
                        "10",
                    ]
                    test_result = subprocess.run(
                        test_cmd, capture_output=True, text=True
                    )

                    status_code = test_result.stdout.strip()
                    status = (
                        "ğŸŸ¢ æ­£å¸¸" if status_code == "200" else f"ğŸ”´ ç•°å¸¸({status_code})"
                    )
                except BaseException:
                    status = "âš ï¸  ä¸æ˜"

                logger.info(f"  {name} ({region}): {status}")
                logger.info(f"    URL: {url}")

            return batch_services
        else:
            logger.error(f"ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§å–å¾—å¤±æ•—: {result.stderr}")

    except Exception as e:
        logger.error(f"Cloud Runç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

    return []


def get_scheduler_status():
    """Cloud Scheduler ã‚¸ãƒ§ãƒ–çŠ¶æ³ç¢ºèª"""

    logger.info("â° Cloud Scheduler ã‚¸ãƒ§ãƒ–ç¢ºèªä¸­...")

    try:
        cmd = [
            "gcloud",
            "scheduler",
            "jobs",
            "list",
            "--location=us-central1",
            "--format",
            "json",
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            jobs = json.loads(result.stdout)

            batch_jobs = [j for j in jobs if "miraikakaku-batch" in j.get("name", "")]

            logger.info(f"ğŸ“… ãƒãƒƒãƒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«: {len(batch_jobs)}å€‹")

            for job in batch_jobs:
                name = job.get("name", "").split("/")[-1]  # ãƒ•ãƒ«ãƒ‘ã‚¹ã‹ã‚‰åå‰ã®ã¿æŠ½å‡º
                schedule = job.get("schedule", "No schedule")
                state = job.get("state", "Unknown")

                state_emoji = "ğŸŸ¢" if state == "ENABLED" else "ğŸ”´"

                logger.info(f"  {name}: {state_emoji} {state}")
                logger.info(f"    ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«: {schedule}")

                # æœ€è¿‘ã®å®Ÿè¡Œå±¥æ­´ç¢ºèª
                try:
                    history_cmd = [
                        "gcloud",
                        "scheduler",
                        "jobs",
                        "run-history",
                        name,
                        "--location=us-central1",
                        "--limit=3",
                        "--format=json",
                    ]
                    history_result = subprocess.run(
                        history_cmd, capture_output=True, text=True, timeout=10
                    )

                    if history_result.returncode == 0:
                        executions = json.loads(history_result.stdout)
                        if executions:
                            latest = executions[0]
                            attempt_time = latest.get("attemptTime", "Unknown")
                            status = latest.get("status", "Unknown")
                            logger.info(f"    æœ€æ–°å®Ÿè¡Œ: {attempt_time} - {status}")
                except BaseException:
                    logger.info(f"    å®Ÿè¡Œå±¥æ­´: å–å¾—ä¸å¯")

            return batch_jobs
        else:
            logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä¸€è¦§å–å¾—å¤±æ•—: {result.stderr}")

    except Exception as e:
        logger.error(f"Schedulerç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

    return []


def get_build_status():
    """æœ€è¿‘ã®Cloud Buildã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª"""

    logger.info("ğŸ”¨ æœ€è¿‘ã®ãƒ“ãƒ«ãƒ‰çŠ¶æ³ç¢ºèªä¸­...")

    try:
        cmd = ["gcloud", "builds", "list", "--limit=5", "--format=json"]
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            builds = json.loads(result.stdout)

            logger.info(f"ğŸ“¦ æœ€è¿‘ã®ãƒ“ãƒ«ãƒ‰: {len(builds)}å€‹")

            for build in builds:
                build_id = build.get("id", "Unknown")[:8]  # çŸ­ç¸®ID
                status = build.get("status", "Unknown")
                create_time = build.get("createTime", "Unknown")

                status_emoji = {
                    "SUCCESS": "ğŸŸ¢",
                    "FAILURE": "ğŸ”´",
                    "WORKING": "ğŸŸ¡",
                    "TIMEOUT": "â±ï¸",
                    "CANCELLED": "âšª",
                }.get(status, "â“")

                logger.info(f"  {build_id}: {status_emoji} {status} ({create_time})")

            return builds
        else:
            logger.error(f"ãƒ“ãƒ«ãƒ‰å±¥æ­´å–å¾—å¤±æ•—: {result.stderr}")

    except Exception as e:
        logger.error(f"Buildç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

    return []


def check_database_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª"""

    logger.info("ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèªä¸­...")

    try:
        # ç°¡å˜ãªDBæ¥ç¶šãƒ†ã‚¹ãƒˆ
        from database.database import get_db
        from sqlalchemy import text

        db = next(get_db())
        result = db.execute(text("SELECT COUNT(*) FROM stock_master"))
        count = result.scalar()

        logger.info(f"âœ… DBæ¥ç¶šæˆåŠŸ: stock_master {count:,}ä»¶")
        db.close()
        return True

    except Exception as e:
        logger.error(f"âŒ DBæ¥ç¶šå¤±æ•—: {e}")
        return False


def generate_monitoring_report():
    """ç·åˆç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

    logger.info("=" * 80)
    logger.info("ğŸ“Š Google Cloud ãƒãƒƒãƒå‡¦ç† ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ")
    logger.info(f"ğŸ“… ãƒ¬ãƒãƒ¼ãƒˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 80)

    # 1. Cloud Run ã‚µãƒ¼ãƒ“ã‚¹ç¢ºèª
    services = get_cloud_run_status()

    logger.info("")

    # 2. Cloud Scheduler ã‚¸ãƒ§ãƒ–ç¢ºèª
    jobs = get_scheduler_status()

    logger.info("")

    # 3. æœ€è¿‘ã®ãƒ“ãƒ«ãƒ‰ç¢ºèª
    builds = get_build_status()

    logger.info("")

    # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
    db_status = check_database_connection()

    logger.info("")
    logger.info("ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ã‚µãƒãƒªãƒ¼")
    logger.info("-" * 60)

    service_count = len(
        [
            s
            for s in services
            if "batch" in s.get("metadata", {}).get("name", "").lower()
        ]
    )
    job_count = len(jobs)
    recent_builds = len([b for b in builds if b.get("status") == "SUCCESS"])

    logger.info(f"  Cloud Run ãƒãƒƒãƒã‚µãƒ¼ãƒ“ã‚¹: {service_count}å€‹ç¨¼åƒä¸­")
    logger.info(f"  Cloud Scheduler ã‚¸ãƒ§ãƒ–: {job_count}å€‹è¨­å®šæ¸ˆã¿")
    logger.info(f"  æœ€è¿‘ã®æˆåŠŸãƒ“ãƒ«ãƒ‰: {recent_builds}å€‹")
    logger.info(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {'âœ… æ­£å¸¸' if db_status else 'âŒ ç•°å¸¸'}")

    # ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ã‚¹ã‚³ã‚¢
    total_checks = 4
    passed_checks = (
        (1 if service_count > 0 else 0)
        + (1 if job_count > 0 else 0)
        + (1 if recent_builds > 0 else 0)
        + (1 if db_status else 0)
    )

    health_score = (passed_checks / total_checks) * 100

    logger.info(
        f"  ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§: {health_score:.0f}% ({passed_checks}/{total_checks})"
    )

    if health_score >= 75:
        logger.info("ğŸŸ¢ ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸å‹•ä½œä¸­")
    elif health_score >= 50:
        logger.info("ğŸŸ¡ ä¸€éƒ¨å•é¡Œã‚ã‚Š - ç¢ºèªæ¨å¥¨")
    else:
        logger.info("ğŸ”´ ã‚·ã‚¹ãƒ†ãƒ ç•°å¸¸ - ç·Šæ€¥å¯¾å¿œå¿…è¦")

    logger.info("=" * 80)

    return {
        "services": service_count,
        "jobs": job_count,
        "successful_builds": recent_builds,
        "database_healthy": db_status,
        "health_score": health_score,
    }


if __name__ == "__main__":
    report = generate_monitoring_report()
    logger.info(f"âœ… ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆå®Œäº†: å¥å…¨æ€§ {report['health_score']:.0f}%")
