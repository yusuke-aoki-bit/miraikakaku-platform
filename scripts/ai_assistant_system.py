#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Miraikakaku AI Assistant System
é«˜åº¦ãªAIæŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼

æ©Ÿèƒ½:
- è‡ªç„¶è¨€èªã«ã‚ˆã‚‹æŠ•è³‡ç›¸è«‡å¯¾å¿œ
- å¸‚å ´åˆ†æã¨äºˆæ¸¬ã®èª¬æ˜
- ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ææ¡ˆ
- ãƒªã‚¹ã‚¯åˆ†æã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
- æŠ•è³‡æˆ¦ç•¥ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åˆ†æï¼ˆãƒ†ã‚­ã‚¹ãƒˆ + ãƒ‡ãƒ¼ã‚¿ï¼‰
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import re
import numpy as np
import pandas as pd

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
import psycopg2
from psycopg2.extras import RealDictCursor

# æ©Ÿæ¢°å­¦ç¿’ãƒ»çµ±è¨ˆ
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ai_assistant.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class UserQuery:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•"""
    text: str
    user_id: Optional[str]
    timestamp: datetime
    context: Dict[str, Any]
    intent: Optional[str] = None
    entities: Optional[Dict[str, List[str]]] = None

@dataclass
class AssistantResponse:
    """AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”"""
    response_text: str
    confidence: float
    response_type: str  # 'analysis', 'recommendation', 'explanation', 'alert'
    data_sources: List[str]
    suggested_actions: List[str]
    related_stocks: List[str]
    charts_data: Optional[Dict[str, Any]]
    timestamp: datetime
    reasoning: List[str]

@dataclass
class InvestmentProfile:
    """æŠ•è³‡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    user_id: str
    risk_tolerance: str  # 'conservative', 'moderate', 'aggressive'
    investment_horizon: str  # 'short', 'medium', 'long'
    preferred_sectors: List[str]
    capital_amount: Optional[float]
    experience_level: str  # 'beginner', 'intermediate', 'advanced'
    goals: List[str]
    constraints: List[str]

class NaturalLanguageProcessor:
    """è‡ªç„¶è¨€èªå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        self.intent_patterns = {
            'price_inquiry': [
                r'.*ä¾¡æ ¼.*', r'.*æ ªä¾¡.*', r'.*ã„ãã‚‰.*', r'.*å€¤æ®µ.*',
                r'.*price.*', r'.*cost.*', r'.*worth.*'
            ],
            'prediction_request': [
                r'.*äºˆæ¸¬.*', r'.*äºˆæƒ³.*', r'.*è¦‹é€šã—.*', r'.*å°†æ¥.*',
                r'.*prediction.*', r'.*forecast.*', r'.*future.*'
            ],
            'analysis_request': [
                r'.*åˆ†æ.*', r'.*è©•ä¾¡.*', r'.*ã©ã†æ€ã†.*', r'.*æ„è¦‹.*',
                r'.*analysis.*', r'.*analyze.*', r'.*opinion.*'
            ],
            'recommendation_request': [
                r'.*ãŠã™ã™ã‚.*', r'.*æ¨å¥¨.*', r'.*è²·ã†.*', r'.*å£²ã‚‹.*',
                r'.*recommend.*', r'.*suggest.*', r'.*buy.*', r'.*sell.*'
            ],
            'portfolio_inquiry': [
                r'.*ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª.*', r'.*è³‡ç”£é…åˆ†.*', r'.*åˆ†æ•£.*',
                r'.*portfolio.*', r'.*allocation.*', r'.*diversification.*'
            ],
            'risk_inquiry': [
                r'.*ãƒªã‚¹ã‚¯.*', r'.*å±é™º.*', r'.*å®‰å…¨.*', r'.*volatility.*',
                r'.*risk.*', r'.*safe.*', r'.*danger.*'
            ]
        }

        self.entity_patterns = {
            'stock_symbols': r'\b([A-Z]{1,5})\b',
            'companies': [
                'Apple', 'Google', 'Microsoft', 'Tesla', 'Amazon',
                'ã‚¢ãƒƒãƒ—ãƒ«', 'ã‚°ãƒ¼ã‚°ãƒ«', 'ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆ', 'ãƒ†ã‚¹ãƒ©', 'ã‚¢ãƒã‚¾ãƒ³'
            ],
            'numbers': r'\$?(\d{1,3}(?:,\d{3})*(?:\.\d{2})?)',
            'time_periods': [
                'ä»Šæ—¥', 'æ˜æ—¥', 'æ¥é€±', 'æ¥æœˆ', 'ä»Šå¹´',
                'today', 'tomorrow', 'next week', 'next month'
            ]
        }

        # TF-IDF for semantic similarity (if available)
        if SKLEARN_AVAILABLE:
            self.vectorizer = TfidfVectorizer(
                max_features=1000,
                stop_words='english',
                ngram_range=(1, 2)
            )
            self._trained = False

    def analyze_query(self, query: UserQuery) -> UserQuery:
        """ã‚¯ã‚¨ãƒªåˆ†æ"""
        logger.info(f"ğŸ“ ã‚¯ã‚¨ãƒªåˆ†æ: {query.text[:50]}...")

        # æ„å›³åˆ†é¡
        query.intent = self._classify_intent(query.text)

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º
        query.entities = self._extract_entities(query.text)

        logger.info(f"ğŸ¯ åˆ†æçµæœ: æ„å›³={query.intent}, ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£={len(query.entities) if query.entities else 0}ä»¶")
        return query

    def _classify_intent(self, text: str) -> str:
        """æ„å›³åˆ†é¡"""
        text_lower = text.lower()

        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    return intent

        return 'general_inquiry'

    def _extract_entities(self, text: str) -> Dict[str, List[str]]:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º"""
        entities = {}

        # æ ªå¼ã‚·ãƒ³ãƒœãƒ«
        symbols = re.findall(self.entity_patterns['stock_symbols'], text.upper())
        if symbols:
            entities['symbols'] = list(set(symbols))

        # ä¼šç¤¾å
        companies = []
        for company in self.entity_patterns['companies']:
            if company.lower() in text.lower():
                companies.append(company)
        if companies:
            entities['companies'] = companies

        # æ•°å€¤
        numbers = re.findall(self.entity_patterns['numbers'], text)
        if numbers:
            entities['numbers'] = numbers

        return entities

class MarketDataAnalyzer:
    """å¸‚å ´ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        self.db_config = {
            'host': "34.173.9.214",
            'database': "miraikakaku",
            'user': "postgres",
            'password': os.getenv('DB_PASSWORD')
        }

    def get_stock_analysis(self, symbol: str) -> Dict[str, Any]:
        """æ ªå¼åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—"""
        logger.info(f"ğŸ“Š {symbol}ã®åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")

        try:
            conn = psycopg2.connect(**self.db_config)

            # æœ€æ–°ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            price_query = """
            SELECT date, close_price, volume,
                   close_price - LAG(close_price) OVER (ORDER BY date) as price_change
            FROM stock_prices
            WHERE symbol = %s
            ORDER BY date DESC
            LIMIT 30
            """

            price_df = pd.read_sql_query(price_query, conn, params=[symbol])

            # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿
            prediction_query = """
            SELECT prediction_date, predicted_price, confidence_score
            FROM stock_predictions
            WHERE symbol = %s
            AND prediction_date >= CURRENT_DATE
            ORDER BY prediction_date ASC
            LIMIT 10
            """

            prediction_df = pd.read_sql_query(prediction_query, conn, params=[symbol])

            conn.close()

            if price_df.empty:
                return {'error': f'{symbol}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}

            # åˆ†æè¨ˆç®—
            analysis = self._calculate_technical_indicators(price_df)
            analysis['predictions'] = prediction_df.to_dict('records') if not prediction_df.empty else []
            analysis['symbol'] = symbol
            analysis['last_updated'] = datetime.now().isoformat()

            return analysis

        except Exception as e:
            logger.error(f"åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'error': str(e)}

    def _calculate_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—"""
        if df.empty:
            return {}

        analysis = {}

        # åŸºæœ¬çµ±è¨ˆ
        latest_price = df.iloc[0]['close_price']
        analysis['current_price'] = float(latest_price)
        analysis['price_change_1d'] = float(df.iloc[0]['price_change']) if df.iloc[0]['price_change'] else 0

        # ç§»å‹•å¹³å‡
        df['ma_5'] = df['close_price'].rolling(5).mean()
        df['ma_20'] = df['close_price'].rolling(20).mean()

        analysis['ma_5'] = float(df.iloc[0]['ma_5']) if not pd.isna(df.iloc[0]['ma_5']) else None
        analysis['ma_20'] = float(df.iloc[0]['ma_20']) if not pd.isna(df.iloc[0]['ma_20']) else None

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        returns = df['close_price'].pct_change().dropna()
        analysis['volatility'] = float(returns.std()) * np.sqrt(252) if len(returns) > 1 else 0

        # RSIé¢¨æŒ‡æ¨™
        gains = returns.where(returns > 0, 0)
        losses = -returns.where(returns < 0, 0)
        if len(gains) > 1 and len(losses) > 1:
            avg_gain = gains.mean()
            avg_loss = losses.mean()
            if avg_loss != 0:
                rs = avg_gain / avg_loss
                analysis['rsi_like'] = float(100 - (100 / (1 + rs)))
            else:
                analysis['rsi_like'] = 100

        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        if len(df) >= 5:
            recent_trend = np.polyfit(range(5), df.iloc[:5]['close_price'].values, 1)[0]
            analysis['trend'] = 'up' if recent_trend > 0 else 'down'
            analysis['trend_strength'] = abs(float(recent_trend))

        return analysis

class InvestmentAdvisor:
    """æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        self.risk_profiles = {
            'conservative': {
                'volatility_threshold': 0.15,
                'recommended_allocation': {'stocks': 0.4, 'bonds': 0.5, 'cash': 0.1},
                'max_single_position': 0.05
            },
            'moderate': {
                'volatility_threshold': 0.25,
                'recommended_allocation': {'stocks': 0.6, 'bonds': 0.3, 'cash': 0.1},
                'max_single_position': 0.10
            },
            'aggressive': {
                'volatility_threshold': 0.35,
                'recommended_allocation': {'stocks': 0.8, 'bonds': 0.1, 'cash': 0.1},
                'max_single_position': 0.20
            }
        }

    def generate_recommendation(
        self,
        query: UserQuery,
        analysis_data: Dict[str, Any],
        user_profile: Optional[InvestmentProfile] = None
    ) -> List[str]:
        """æŠ•è³‡æ¨å¥¨ç”Ÿæˆ"""

        recommendations = []

        if 'error' in analysis_data:
            recommendations.append("ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚")
            return recommendations

        symbol = analysis_data.get('symbol', 'Unknown')
        current_price = analysis_data.get('current_price', 0)
        volatility = analysis_data.get('volatility', 0)
        trend = analysis_data.get('trend', 'neutral')

        # ãƒªã‚¹ã‚¯è©•ä¾¡
        risk_level = self._assess_risk_level(analysis_data, user_profile)

        if query.intent == 'recommendation_request':
            if trend == 'up' and risk_level == 'low':
                recommendations.append(f"{symbol}ã¯ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã¤ä½ãƒªã‚¹ã‚¯ã§ã€æŠ•è³‡æ¤œè¨ã«å€¤ã—ã¾ã™ã€‚")
            elif trend == 'down' or risk_level == 'high':
                recommendations.append(f"{symbol}ã¯ç¾åœ¨ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚ã€æ…é‡ãªåˆ¤æ–­ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
            else:
                recommendations.append(f"{symbol}ã¯ä¸­ç«‹çš„ãªçŠ¶æ³ã§ã™ã€‚ä»–ã®æŠ•è³‡æ©Ÿä¼šã¨æ¯”è¼ƒæ¤œè¨ã—ã¦ãã ã•ã„ã€‚")

        elif query.intent == 'risk_inquiry':
            if volatility > 0.3:
                recommendations.append(f"{symbol}ã¯é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ{volatility:.1%}ï¼‰ã®ãŸã‚ã€ãƒªã‚¹ã‚¯ç®¡ç†ãŒé‡è¦ã§ã™ã€‚")
            else:
                recommendations.append(f"{symbol}ã¯æ¯”è¼ƒçš„å®‰å®šçš„ãªå€¤å‹•ãï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£{volatility:.1%}ï¼‰ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚")

        elif query.intent == 'prediction_request':
            predictions = analysis_data.get('predictions', [])
            if predictions:
                next_pred = predictions[0]
                recommendations.append(f"AIãƒ¢ãƒ‡ãƒ«ã¯{symbol}ã®æ¬¡æœŸäºˆæ¸¬ä¾¡æ ¼ã‚’${next_pred['predicted_price']:.2f}ã¨äºˆæ¸¬ã—ã¦ã„ã¾ã™ã€‚")
                recommendations.append(f"äºˆæ¸¬ä¿¡é ¼åº¦: {next_pred['confidence_score']:.1%}")

        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªé–¢é€£ã‚¢ãƒ‰ãƒã‚¤ã‚¹
        if user_profile and query.intent == 'portfolio_inquiry':
            profile_rec = self._generate_portfolio_advice(user_profile, analysis_data)
            recommendations.extend(profile_rec)

        return recommendations

    def _assess_risk_level(
        self,
        analysis_data: Dict[str, Any],
        user_profile: Optional[InvestmentProfile]
    ) -> str:
        """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è©•ä¾¡"""
        volatility = analysis_data.get('volatility', 0)

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤
        thresholds = self.risk_profiles['moderate']

        if user_profile and user_profile.risk_tolerance in self.risk_profiles:
            thresholds = self.risk_profiles[user_profile.risk_tolerance]

        if volatility > thresholds['volatility_threshold']:
            return 'high'
        elif volatility < thresholds['volatility_threshold'] * 0.6:
            return 'low'
        else:
            return 'medium'

    def _generate_portfolio_advice(
        self,
        profile: InvestmentProfile,
        analysis_data: Dict[str, Any]
    ) -> List[str]:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆ"""
        advice = []

        risk_config = self.risk_profiles.get(profile.risk_tolerance, self.risk_profiles['moderate'])

        advice.append(f"ã‚ãªãŸã®{profile.risk_tolerance}ãƒªã‚¹ã‚¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãæ¨å¥¨è³‡ç”£é…åˆ†:")
        for asset, ratio in risk_config['recommended_allocation'].items():
            advice.append(f"- {asset}: {ratio:.0%}")

        advice.append(f"å˜ä¸€éŠ˜æŸ„ã®æœ€å¤§æŠ•è³‡æ¯”ç‡: {risk_config['max_single_position']:.0%}")

        return advice

class AIAssistantEngine:
    """AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        self.nlp = NaturalLanguageProcessor()
        self.market_analyzer = MarketDataAnalyzer()
        self.investment_advisor = InvestmentAdvisor()

        # å¿œç­”ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.response_templates = {
            'greeting': [
                "ã“ã‚“ã«ã¡ã¯ï¼æŠ•è³‡ã«é–¢ã™ã‚‹ã”è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚",
                "Miraikakaku AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ã©ã®ã‚ˆã†ãªã‚µãƒãƒ¼ãƒˆã‚’ãŠæ±‚ã‚ã§ã™ã‹ï¼Ÿ"
            ],
            'price_inquiry': [
                "æœ€æ–°ã®ä¾¡æ ¼æƒ…å ±ã‚’ãŠèª¿ã¹ã—ã¾ã™ã€‚",
                "ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã„ã¾ã™..."
            ],
            'analysis_complete': [
                "åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚",
                "ä»¥ä¸‹ãŒåˆ†æçµæœã§ã™ï¼š"
            ]
        }

    def process_query(
        self,
        query_text: str,
        user_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> AssistantResponse:
        """ãƒ¡ã‚¤ãƒ³ã‚¯ã‚¨ãƒªå‡¦ç†"""

        logger.info(f"ğŸ¤– AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå‡¦ç†é–‹å§‹: {query_text[:50]}...")

        # ã‚¯ã‚¨ãƒªæº–å‚™
        query = UserQuery(
            text=query_text,
            user_id=user_id,
            timestamp=datetime.now(),
            context=context or {}
        )

        # è‡ªç„¶è¨€èªå‡¦ç†
        query = self.nlp.analyze_query(query)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
        response = self._generate_response(query)

        logger.info(f"âœ… å¿œç­”ç”Ÿæˆå®Œäº†: ä¿¡é ¼åº¦{response.confidence:.2f}")
        return response

    def _generate_response(self, query: UserQuery) -> AssistantResponse:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""

        response_text = ""
        confidence = 0.7
        suggested_actions = []
        related_stocks = []
        data_sources = []
        reasoning = []

        try:
            # æŒ¨æ‹¶ãƒ»ä¸€èˆ¬çš„ãªè³ªå•
            if any(greeting in query.text.lower() for greeting in ['ã“ã‚“ã«ã¡ã¯', 'hello', 'hi', 'ã¯ã˜ã‚ã¾ã—ã¦']):
                response_text = "ã“ã‚“ã«ã¡ã¯ï¼Miraikakaku AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ ªå¼æŠ•è³‡ã«é–¢ã™ã‚‹ã”è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚éŠ˜æŸ„åˆ†æã€å¸‚å ´äºˆæ¸¬ã€æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãªã©ã€ãŠæ°—è»½ã«ãŠå°‹ã­ãã ã•ã„ã€‚"
                confidence = 0.95

            # æ ªå¼é–¢é€£ã®è³ªå•
            elif query.entities and 'symbols' in query.entities:
                symbol = query.entities['symbols'][0]
                related_stocks = [symbol]

                # å¸‚å ´ãƒ‡ãƒ¼ã‚¿åˆ†æ
                analysis_data = self.market_analyzer.get_stock_analysis(symbol)
                data_sources = ['market_data', 'predictions']

                if 'error' not in analysis_data:
                    # åŸºæœ¬æƒ…å ±
                    current_price = analysis_data.get('current_price', 0)
                    price_change = analysis_data.get('price_change_1d', 0)
                    volatility = analysis_data.get('volatility', 0)

                    response_text = f"{symbol}ã®åˆ†æçµæœï¼š\n"
                    response_text += f"ç¾åœ¨ä¾¡æ ¼: ${current_price:.2f}\n"
                    response_text += f"1æ—¥å¤‰å‹•: {price_change:+.2f} ({price_change/current_price*100:+.1f}%)\n"
                    response_text += f"å¹´é–“ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {volatility:.1%}\n"

                    # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±
                    trend = analysis_data.get('trend')
                    if trend:
                        trend_desc = "ä¸Šæ˜‡å‚¾å‘" if trend == 'up' else "ä¸‹é™å‚¾å‘"
                        response_text += f"çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰: {trend_desc}\n"

                    # æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹
                    recommendations = self.investment_advisor.generate_recommendation(
                        query, analysis_data
                    )

                    if recommendations:
                        response_text += "\nğŸ“‹ æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹:\n"
                        for rec in recommendations:
                            response_text += f"â€¢ {rec}\n"

                    confidence = 0.85
                    reasoning = [
                        f"æœ€æ–°ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ",
                        f"ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’è¨ˆç®—",
                        f"AIãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬ã‚’è€ƒæ…®"
                    ]

                    # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                    if query.intent == 'recommendation_request':
                        if analysis_data.get('trend') == 'up':
                            suggested_actions = ["è©³ç´°åˆ†æã®å®Ÿè¡Œ", "ãƒªã‚¹ã‚¯è©•ä¾¡ã®ç¢ºèª", "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå½±éŸ¿ã®æ¤œè¨"]
                        else:
                            suggested_actions = ["å¸‚å ´å‹•å‘ã®ç¶™ç¶šç›£è¦–", "ä»£æ›¿æŠ•è³‡æ©Ÿä¼šã®æ¢ç´¢"]

                else:
                    response_text = f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚{symbol}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                    confidence = 0.3

            # ä¸€èˆ¬çš„ãªæŠ•è³‡ç›¸è«‡
            elif query.intent == 'portfolio_inquiry':
                response_text = """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã®ãŸã‚ã®åŸºæœ¬åŸå‰‡ï¼š

1. **åˆ†æ•£æŠ•è³‡**: ãƒªã‚¹ã‚¯ã‚’è¤‡æ•°ã®è³‡ç”£ã«åˆ†æ•£
2. **è³‡ç”£é…åˆ†**: å¹´é½¢ã¨æŠ•è³‡ç›®æ¨™ã«å¿œã˜ãŸæ ªå¼ãƒ»å‚µåˆ¸ã®æ¯”ç‡
3. **å®šæœŸçš„ãªãƒªãƒãƒ©ãƒ³ã‚¹**: ç›®æ¨™é…åˆ†ã®ç¶­æŒ
4. **é•·æœŸæŠ•è³‡**: å¸‚å ´ã®çŸ­æœŸå¤‰å‹•ã«æƒ‘ã‚ã•ã‚Œãªã„

å…·ä½“çš„ãªéŠ˜æŸ„ã«ã¤ã„ã¦ãŠèãã«ãªã‚ŠãŸã„å ´åˆã¯ã€éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼šAAPLã€GOOGLï¼‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"""
                confidence = 0.8
                suggested_actions = ["å…·ä½“çš„ãªéŠ˜æŸ„ã®ç›¸è«‡", "ãƒªã‚¹ã‚¯è¨±å®¹åº¦ã®è¨ºæ–­", "æŠ•è³‡ç›®æ¨™ã®è¨­å®š"]

            elif query.intent == 'risk_inquiry':
                response_text = """æŠ•è³‡ãƒªã‚¹ã‚¯ç®¡ç†ã®ãƒã‚¤ãƒ³ãƒˆï¼š

ğŸ”´ **é«˜ãƒªã‚¹ã‚¯è¦å› **:
â€¢ é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£éŠ˜æŸ„ï¼ˆå¹´é–“30%ä»¥ä¸Šã®ä¾¡æ ¼å¤‰å‹•ï¼‰
â€¢ é›†ä¸­æŠ•è³‡ï¼ˆå˜ä¸€éŠ˜æŸ„ã¸ã®åé‡ï¼‰
â€¢ çŸ­æœŸå£²è²·

ğŸŸ¡ **ãƒªã‚¹ã‚¯è»½æ¸›ç­–**:
â€¢ åˆ†æ•£æŠ•è³‡ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯åˆ†æ•£
â€¢ æåˆ‡ã‚Šãƒ«ãƒ¼ãƒ«ã®è¨­å®š
â€¢ æŠ•è³‡é‡‘é¡ã®é©åˆ‡ãªç®¡ç†

å…·ä½“çš„ãªéŠ˜æŸ„ã®ãƒªã‚¹ã‚¯è©•ä¾¡ã«ã¤ã„ã¦ã¯ã€éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’ãŠæ•™ãˆãã ã•ã„ã€‚"""
                confidence = 0.75

            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¿œç­”
                response_text = """ä»¥ä¸‹ã«ã¤ã„ã¦ã‚µãƒãƒ¼ãƒˆã§ãã¾ã™ï¼š

ğŸ“ˆ **å¸‚å ´åˆ†æ**: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆAAPLã€GOOGLãªã©ï¼‰ã‚’æ•™ãˆã¦ãã ã•ã„
ğŸ¯ **æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹**: ã€ŒAAPLã‚’è²·ã†ã¹ãã§ã™ã‹ï¼Ÿã€ã®ã‚ˆã†ãªè³ªå•
ğŸ“Š **ãƒªã‚¹ã‚¯åˆ†æ**: ã€ŒTSLAã®ãƒªã‚¹ã‚¯ã¯ï¼Ÿã€ã®ã‚ˆã†ãªè³ªå•
ğŸ’¼ **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç›¸è«‡**: è³‡ç”£é…åˆ†ã‚„åˆ†æ•£æŠ•è³‡ã«ã¤ã„ã¦

ä½•ã«ã¤ã„ã¦ãŠçŸ¥ã‚Šã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ"""
                confidence = 0.6

        except Exception as e:
            logger.error(f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            response_text = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            confidence = 0.2

        return AssistantResponse(
            response_text=response_text,
            confidence=confidence,
            response_type=query.intent or 'general',
            data_sources=data_sources,
            suggested_actions=suggested_actions,
            related_stocks=related_stocks,
            charts_data=None,
            timestamp=datetime.now(),
            reasoning=reasoning
        )

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    logger.info("ğŸ¤– AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")

    assistant = AIAssistantEngine()

    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_queries = [
        "ã“ã‚“ã«ã¡ã¯",
        "AAPLã®æ ªä¾¡ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
        "TSLAã‚’è²·ã†ã¹ãã§ã—ã‚‡ã†ã‹ï¼Ÿ",
        "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®åˆ†æ•£ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "MSFTã®ãƒªã‚¹ã‚¯ã‚’æ•™ãˆã¦",
        "æŠ•è³‡åˆå¿ƒè€…ã«ãŠã™ã™ã‚ã®éŠ˜æŸ„ã¯ï¼Ÿ"
    ]

    for query in test_queries:
        logger.info(f"\n{'='*50}")
        logger.info(f"è³ªå•: {query}")
        logger.info(f"{'='*50}")

        response = assistant.process_query(query)

        print(f"ğŸ¤– AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ:")
        print(response.response_text)
        print(f"\nä¿¡é ¼åº¦: {response.confidence:.2f}")
        print(f"å¿œç­”ã‚¿ã‚¤ãƒ—: {response.response_type}")

        if response.suggested_actions:
            print(f"æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {', '.join(response.suggested_actions)}")

        if response.related_stocks:
            print(f"é–¢é€£éŠ˜æŸ„: {', '.join(response.related_stocks)}")

        print("\n" + "="*50 + "\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆçµ‚äº†")
    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)